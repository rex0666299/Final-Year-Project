from fastapi import (
    APIRouter,
    Cookie,
    Depends,
    FastAPI,
    File,
    Form,
    HTTPException,
    Query,
    Request,
    UploadFile,
)
import time
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import (
    FileResponse,
    JSONResponse,
    StreamingResponse,
)
from fastapi import Query, Depends, HTTPException
from fastapi.security import OAuth2PasswordBearer
from fastapi.staticfiles import StaticFiles
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, validator
from datetime import datetime, timedelta
import uuid
import traceback
import io
import os
import shutil
import sqlite3
import sys
import tempfile
import re
import random
import base64
import json
import urllib.parse
from pydantic import BaseModel
import numpy as np
import httpx
from sentence_transformers import SentenceTransformer
from pypinyin import lazy_pinyin, Style
from gtts import gTTS
import eng_to_ipa as ipa
from ipa import ipa_to_word
import ollama
from openai import OpenAI
import main_chat
import requests
import aiohttp
from playwright.sync_api import sync_playwright
from jose import JWTError, jwt
from fastapi import APIRouter
from fastapi.responses import JSONResponse
from docx import Document
import pdfplumber
import magic
import slp_training_tasks as slp_tasks
import smtplib
from email.mime.text import MIMEText
from email.header import Header
from passlib.hash import bcrypt as passlib_bcrypt
import bcrypt as pybcrypt
from fastapi import Response
from fastapi.responses import FileResponse
from pathlib import Path
from LLM1_cn.AdditionPractice import detect_addition_error as detect_addition_error_1
from LLM1_cn.Distortion import detect_distortion_error
from LLM1_cn.InitialConsonantPractice import detect_initial_consonant_error
from LLM1_cn.Tone import detect_tone_error
from LLM1_cn.VowelFinal import detect_vowelfinal_error
from LLM1_cn.OmissionPractice import detect_omission_error as detect_omission_error_1
from LLM1_cn.SubstitutionPractice import detect_substitution_error as detect_substitution_error_1
from fastapi import FastAPI, HTTPException
from LLM_US.Substitution import detect_substitution_error
from LLM_US.Addition import detect_addition_error
from LLM_US.Omission import detect_omission_error
import logging
from Chinese.asr_llm_server import transcribe_bytes
import Chinese.asr_llm_server as asr_mod
from English_US.asr_llm_server import transcribe_bytes_en
from English_US.llm_call_gradio_client_local1 import analyze_record_payload
import uuid
from datetime import datetime
from English_US.asr_llm_server import transcribe_bytes_en as transcribe_bytes_en_full
import subprocess

uv_logger = logging.getLogger("uvicorn.error")
uv_logger.warning("[IMPORT DEBUG] Chinese.asr_llm_server file = %s", asr_mod.__file__)
uv_logger.warning("[IMPORT DEBUG] transcribe_bytes module = %s", transcribe_bytes.__module__)

from pydub import AudioSegment
from ws_audio import router as ws_audio_router

app = FastAPI()
app.include_router(ws_audio_router)

ESPEAK_DIR = r"eSpeak NG"
os.environ["PATH"] = ESPEAK_DIR + os.pathsep + os.environ.get("PATH", "")
BASE_DIR = Path(__file__).resolve().parent

USER_ROOT_DIR = "User" 
os.makedirs(USER_ROOT_DIR, exist_ok=True)

sys.path.insert(0, str(Path(__file__).resolve().parent / "English_US"))
sys.path.insert(0, str(Path(__file__).resolve().parent / "Chinese"))

BASE_DIR = Path(__file__).resolve().parent
FFMPEG_BIN = (BASE_DIR / "ffmpeg" / "bin").resolve()

FFMPEG_EXE = str((FFMPEG_BIN / "ffmpeg.exe").resolve())
FFPROBE_EXE = str((FFMPEG_BIN / "ffprobe.exe").resolve())
LLM_MODEL_PATH = "./Chinese/model/Tiger-Gemma-9B-v3-Q3_K_M.gguf"

AudioSegment.converter = FFMPEG_EXE
AudioSegment.ffprobe = FFPROBE_EXE


os.environ["PATH"] = str(FFMPEG_BIN) + os.pathsep + os.environ.get("PATH", "")

print("[FFMPEG] bin =", FFMPEG_BIN)
print("[FFMPEG] ffmpeg exists?", os.path.exists(FFMPEG_EXE), FFMPEG_EXE)
print("[FFMPEG] ffprobe exists?", os.path.exists(FFPROBE_EXE), FFPROBE_EXE)
AudioSegment.ffprobe   = str(FFMPEG_BIN / "ffprobe.exe")

app = FastAPI(title="ASR+LLM Backend with DB")

# âœ… æ›è¼‰éœæ…‹è·¯å¾‘åç¨±æœªå¿…è¦ä¸€è‡´ï¼Œä½†å»ºè­°ä¿æŒæ¸…æ¥š
app.mount("/User", StaticFiles(directory=USER_ROOT_DIR), name="User")
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/uploads", StaticFiles(directory="uploads"), name="uploads")

SECRET_KEY = "abc123"
ADMIN_USERS = ["admin", "bbb"]
ALGORITHM = "HS256"
ROUTE_DB = "route_knowledge.db"
FRONTEND_BASE = r"..\frontend\src"
FRONTEND_URL = "https://203.176.209.165:8443" 

ADMIN_LOCAL_ONLY = "admin" 
ONLY_ADMIN_UPLOAD = True
SLP_INACTIVE_CLOSE_MINUTES = 5
PRESENCE_TTL_SECONDS = 60  

TEST_WORDS_PER_SUBTYPE = 3 #this is cn
TEST_SLP_THRESHOLD = 1 #this is cn

TEST_EN_LANG = "en" #this is en
TEST_EN_WORDS_PER_SUBTYPE_DEFAULT = 3 #this is en
TEST_EN_SLP_THRESHOLD_DEFAULT = 2 #this is en
TEST_EN_SUPER_ORDER = ["Addition", "Omission", "Substitution"]
test_en_router = APIRouter(prefix="/api/test_en", tags=["test_en"])

SEND_USERNAME_COOKIE_DEFAULT = False
UPLOAD_AUDIO_DIR = "./uploads/audio"
UPLOAD_IMAGE_DIR = "./uploads/image"
UPLOAD_DOC_DIR = "uploaded_docs"
os.makedirs(UPLOAD_AUDIO_DIR, exist_ok=True)
os.makedirs(UPLOAD_IMAGE_DIR, exist_ok=True)
os.makedirs(UPLOAD_DOC_DIR, exist_ok=True)

def levenshtein_distance(a, b) -> int:
    # a, b can be list (segments) or str
    if a == b:
        return 0
    n, m = len(a), len(b)
    if n == 0:
        return m
    if m == 0:
        return n

    prev = list(range(m + 1))
    for i in range(1, n + 1):
        cur = [i] + [0] * m
        ai = a[i - 1]
        for j in range(1, m + 1):
            cost = 0 if ai == b[j - 1] else 1
            cur[j] = min(
                prev[j] + 1,      # deletion
                cur[j - 1] + 1,   # insertion
                prev[j - 1] + cost  # substitution
            )
        prev = cur
    return prev[m]

def normalize_difficulty(level: str) -> str:
    """
    DB records_analysis.difficulty åªæ¥å—:
      primary | secondary | advanced
    å‰ç«¯/ASR å¯èƒ½é€:
      å°å­¸ | ä¸­å­¸ | å¤§å­¸ ä¹‹é¡
    """
    s = (level or "").strip().lower()
    mapping = {
        "å°å­¸": "primary",
        "å°å­¦": "primary",
        "primary": "primary",

        "ä¸­å­¸": "secondary",
        "ä¸­å­¦": "secondary",
        "secondary": "secondary",

        "å¤§å­¸": "advanced",
        "å¤§å­¦": "advanced",
        "advanced": "advanced",
    }
    return mapping.get(s, "primary")

def save_records_analysis_v2(
    user_id: str,
    language: str,          # ä¾‹å¦‚ "Chinese"ï¼ˆä¸è¦ç”¨ "en"ï¼‰
    test_type: str,         # super typeï¼Œä¾‹å¦‚ "Substitution" / "Tone" / "Addition"...
    category: str,          # sub typeï¼Œä¾‹å¦‚ pattern æˆ– bank key
    target_word: str,
    target_ipa: str,
    asr_ipa: str,
    asr_word: str,
    correct_rate,           # int æˆ– str éƒ½å¯ï¼Œæˆ‘æœƒè½‰ str
    check_results: dict,
    difficulty_level: str = "primary",
    score: int | None = None,
    severity: str | None = None,
):
    conn = get_db()
    cur = conn.cursor()
    rid = str(uuid.uuid4())
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    cur.execute("""
        INSERT INTO records_analysis
        (id, user_id, date,
         target_word, target_ipa, asr_ipa, asr_word,
         score, correct_rate, severity, difficulty,
         check_results, language, test_type, category, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (
        rid, user_id, now,
        target_word, target_ipa, asr_ipa, asr_word,
        score,
        str(correct_rate) if correct_rate is not None else None,
        severity,
        normalize_difficulty(difficulty_level),
        json.dumps(check_results, ensure_ascii=False),
        language,
        test_type,
        category,
        now
    ))

    conn.commit()
    conn.close()
    return rid

def climb_and_verify(url: str, keywords: list[str]) -> bool:
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page(ignore_https_errors=True)  # âœ… å¿½ç•¥ SSL å•é¡Œ
        page = browser.new_page()
        page.goto(url, wait_until="domcontentloaded")
        content = page.content()
        browser.close()
        return any(keyword.lower() in content.lower() for keyword in keywords)

router = APIRouter()

@app.on_event("startup")
def init_task_table_safe():
    try:
        ensure_task_table_v2()
        ensure_staff_verify_table()
        ensure_customer_service_tables()
        ensure_tests_table_v2_columns()
        migrate_practice_progress_unique_with_language()
        ensure_practice_progress_table()
        conn = get_db()
        cur = conn.cursor()
        cur.execute("PRAGMA table_info(patients);")
        columns = [r[1] for r in cur.fetchall()]
        if "task_id" not in columns:
            cur.execute("ALTER TABLE patients ADD COLUMN task_id TEXT;")
            conn.commit()
            print("ğŸ§¿ å·²è‡ªå‹•ç‚º patients è¡¨æ–°å¢æ¬„ä½ï¼štask_id")
        conn.close()
    except Exception as e:
        print("âš ï¸ åˆå§‹åŒ–ä»»å‹™è¡¨å¤±æ•—ï¼š", e)

sys.stdout.reconfigure(encoding='utf-8')

TTS_DIR = "tts_audio"
os.makedirs(TTS_DIR, exist_ok=True)

from fastapi.responses import StreamingResponse
import requests

# æ¸¬è©¦é¦–é 
@app.get("/")
async def root():
    return {"message": "Google TTS API is running. Try /google_tts/hello"}

@app.get("/routes")
async def get_routes():
    return [{"path": route.path, "name": route.name, "methods": list(route.methods)} for route in app.routes]
# å¦‚æœç”¨ uvicorn run
# uvicorn this_file_name:app --host 0.0.0.0 --port 8001 --reload
    
class WordRequest(BaseModel):
    errorType: str
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def banks_json_to_error_map(data: dict) -> dict:
    """
    æ”¯æ´æ–°æ ¼å¼ï¼š
      {
        "meta": {...},
        "banks": {
           "<bucket_name>": {"count":..., "items":[{"w":"..."}, ...]},
           ...
        }
      }
    è½‰æˆï¼š
      {"<bucket_name>": ["word1","word2",...], ...}

    ä¹Ÿæ”¯æ´èˆŠæ ¼å¼ï¼š
      {"<bucket_name>": ["word1",...], ...}
    """
    if not isinstance(data, dict):
        return {}

    # NEW format
    if "banks" in data and isinstance(data.get("banks"), dict):
        out = {}
        for bucket, bank in data["banks"].items():
            if not isinstance(bank, dict):
                continue
            items = bank.get("items", [])
            if not isinstance(items, list):
                continue

            words = []
            seen = set()
            for it in items:
                if not isinstance(it, dict):
                    continue
                w = it.get("w")
                if isinstance(w, str):
                    ww = w.strip()
                    if ww and ww not in seen:
                        seen.add(ww)
                        words.append(ww)
            if words:
                out[str(bucket)] = words
        return out

    # OLD format
    out = {}
    for k, v in data.items():
        if isinstance(v, list) and all(isinstance(x, str) for x in v):
            out[str(k)] = v
    return out


def safe_load_json(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        obj = json.load(f)
    if not isinstance(obj, dict):
        raise ValueError(f"{path} is not a JSON object at top-level")
    return obj

# è¼‰å…¥ Substitution.json
substitution_errors = banks_json_to_error_map(safe_load_json("LLM/Substitution.json"))
omission_errors_llm1 = banks_json_to_error_map(safe_load_json("LLM/Omission.json"))
addition_errors = banks_json_to_error_map(safe_load_json("LLM/Addition.json"))

print("DEBUG substitution_errors keys:", list(substitution_errors.keys())[:20])
print("DEBUG omission_errors_llm1 keys:", list(omission_errors_llm1.keys())[:20])
print("DEBUG addition_errors keys:", list(addition_errors.keys())[:20])

with open("LLM1/omission.json", "r", encoding="utf-8") as f:
    omission_errors = json.load(f)

print("DEBUG omission keys:", list(omission_errors.keys()))

with open("LLM1/substitution.json", "r", encoding="utf-8") as f:
    substitution_errors_llm1 = json.load(f)

with open("LLM1/Distortion.json", "r", encoding="utf-8") as f:
    distortion_errors_llm1 = json.load(f)

with open("LLM1/Addition.json", "r", encoding="utf-8") as f:
    Addition_errors_llm1 = json.load(f)
    ADDITION_BANK = Addition_errors_llm1

with open("LLM1/Tone.json", "r", encoding="utf-8") as f:
    Tone_errors_llm1 = json.load(f)

with open("LLM1/VowelFinal.json", "r", encoding="utf-8") as f:
    VowelFinal = json.load(f)

with open("LLM1/InitialConsonant.json", "r", encoding="utf-8") as f:
    InitialConsonant = json.load(f)
# âš ï¸ æ³¨æ„ï¼šé€™è£¡è¦å–è£¡é¢çš„ "AdditionErrors"
slpErrors = {
    **substitution_errors,        # LLM/Substitution.json (banks -> map)
    **omission_errors,            # LLM1/omission.json (çœ‹èµ·ä¾†æ˜¯èˆŠæ ¼å¼ dict)
    **substitution_errors_llm1,   # LLM1/substitution.json
    **addition_errors,            # âœ… é€™è£¡ç›´æ¥åˆä½µæ•´å€‹ mapï¼Œä¸è¦ ["AdditionErrors"]
    **omission_errors_llm1,       # LLM/Omission.json (banks -> map)
    **distortion_errors_llm1,
    **Addition_errors_llm1,
    **Tone_errors_llm1,
    **VowelFinal,
    **InitialConsonant,
}

def get_db():
    conn = sqlite3.connect("asr_llm.db")
    conn.execute("PRAGMA foreign_keys = ON;")
    return conn

# ==============================
# âœ… Tests v2 (plan + progress) Migration & Helpers
# ==============================

def ensure_tests_table_v2_columns():
    # ä½ å·²ç¶“ç”¨ create_db_new.py å»ºå¥½æ–° schemaï¼Œé€™è£¡åªä¿ç•™ indexï¼ˆå¯é¸ï¼‰
    conn = get_db()
    cur = conn.cursor()
    cur.execute("CREATE INDEX IF NOT EXISTS idx_tests_patient_status_time ON tests(patient_id, status, updated_at);")
    conn.commit()
    conn.close()


def build_test_flat_queue(plan: list[dict]) -> list[dict]:
    """
    plan format: [{super_type, sub_type, words:[...]}]
    return flatQueue: [{index, super_type, sub_type, word}]
    """
    flat = []
    idx = 0
    for blk in plan or []:
        st = str(blk.get("super_type", "")).strip()
        sb = str(blk.get("sub_type", "")).strip()
        words = blk.get("words", []) or []
        for w in words:
            ww = str(w).strip()
            if not ww:
                continue
            flat.append({"index": idx, "super_type": st, "sub_type": sb, "word": ww})
            idx += 1
    return flat


def load_test_plan_obj(cur, test_id: str) -> dict:
    cur.execute("SELECT plan FROM tests WHERE id=?", (test_id,))
    row = cur.fetchone()
    if not row or not row[0]:
        return {}
    try:
        obj = json.loads(row[0])
        return obj if isinstance(obj, dict) else {}
    except Exception:
        return {}


def compute_test_progress_cursor(cur, test_id: str) -> int:
    cur.execute("SELECT COUNT(DISTINCT question_index) FROM test_records WHERE test_id=?", (test_id,))
    return int(cur.fetchone()[0] or 0)

# ==============================
# âœ… Customer Service (DB + Helpers)
# ==============================

def compute_priority_by_age_minutes(age_minutes: int) -> int:
    # 0=low, 1=medium, 2=high
    if age_minutes <= 5:
        return 0
    if age_minutes <= 10:
        return 1
    return 2

def refresh_one_session_priority(cur, session_id: str):
    # ç”¨ created_at ç®—ç­‰å¾…åˆ†é˜æ•¸
    cur.execute("""
        SELECT priority,
               CAST((julianday('now') - julianday(created_at)) * 24 * 60 AS INTEGER) AS age_minutes
        FROM service_sessions
        WHERE id=?
    """, (session_id,))
    row = cur.fetchone()
    if not row:
        return

    old_p = int(row[0] or 0)
    age_minutes = int(row[1] or 0)
    new_p = compute_priority_by_age_minutes(age_minutes)

    # åªå‡ä¸é™ï¼ˆé¿å…æ™‚é–“èª¤å·®é€ æˆä¸‹é™ï¼‰
    if new_p > old_p:
        cur.execute("UPDATE service_sessions SET priority=? WHERE id=?", (new_p, session_id))


def ensure_practice_progress_table():
    conn = get_db()
    cur = conn.cursor()

    # å…ˆå»ºç«‹ï¼ˆå…¼å®¹èˆŠ DB æˆ–æ–° DBï¼‰
    cur.execute("""
    CREATE TABLE IF NOT EXISTS practice_progress (
        id TEXT PRIMARY KEY,
        user_id TEXT NOT NULL,
        super_type TEXT NOT NULL,
        sub_type TEXT NOT NULL,
        chunk_size INTEGER NOT NULL DEFAULT 50,
        next_start_index INTEGER NOT NULL DEFAULT 0,
        last_range_end INTEGER NOT NULL DEFAULT 0,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (user_id) REFERENCES patients(id) ON DELETE CASCADE,
        UNIQUE(user_id, super_type, sub_type)
    )
    """)

    # âœ… Migration: è£œ language æ¬„ä½ï¼ˆèˆŠ DB æ²’æœ‰å°±åŠ ï¼‰
    cur.execute("PRAGMA table_info(practice_progress);")
    cols = [r[1] for r in cur.fetchall()]
    if "language" not in cols:
        cur.execute("ALTER TABLE practice_progress ADD COLUMN language TEXT NOT NULL DEFAULT 'en';")
        conn.commit()
        print("ğŸ§¿ practice_progress å·²æ–°å¢æ¬„ä½ï¼šlanguage (default='en')")

    conn.commit()
    conn.close()

def ensure_customer_service_tables():
    conn = get_db()
    cur = conn.cursor()

    # 1) service_sessions
    cur.execute("""
    CREATE TABLE IF NOT EXISTS service_sessions (
        id          TEXT PRIMARY KEY,
        patient_id  TEXT NOT NULL,
        slp_id      TEXT,

        topic       TEXT,
        priority    INTEGER NOT NULL DEFAULT 0,

        status      TEXT NOT NULL DEFAULT 'queued'
                    CHECK(status IN ('queued','assigned','open','closed','cancelled')),

        last_message_at      TIMESTAMP,
        last_slp_activity_at TIMESTAMP,

        created_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        closed_at   TIMESTAMP,
        closed_by   TEXT CHECK(closed_by IN ('patient','slp','system')),

        FOREIGN KEY(patient_id) REFERENCES patients(id) ON DELETE CASCADE,
        FOREIGN KEY(slp_id)     REFERENCES staff_users(id) ON DELETE RESTRICT
    );
    """)

    # 2) service_messages
    cur.execute("""
    CREATE TABLE IF NOT EXISTS service_messages (
        id           TEXT PRIMARY KEY,
        session_id   TEXT NOT NULL,
        sender_type  TEXT NOT NULL CHECK(sender_type IN ('patient','slp','system')),
        sender_id    TEXT,
        message      TEXT NOT NULL,
        message_type TEXT NOT NULL DEFAULT 'text'
                     CHECK(message_type IN ('text','system_event')),
        created_at   TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

        FOREIGN KEY(session_id) REFERENCES service_sessions(id) ON DELETE CASCADE
    );
    """)

    # 3) service_assignments
    cur.execute("""
    CREATE TABLE IF NOT EXISTS service_assignments (
        id TEXT PRIMARY KEY,
        session_id TEXT NOT NULL,
        slp_id TEXT NOT NULL,
        assigned_by TEXT,
        assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        unassigned_at TIMESTAMP,
        reason TEXT,

        FOREIGN KEY(session_id) REFERENCES service_sessions(id) ON DELETE CASCADE,
        FOREIGN KEY(slp_id) REFERENCES staff_users(id) ON DELETE RESTRICT,
        FOREIGN KEY(assigned_by) REFERENCES staff_users(id) ON DELETE SET NULL
    );
    """)

    # 4) audit_logs
    cur.execute("""
    CREATE TABLE IF NOT EXISTS audit_logs (
        id TEXT PRIMARY KEY,
        actor_type TEXT NOT NULL CHECK(actor_type IN ('patient','slp','admin','system')),
        actor_id TEXT,
        action TEXT NOT NULL,
        resource_type TEXT NOT NULL,
        resource_id TEXT,
        reason TEXT,
        metadata TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """)

    # 5) slp_presenceï¼ˆé—œéµï¼šåªæœ‰ is_waiting=1 æ‰å¯è¢« auto allocateï¼‰
    cur.execute("""
    CREATE TABLE IF NOT EXISTS slp_presence (
        slp_id TEXT PRIMARY KEY,
        is_online INTEGER NOT NULL DEFAULT 0 CHECK(is_online IN (0,1)),
        is_waiting INTEGER NOT NULL DEFAULT 0 CHECK(is_waiting IN (0,1)),
        last_seen_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        waiting_since TIMESTAMP,
        FOREIGN KEY(slp_id) REFERENCES staff_users(id) ON DELETE CASCADE
    );
    """)

    # Indexes
    cur.execute("CREATE INDEX IF NOT EXISTS idx_service_sessions_status_created ON service_sessions(status, created_at);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_service_sessions_patient ON service_sessions(patient_id);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_service_sessions_slp ON service_sessions(slp_id);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_service_messages_session_time ON service_messages(session_id, created_at);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_service_assignments_session_time ON service_assignments(session_id, assigned_at);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_slp_presence_waiting ON slp_presence(is_waiting, last_seen_at);")

    conn.commit()
    conn.close()

def audit_log(actor_type, actor_id, action, resource_type, resource_id, reason=None, metadata=None):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO audit_logs
        (id, actor_type, actor_id, action, resource_type, resource_id, reason, metadata)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    """, (str(uuid.uuid4()), actor_type, actor_id, action, resource_type, resource_id, reason, metadata))
    conn.commit()
    conn.close()

def slp_set_online_db(slp_id: str, online: bool):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO slp_presence (slp_id, is_online, is_waiting, last_seen_at, waiting_since)
        VALUES (?, ?, 0, CURRENT_TIMESTAMP, NULL)
        ON CONFLICT(slp_id) DO UPDATE SET
            is_online=excluded.is_online,
            last_seen_at=CURRENT_TIMESTAMP,
            is_waiting=CASE WHEN excluded.is_online=0 THEN 0 ELSE slp_presence.is_waiting END,
            waiting_since=CASE WHEN excluded.is_online=0 THEN NULL ELSE slp_presence.waiting_since END
    """, (slp_id, 1 if online else 0))
    conn.commit()
    conn.close()

def slp_wait_db(slp_id: str, waiting: bool):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO slp_presence (slp_id, is_online, is_waiting, last_seen_at, waiting_since)
        VALUES (?, 1, ?, CURRENT_TIMESTAMP, CASE WHEN ?=1 THEN CURRENT_TIMESTAMP ELSE NULL END)
        ON CONFLICT(slp_id) DO UPDATE SET
            is_online=1,
            is_waiting=?,
            last_seen_at=CURRENT_TIMESTAMP,
            waiting_since=CASE WHEN ?=1 THEN COALESCE(slp_presence.waiting_since, CURRENT_TIMESTAMP) ELSE NULL END
    """, (slp_id, 1 if waiting else 0, 1 if waiting else 0, 1 if waiting else 0, 1 if waiting else 0))
    conn.commit()
    conn.close()

def slp_heartbeat_db(slp_id: str):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("UPDATE slp_presence SET last_seen_at=CURRENT_TIMESTAMP WHERE slp_id=?", (slp_id,))
    conn.commit()
    conn.close()

def pick_waiting_slp_id(cur) -> Optional[str]:
    cur.execute("""
        SELECT slp_id
        FROM slp_presence
        WHERE is_online=1 AND is_waiting=1
          AND last_seen_at >= datetime('now', ?)
        ORDER BY COALESCE(waiting_since, last_seen_at) ASC
        LIMIT 1
    """, (f"-{PRESENCE_TTL_SECONDS} seconds",))
    row = cur.fetchone()
    return row[0] if row else None

def patient_inactive_after_slp_reply(cur, session_id: str, minutes: int) -> bool:
    cur.execute("""
        SELECT
          MAX(CASE WHEN sender_type='patient' THEN created_at END) AS last_patient_at,
          MAX(CASE WHEN sender_type='slp' THEN created_at END)     AS last_slp_at
        FROM service_messages
        WHERE session_id=?
    """, (session_id,))
    row = cur.fetchone()
    last_patient_at, last_slp_at = row[0], row[1]

    # SLP æ²’è¬›éè©±ï¼Œä¸ç®—ç—…äººæ²’å›è¦†
    if not last_slp_at:
        return False

    # ç—…äººæœ€å¾Œè¨Šæ¯æ™‚é–“ >= SLP æœ€å¾Œè¨Šæ¯æ™‚é–“ï¼Œä»£è¡¨ç—…äººå·²å›è¦†ï¼ˆæˆ–æ¯” SLP æ–°ï¼‰ï¼Œä¸å…è¨±ç”¨ã€Œç—…äººé€¾æ™‚ã€é—œå–®
    if last_patient_at and str(last_patient_at) >= str(last_slp_at):
        return False

    # ä»¥ç—…äººæœ€å¾Œè¨Šæ¯ç‚ºåŸºæº–ç®—é€¾æ™‚
    # è‹¥ç—…äººæ²’æœ‰è¨Šæ¯ï¼ˆç†è«–ä¸Šä½ æœ‰ first_messageï¼Œæ‰€ä»¥å¾ˆå°‘ç™¼ç”Ÿï¼‰ï¼Œå‰‡ç”¨ SLP æœ€å¾Œè¨Šæ¯ç®—
    base_time = last_patient_at or last_slp_at

    cur.execute("""
        SELECT CAST((julianday('now') - julianday(?)) * 24 * 60 AS INTEGER)
    """, (base_time,))
    mins = int(cur.fetchone()[0] or 0)

    return mins >= int(minutes)

def system_auto_allocate_one_db() -> Optional[dict]:
    """
    ç³»çµ±æ´¾ 1 å¼µ queued çµ¦ 1 ä½ç­‰å¾…ä¸­çš„ SLP
    - è‹¥æ²’å·¥å–®æˆ–æ²’ waiting SLP => None
    """
    conn = get_db()
    cur = conn.cursor()
    try:
        # æ‰¾æœ€èˆŠ queued
        cur.execute("""
            SELECT id
            FROM service_sessions
            WHERE status='queued'
            ORDER BY created_at ASC
            LIMIT 1
        """)
        sess = cur.fetchone()
        if not sess:
            return None

        slp_id = pick_waiting_slp_id(cur)
        if not slp_id:
            return None

        session_id = sess[0]

        # åŸå­æ›´æ–°ï¼šé¿å…é‡è¤‡æ´¾å–®
        cur.execute("""
            UPDATE service_sessions
            SET slp_id=?, status='assigned'
            WHERE id=? AND status='queued'
        """, (slp_id, session_id))
        if cur.rowcount != 1:
            return None

        # å¯«å…¥ assignment è¨˜éŒ„
        cur.execute("""
            INSERT INTO service_assignments (id, session_id, slp_id, assigned_by, reason)
            VALUES (?, ?, ?, NULL, 'AUTO_ALLOCATE')
        """, (str(uuid.uuid4()), session_id, slp_id))

        # ä¸€æ¬¡æ¥ä¸€å–®ï¼šæ´¾åˆ°å°±é—œæ‰ waitingï¼ˆä½ è‹¥è¦å¤šå–®ï¼ŒæŠŠé€™æ®µç§»é™¤ï¼‰
        cur.execute("""
            UPDATE slp_presence
            SET is_waiting=0, waiting_since=NULL, last_seen_at=CURRENT_TIMESTAMP
            WHERE slp_id=?
        """, (slp_id,))

        conn.commit()

        audit_log("system", None, "AUTO_ALLOCATE", "service_session", session_id,
                  metadata=json.dumps({"slp_id": slp_id}, ensure_ascii=False))

        return {"session_id": session_id, "slp_id": slp_id}
    finally:
        conn.close()

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="auth/login")

def pinyin_to_chinese_diff(asr_pinyin: str, target_pinyin: str, target_word: str) -> str:
    """
    æŠŠ ASR æ‹¼éŸ³å’Œ Target IPA æ¯”å°ï¼š
    - ä¸€æ¨£çš„åœ°æ–¹ç›´æ¥ç”¨ target_word å°æ‡‰å­—
    - ä¸ä¸€æ¨£çš„åœ°æ–¹ï¼Œç”¨æ‹¼éŸ³è½‰æ›æˆè¿‘ä¼¼å­—ï¼ˆå–ç¬¬ä¸€å€‹å€™é¸å­—ï¼‰
    """
    asr_list = asr_pinyin.split()
    tgt_list = target_pinyin.split()
    result_chars = []

    for i, tgt in enumerate(tgt_list):
        if i < len(asr_list):
            asr = asr_list[i]
            if asr == tgt:
                # âœ… å– target_word å°æ‡‰ä½ç½®çš„å­—
                if i < len(target_word):
                    result_chars.append(target_word[i])
                else:
                    result_chars.append("?")
            else:
                # âŒ éŒ¯èª¤éŸ³ç¯€ â†’ å˜—è©¦ç”¨æ‹¼éŸ³è½‰æ¼¢å­—
                # å»æ‰æ•¸å­—è²èª¿ (ma1 -> ma)
                base_pinyin = ''.join([c for c in asr if not c.isdigit()])
                candidates = lazy_pinyin(base_pinyin, style=Style.NORMAL)
                result_chars.append(candidates[0] if candidates else "?")
        else:
            # ç”¨æˆ¶å°‘å¿µäº† â†’ ç©º
            result_chars.append("_")

    return "".join(result_chars)

def load_react_files():
    paths = []
    app_path = os.path.join(FRONTEND_BASE, "App.js")
    if os.path.exists(app_path):
        with open(app_path, "r", encoding="utf-8") as f:
            paths.append(("App.js", f.read()))
    pages_dir = os.path.join(FRONTEND_BASE, "pages")
    for root, dirs, files in os.walk(pages_dir):
        for file in files:
            if file.endswith((".js", ".jsx")):
                full_path = os.path.join(root, file)
                with open(full_path, "r", encoding="utf-8", errors="ignore") as f:
                    paths.append((file, f.read()))
    return paths

def analyze_with_llm(files):
    prompt = "é€™æ˜¯ React å°ˆæ¡ˆçš„ç¨‹å¼ç¢¼ï¼Œè«‹åˆ†æ routes (è·¯å¾‘) èˆ‡å°æ‡‰é é¢ï¼Œä¾‹å¦‚ `/profile â†’ Profile`ã€‚\n\n"
    for filename, content in files:
        prompt += f"\n=== {filename} ===\n{content}\n"
    resp = ollama.chat(
        model="gpt-oss-20b",
        messages=[{"role":"user","content":prompt}],
        options={"num_predict": 800}
    )
    return resp["message"]["content"]

def init_path_knowledge(reset=True):
    files = load_react_files()
    structure = analyze_with_llm(files)
    conn = sqlite3.connect(ROUTE_DB)
    cur = conn.cursor()
    cur.execute("CREATE TABLE IF NOT EXISTS knowledge (id TEXT PRIMARY KEY, content TEXT)")
    if reset:
        cur.execute("DELETE FROM knowledge")
    cur.execute("INSERT INTO knowledge (id, content) VALUES (?, ?)", (str(uuid.uuid4()), structure))
    conn.commit()
    conn.close()
    print("âœ… è·¯å¾‘çµæ§‹çŸ¥è­˜å·²é‡æ–°å»ºç«‹")

def detect_language(text: str):
    chinese_chars = sum(1 for ch in text if '\u4e00' <= ch <= '\u9fff')
    english_chars = sum(1 for ch in text if ch.isalpha())
    if chinese_chars > english_chars:
        return "zh"
    return "en"

def ask_about_route(user_question: str):
    # STEP1 è®€ DB çŸ¥è­˜
    conn = sqlite3.connect(ROUTE_DB)
    cur = conn.cursor()
    cur.execute("SELECT content FROM knowledge LIMIT 1")
    row = cur.fetchone()
    conn.close()

    if not row:
        return "âš ï¸ é‚„æ²’æœ‰è·¯å¾‘çŸ¥è­˜ï¼Œè«‹å…ˆå•Ÿå‹•ä¼ºæœå™¨å»ºç«‹"

    structure = row[0]
    lang = detect_language(user_question)

    # ç³»çµ±æŒ‡ä»¤
    role_instruction = (
        "ä½ æ˜¯ä¸€å€‹ç¶²ç«™å°èˆªåŠ©ç†ï¼Œä½ éœ€è¦å¹«åŠ©ä½¿ç”¨è€…æ“ä½œé€™å€‹ç¶²ç«™ï¼šhttps://203.176.209.165:8443/ ã€‚è«‹ç”¨ç°¡å–®ä¸­æ–‡åˆ†æ­¥é©Ÿå‘Šè¨´ç”¨æˆ¶è¦æ€éº¼é»æ“Šæ‰èƒ½åˆ°é”ç›®æ¨™é é¢ã€‚"
        if lang == "zh" else 
        "You are a website navigation assistant. Your task is to guide users on this website: https://203.176.209.165:8443/ . Please reply in simple English with clear stepâ€‘byâ€‘step navigation instructions."
    )

    # STEP2ï¼šLLM æ‰¾å€™é¸ path
    prompt = f"""
å·²çŸ¥ React å°ˆæ¡ˆçš„è·¯å¾‘çµæ§‹ï¼š

{structure}

ä½¿ç”¨è€…å•é¡Œï¼š{user_question}

è«‹åªå›è¦†æœ€å¯èƒ½çš„ path (ä¾‹å¦‚ `/settings/password`)ï¼Œä¸è¦åŠ å¤šé¤˜è§£é‡‹ã€‚
"""
    resp = ollama.chat(
        model="gpt-oss-20b",
        messages=[
            {"role": "system", "content": role_instruction},
            {"role": "user", "content": prompt},
        ],
        options={"num_predict": 200},
    )
    candidate_path = resp["message"]["content"].strip()

    # STEP3ï¼šåŒ…è£æˆã€Œæ“ä½œæŒ‡å¼•ã€
    if candidate_path.startswith("/"):
        full_url = f"{FRONTEND_URL}{candidate_path}"

        # ç°¡å–®é©—è­‰é é¢æ˜¯å¦å­˜åœ¨
        if climb_and_verify(full_url, ["å¯†ç¢¼", "password", "ä¿®æ”¹", "è¨­å®š", "change"]):
            if lang == "zh":
                return f"âœ… è«‹æ‰“é–‹ç¶²ç«™é¸å–®ï¼Œæ‰¾åˆ°ã€{candidate_path}ã€‘é é¢ï¼Œé»æ“Šå³å¯é€²å…¥ä¸¦æ“ä½œã€‚"
            else:
                return f"âœ… Please open the website menu, find **{candidate_path}**, and click it to access the page."
        else:
            if lang == "zh":
                return f"âš ï¸ æ‰¾åˆ°äº† {candidate_path}ï¼Œä½†æª¢æŸ¥å¾Œä¼¼ä¹æ²’æœ‰ç›¸é—œåŠŸèƒ½ã€‚"
            else:
                return f"âš ï¸ Found {candidate_path}, but no related function was detected."

    # STEP4ï¼šfallback å¸¸è¦‹é é¢
    fallback_paths = ["/settings", "/account", "/profile", "/user", "/config"]
    for path in fallback_paths:
        full_url = f"{FRONTEND_URL}{path}"
        if climb_and_verify(full_url, ["å¯†ç¢¼", "password", "ä¿®æ”¹", "è¨­å®š", "change"]):
            if lang == "zh":
                return f"âœ… é›–ç„¶æ²’æœ‰æ‰¾åˆ°ç²¾æº–é é¢ï¼Œä½†è«‹å˜—è©¦é»æ“Šç¶²ç«™é¸å–®ä¸­çš„ã€{path}ã€‘ï¼Œæ‡‰è©²èƒ½é€²è¡Œç›¸é—œæ“ä½œã€‚"
            else:
                return f"âœ… The system did not return an exact page, but please try clicking **{path}** in the menu to perform the action."

    # STEP5ï¼šå®Œå…¨æ²’æ‰¾åˆ°
    return "âŒ ç³»çµ±ä¸­æ²’æœ‰æ‰¾åˆ°ç¬¦åˆçš„é é¢" if lang == "zh" else "âŒ No matching page found in the system."

def get_current_username_from_db(token: str = Depends(oauth2_scheme)):
    """
    é€é token.sub (user_id) å¾ patients è³‡æ–™è¡¨æŸ¥ username
    """
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid token")

        conn = get_db()
        cur = conn.cursor()
        cur.execute("SELECT username FROM patients WHERE id=?", (user_id,))
        row = cur.fetchone()
        conn.close()

        if not row:
            raise HTTPException(status_code=401, detail="User not found in DB")

        return row[0]  # çœŸæ­£çš„ username
    except JWTError:
        raise HTTPException(status_code=401, detail="Token expired or invalid")

# â‹ å°è£é©—è­‰å‡½æ•¸
def get_current_user_id(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid token")
        return user_id
    except JWTError:
        raise HTTPException(status_code=401, detail="Token expired or invalid")

class UpdateMeRequest(BaseModel):
    name: Optional[str] = None
    age: Optional[int] = None
    diagnosis: Optional[str] = None
    email: Optional[str] = None
    language: Optional[str] = None

    old_password: Optional[str] = None
    new_password: Optional[str] = None

    @validator("age", pre=True)
    def parse_age(cls, v):
        # å®¹éŒ¯ï¼šå…è¨±å‰ç«¯é€ "20" / "" / None
        if v is None:
            return None
        if isinstance(v, str):
            vv = v.strip()
            if vv == "":
                return None
            if vv.isdigit():
                return int(vv)
        return v


@app.post("/api/patient/update-me")
def update_me(
    data: UpdateMeRequest,
    current_user_id: str = Depends(get_current_user_id),
):
    """
    âœ… åªç”¨ token(sub=user_id) æ›´æ–°è‡ªå·±è³‡æ–™ï¼Œä¸éœ€è¦ username
    - æ”¹å¯†ç¢¼æ‰éœ€è¦ old_password + new_password
    - æ”¹ email æ™‚è‡ªå‹•æŠŠ verify è¨­ç‚º 0ï¼ˆé‡æ–°é©—è­‰ï¼‰
    """
    conn = get_db()
    cur = conn.cursor()

    cur.execute("SELECT password_hash FROM patients WHERE id=?", (current_user_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")
    stored_hash = row[0]

    updates = []
    params = []

    if data.name is not None:
        updates.append("name=?")
        params.append(data.name)

    if data.age is not None:
        updates.append("age=?")
        params.append(data.age)

    if data.diagnosis is not None:
        updates.append("diagnosis=?")
        params.append(data.diagnosis)

    if data.language is not None:
        updates.append("language=?")
        params.append(data.language)

    if data.email is not None:
        updates.append("email=?")
        params.append(data.email)

        # email æ”¹äº† => é‡æ–°é©—è­‰
        updates.append("verify=?")
        params.append(0)

    # æ”¹å¯†ç¢¼ï¼ˆåªæœ‰é€™å€‹éœ€è¦é©— old_passwordï¼‰
    if data.new_password:
        if not data.old_password or not verify_password(data.old_password, stored_hash):
            conn.close()
            raise HTTPException(status_code=400, detail="Old password incorrect")
        updates.append("password_hash=?")
        params.append(hash_password(data.new_password))

    if not updates:
        conn.close()
        return {"msg": "No fields updated"}

    sql = f"UPDATE patients SET {', '.join(updates)} WHERE id=?"
    params.append(current_user_id)
    cur.execute(sql, tuple(params))
    conn.commit()

    cur.execute("""
        SELECT id, username, name, age, diagnosis, email, language, integral, verify, user_picture
        FROM patients WHERE id=?
    """, (current_user_id,))
    user_row = cur.fetchone()
    conn.close()

    return {
        "msg": "Profile updated successfully",
        "user": {
            "id": user_row[0],
            "username": user_row[1],
            "name": user_row[2],
            "age": user_row[3],
            "diagnosis": user_row[4],
            "email": user_row[5],
            "language": user_row[6],
            "integral": user_row[7],
            "verify": user_row[8],
            "user_picture": user_row[9],
        }
    }

def hash_password(password: str) -> str:
    pw = password.encode("utf-8")
    salt = pybcrypt.gensalt(rounds=12)
    return pybcrypt.hashpw(pw, salt).decode("utf-8")

def verify_password(password: str, hashed: str) -> bool:
    return pybcrypt.checkpw(password.encode("utf-8"), hashed.encode("utf-8"))

from English_US.asr_llm_server import (
    load_and_denoise,
    recognize_word,
    normalize_ipa,
    pronunciation_dict,
)
from English_US.asr_llm_server import word_to_ipa_or_star

UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

class DBConnections:
    def __init__(self):
        self.db1 = sqlite3.connect("asr_llm.db")
        self.db2 = sqlite3.connect("asr_llm.db")

    def close(self):
        self.db1.close()
        self.db2.close()

@app.get("/api/checkin/history")
def get_checkin_history(current_user_id: str = Depends(get_current_user_id)):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT date FROM checkins WHERE user_id=? ORDER BY date", (current_user_id,))
    rows = cur.fetchall()
    history = [r[0] for r in rows]

    today = datetime.now().strftime("%Y-%m-%d")
    todayCheckedIn = today in history

    # ğŸ”¥ è¨ˆç®—é€£çºŒå¤©æ•¸
    streak = 0
    for d in reversed(history):
        if d == (datetime.now().date() - timedelta(days=streak)).strftime("%Y-%m-%d"):
            streak += 1
        else:
            break
    print("DEBUG history for user:", current_user_id, history)        
    conn.close()
    return {"history": history, "streak": streak, "todayCheckedIn": todayCheckedIn}

# -------------------------------
# ğŸ“Œ ç°½åˆ°
# -------------------------------
@app.post("/api/checkin")
def checkin(current_user_id: str = Depends(get_current_user_id)):
    conn = get_db()
    cur = conn.cursor()
    today = datetime.now().strftime("%Y-%m-%d")

    # å…ˆæª¢æŸ¥ä»Šå¤©æ˜¯å¦å·²ç°½åˆ°
    cur.execute("SELECT 1 FROM checkins WHERE user_id=? AND date=?", (current_user_id, today))
    already = cur.fetchone() is not None

    if not already:
        # 1) å¯«å…¥ç°½åˆ°ç´€éŒ„
        cur.execute(
            "INSERT INTO checkins (id, user_id, date) VALUES (?, ?, ?)",
            (str(uuid.uuid4()), current_user_id, today)
        )

        # 2) âœ… åŠ  10 åˆ†ï¼ˆåªåœ¨é¦–æ¬¡ç°½åˆ°æ‰åŠ ï¼‰
        cur.execute(
            "UPDATE patients SET integral = COALESCE(integral, 0) + 10 WHERE id=?",
            (current_user_id,)
        )

        conn.commit()

    # æŸ¥è¿”æœ€æ–°ç´€éŒ„
    cur.execute("SELECT date FROM checkins WHERE user_id=? ORDER BY date", (current_user_id,))
    rows = cur.fetchall()
    history = [r[0] for r in rows]

    todayCheckedIn = today in history

    # è¨ˆç®—é€£çºŒå¤©æ•¸
    streak = 0
    for d in reversed(history):
        if d == (datetime.now().date() - timedelta(days=streak)).strftime("%Y-%m-%d"):
            streak += 1
        else:
            break

    conn.close()
    return {
        "history": history,
        "streak": streak,
        "todayCheckedIn": todayCheckedIn,
        "added_integral": 10 if not already else 0   # âœ… å¯é¸ï¼šå›å‚³é€™æ¬¡åŠ äº†å¹¾åˆ†
    }

@app.get("/db-test")
def db_test():
    dbs = DBConnections()
    cur1 = dbs.db1.cursor()
    cur2 = dbs.db2.cursor()

    cur1.execute("SELECT COUNT(*) FROM patients")
    cur2.execute("SELECT COUNT(*) FROM patients")

    r1 = cur1.fetchone()[0]
    r2 = cur2.fetchone()[0]

    dbs.close()
    return {"asr_llm.db patients": r1, "asr_llm.db patients": r2}

@app.delete("/auth/delete")
def delete_account(username: str = Query(...)):
    conn = get_db()
    cur = conn.cursor()

    # æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦å­˜åœ¨
    cur.execute("SELECT id FROM patients WHERE username=?", (username,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")
    patient_id = row[0]

    # åˆªæ‰ attempts â†’ sessions â†’ patient
    cur.execute("DELETE FROM attempts WHERE session_id IN (SELECT id FROM sessions WHERE patient_id=?)", (patient_id,))
    cur.execute("DELETE FROM sessions WHERE patient_id=?", (patient_id,))
    cur.execute("DELETE FROM patients WHERE id=?", (patient_id,))

    conn.commit()
    conn.close()

    return {"msg": f"Account {username} deleted successfully"}
    

from sqlite3 import Row  # å¯é¸

@app.get("/auth/me_llm1")
def get_user_llm1(username: str = Query(..., alias="username")):
    token = username
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid token")
    except JWTError:
        raise HTTPException(status_code=401, detail="Token expired or invalid")

    conn = get_db()
    # âœ… ä»¤ fetch åˆ°å˜… row å¯ä»¥ç”¨æ¬„åè½‰ dict
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()

    cur.execute("""
        SELECT *
        FROM records_analysis
        WHERE user_id = ?
        ORDER BY created_at DESC
    """, (user_id,))
    rows = cur.fetchall()
    conn.close()

    # âœ… å°‡æ¯ç­† Row è½‰æˆ dictï¼ˆåŒ…å« records_analysis å…¨éƒ¨æ¬„ä½ï¼‰
    records = [dict(r) for r in rows]

    return {"records": records}

def calc_correct_rate(asr: str, target: str) -> int:
    a = [x for x in (asr or "").strip().split() if x]
    b = [x for x in (target or "").strip().split() if x]
    if not a or not b:
        return 0
    dist = levenshtein_distance(a, b)
    max_len = max(len(a), len(b))
    return round(((max_len - dist) / max_len) * 100) if max_len > 0 else 0
#---------TTS web--------#

@app.get("/google_tts/{word}")
async def google_tts(word: str):
    """
    Google TTS for English words (path parameter)
    """
    try:
        tts_url = "https://translate.google.com/translate_tts"
        lang = "en"

        encoded_word = urllib.parse.quote(word, safe="")
        full_url = f"{tts_url}?ie=UTF-8&q={encoded_word}&tl={lang}&client=gtx"

        headers = {
            "User-Agent": "Mozilla/5.0",
            "Accept": "*/*",
            "Referer": "https://translate.google.com/",
            "Range": "bytes=0-",
        }

        r = requests.get(full_url, headers=headers, stream=True, allow_redirects=True)

        if r.status_code not in (200, 206):
            raise HTTPException(status_code=500, detail=f"Google TTS failed: {r.status_code}")

        if "audio" not in r.headers.get("Content-Type", ""):
            raise HTTPException(status_code=500, detail="Google TTS did not return audio")

        return StreamingResponse(
            r.iter_content(chunk_size=1024),
            media_type="audio/mpeg",
            headers={"Content-Disposition": f'inline; filename="{word}.mp3"'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"TTS error: {str(e)}")
    

@app.get("/google_tts_ch")
async def google_tts_ch(word: str = Query(..., description="å¿…é ˆæ˜¯ä¸­æ–‡è©èª")):
    """
    ä½¿ç”¨ Google Translate TTS endpoint ä»£ç†ï¼Œç›´æ¥å›å‚³ MP3
    """
    url = "https://translate.google.com/translate_tts"
    params = {
        "ie": "UTF-8",
        "tl": "zh-CN",   # ä¸­æ–‡
        "client": "tw-ob",
        "q": word,
    }
    headers = {"User-Agent": "Mozilla/5.0"}

    r = requests.get(url, params=params, headers=headers)
    if r.status_code != 200:
        return {"status": r.status_code, "error": "Google TTS request failed"}

    return StreamingResponse(io.BytesIO(r.content),
        media_type="audio/mpeg",
        headers={"Content-Disposition": 'inline; filename="audio.mp3"'}
    )

#---------TTS web--------#

#------Cet word from LLM1 Chinese -----#
@app.get("/get_word_from_tone")
async def get_word_from_tone(errorType: str = Query(..., description="Tone error type")):
    """
    å¾ Tone.json æ ¹æ“š errorType æŠ½ä¸€å€‹è©å›å‚³
    """
    with open("LLM1/Tone.json", "r", encoding="utf-8") as f:
        tone_errors = json.load(f)

    if not errorType or errorType not in tone_errors:
        raise HTTPException(status_code=400, detail="Invalid errorType")

    word = random.choice(tone_errors[errorType])
    return {"word": word}

@app.get("/get_word_from_addition")
async def get_word_from_addition(errorType: str = Query(..., description="Addition error type")):
    """
    å¾ Addition.json æ ¹æ“š errorType æŠ½ä¸€å€‹è©å›å‚³
    - errorType: "å£°æ¯æ·»åŠ " / "éŸµæ¯æ·»åŠ " / "éŸµå°¾æ·»åŠ " / "æ’éŸ³"
    """
    if not errorType or errorType not in Addition_errors_llm1:
        raise HTTPException(status_code=400, detail="Invalid errorType")

    word = random.choice(Addition_errors_llm1[errorType])
    return {"word": word}


@app.get("/get_word_from_distortion")
async def get_word_from_distortion(errorType: str = Query(..., description="Distortion error type")):
    """
    å¾ Distortion.json æ ¹æ“š errorType æŠ½ä¸€å€‹è©å›å‚³
    """
    if not errorType or errorType not in distortion_errors_llm1:
        raise HTTPException(status_code=400, detail="Invalid errorType")

    word = random.choice(distortion_errors_llm1[errorType])
    return {"word": word}

@app.get("/get_word_from_omission")
async def get_word_from_omission(errorType: str = Query(..., description="Omission error type")):
    if not errorType or errorType not in omission_errors:
        raise HTTPException(status_code=400, detail="Invalid errorType")

    word = random.choice(omission_errors[errorType])
    return {"word": word}


class VerifyCodeRequest(BaseModel):
    username: str
    code: str

@app.post("/auth/verify-code")
def verify_user_code(data: VerifyCodeRequest):
    """
    æ”¯æ´ä½¿ç”¨è€…è¼¸å…¥ username æˆ– email é©—è­‰å¸³è™Ÿï¼Œ
    æ¯”å°é©—è­‰ç¢¼å¾Œè¨­å®š verify=1ã€‚
    """
    conn = get_db()
    cur = conn.cursor()

    # 1ï¸âƒ£ å˜—è©¦æ‰¾åˆ°åŒ¹é…çš„é©—è­‰ç¢¼ç´€éŒ„
    cur.execute("""
        SELECT code, username
        FROM email_verifies
        WHERE username = ?
           OR username IN (SELECT username FROM patients WHERE email = ?)
    """, (data.username, data.username))
    row = cur.fetchone()

    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="Verification code not found")

    db_code, username = row

    if str(data.code).strip() != str(db_code).strip():
        conn.close()
        raise HTTPException(status_code=400, detail="Incorrect verification code")

    # 2ï¸âƒ£ æ›´æ–°ï¼Œè‹¥ username å°ä¸åˆ°ï¼Œç”¨ email ä¹Ÿå˜—è©¦ä¸€æ¬¡
    cur.execute("""
        UPDATE patients
        SET verify = 1
        WHERE username = ? OR email = ?
    """, (username, data.username))
    conn.commit()

    # 3ï¸âƒ£ é©—è­‰ç¢ºå¯¦å¯«å…¥
    cur.execute("SELECT verify FROM patients WHERE username = ? OR email = ?", (username, data.username))
    v = cur.fetchone()

    if not v or int(v[0]) != 1:
        conn.close()
        raise HTTPException(status_code=500, detail="âš ï¸ verify æ¬„ä½æœªæ›´æ–°ï¼Œè«‹ç¢ºèªå¸³è™ŸåŒ¹é…")

    # 4ï¸âƒ£ æˆåŠŸå¾Œåˆªé™¤é©—è­‰ç¢¼
    cur.execute("DELETE FROM email_verifies WHERE username = ?", (username,))
    conn.commit()
    conn.close()

    return {"msg": "âœ… é©—è­‰æˆåŠŸï¼Œå¸³è™Ÿå·²å•Ÿç”¨ï¼"}

# -----------------------------
# API: å–å¾—ä¸€å€‹éŸ»æ¯éŒ¯èª¤è©
# -----------------------------
@app.get("/get_word_from_vowel_final")
async def get_word_from_vowel_final(errorType: str):
    """
    å¾ VowelFinal.json éš¨æ©ŸæŠ½å–ä¸€å€‹è©
    errorType å¿…é ˆæ˜¯ VowelFinal.json è£¡çš„ key (å–®å…ƒéŸ³æ›¿ä»£ / è¤‡åˆéŸ»æ¯éŒ¯èª¤)
    """
    try:
        if errorType not in VowelFinal:
            return JSONResponse(
                status_code=400,
                content={"detail": f"æœªçŸ¥çš„éŸ»æ¯éŒ¯èª¤é¡å‹: {errorType}"}
            )

        word = random.choice(VowelFinal[errorType])
        return {"word": word}

    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"detail": f"å–è©å¤±æ•—: {str(e)}"}
        )

#------Cet word from LLM1 -----#

#------Chinese-----#

def save_analysis_record(
    user_id: str,
    language: str,
    target_word: str,
    target_ipa: str,
    asr_ipa: str,
    asr_word: str,
    correct_rate: int,
    difficulty: str,
    check_results: dict,
    test_type: str,
    category: Optional[str] = None,
    score: Optional[int] = None,
):
    conn = get_db()
    cur = conn.cursor()
    now = datetime.now()
    record_id = str(uuid.uuid4())

    cur.execute("""
        INSERT INTO records_analysis (
            id, user_id, date,
            target_word, target_ipa, asr_ipa, asr_word,
            score, correct_rate, difficulty, check_results,
            language, test_type, category, created_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (
        record_id,
        user_id,
        now.strftime("%Y-%m-%d %H:%M:%S"),
        target_word,
        target_ipa,
        asr_ipa,
        asr_word,
        score,
        correct_rate,
        difficulty,
        json.dumps(check_results, ensure_ascii=False),
        language,
        test_type,
        category,
        now.strftime("%Y-%m-%d %H:%M:%S"),
    ))

    conn.commit()
    conn.close()
    
def to_py_bool(x):
    try:
        import torch
        if isinstance(x, torch.Tensor):
            # 0-d or 1 element -> item; multi-element -> any
            return bool(x.item()) if x.numel() == 1 else bool(x.any().item())
    except Exception:
        pass

    try:
        import numpy as np
        if isinstance(x, np.ndarray):
            return bool(x.item()) if x.size == 1 else bool(x.any())
    except Exception:
        pass

    return bool(x)

def pinyin_syllable_list(s: str) -> list[str]:
    # reuse your normalize_pinyin_list if you like
    s = (s or "").strip().lower().replace("/", "")
    s = re.sub(r"\s+", " ", s).strip()
    return s.split() if s else []

def normalize_bool(x):
    return bool(x)

SUPER_TYPE_TO_DETECTORS = {
    # ä½ å‰ç«¯ category å‚³å…¥å˜… super type
    "Substitution": ["substitution"],
    "Omission": ["omission"],
    "Addition": ["addition"],
    "Tone": ["tone"],
    "Distortion": ["distortion"],
    "InitialConsonant": ["initial"],
    "VowelFinal": ["vowel_final"],
    "Pinyin": ["tone"],  # ä¾‹ï¼šä½  PinyinPractice å¯èƒ½æƒ³ tone åšä¸»
}

def severity_from_subtype_num(n: int | None):
    if not n or n <= 0:
        return None
    if n == 1:
        return "slight"
    if n in (2, 3):
        return "medium"
    return "high"   # >=4


@app.post("/analyze_substitution")
async def analyze_substitution(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    username: str = Form("guest"),
    subtype: int = Form(0),  # legacy; ignored
    category: str = Form("Substitution"),
    pattern: str = Form("Substitution_initial_consonant"),
    checks: str = Form(""),  # legacy; ignored (substitution-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… Substitution-only (script) version (aligned with /analyze_addition)

    - Only run Substitution detector (rule-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type (subtype): å£°æ¯æ›¿ä»£ | éŸµæ¯æ›¿ä»£ | å£°è°ƒæ›¿ä»£ (only if slp)
      severity: slight | middle | high              (only if slp)

    - Still compute:
        correct_rate (0~100)
        score (0~10) = round(correct_rate / 10)

    - status:
        correct if IPA exactly matches; else wrong
        (same as addition endpoint)
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 3) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)   # 0~100
        score_points = int(round(correct_rate / 10))            # 0~10

        # -----------------------------
        # 4) meta off_target
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 5) Substitution detector only (script-based)
        # -----------------------------
        sub_res = detect_substitution_error_1(
            target_word,
            asr_ipa,
            llm=None,                 # âœ… disable LLM explicitly
            off_target=off,           # âœ… let detector gate
            correct_rate=correct_rate,
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["substitution"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "substitution": sub_res,
        }

        # -----------------------------
        # 6) status (substitution-only)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 7) severity (only when slp)
        # -----------------------------
        sub_final = str((sub_res or {}).get("final_label") or "").strip().lower()
        severity_value = (sub_res or {}).get("severity") if sub_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None

        # -----------------------------
        # 8) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 9) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 10) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,
            "patient_explain": (
                (check_results.get("substitution") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Substitution analysis failed: {str(e)}")

# -----------------------------
# API: åˆ†æéŸ»æ¯éŒ¯èª¤
# -----------------------------
@app.post("/analyze_vowel_final")
async def analyze_vowelfinal(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    subtype: int = Form(0),          # legacy; ignored (match Addition behavior)
    username: str = Form("guest"),
    category: str = Form("VowelFinal"),
    pattern: str = Form("VowelFinal_error"),
    checks: str = Form(""),          # legacy; ignored (vowel-final-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… VowelFinal-only (script) version â€” aligned to /analyze_addition & /analyze_tone & /analyze_omission

    - Only run VowelFinal detector (rule-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type (subtype): å•å…ƒéŸ³æ›¿ä»£ | å¤åˆéŸµæ¯é”™è¯¯ | éŸµæ¯æ›¿ä»£(å¯é€‰fallback) (only if slp)
      severity: slight | middle | high                               (only if slp)

    - Still compute:
        correct_rate (accuracy, 0~100)
        score (0~10) = round(correct_rate / 10)

    - status:
        correct if asr_ipa == target_ipa
        wrong   otherwise
.

    - severity:
        only from vowel_final.severity AND only when final_label == slp
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        # -----------------------------
        # 3) results
        # -----------------------------
        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 4) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)  # 0~100
        score_points = int(round(correct_rate / 10))           # 0~10

        # -----------------------------
        # 5) meta off_target (still useful)
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 6) VowelFinal detector only (script-based)
        # IMPORTANT: detect_vowelfinal_error must return Addition-style fields:
        # final_label + severity (canonical) + type etc.
        # -----------------------------
        vf_res = detect_vowelfinal_error(
            target_word,
            asr_ipa,
            llm=None,                 # âœ… disable LLM explicitly
            off_target=off,           # âœ… pass off_target
            correct_rate=correct_rate # âœ… pass correct_rate
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["vowel_final"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "vowel_final": vf_res,
        }

        # -----------------------------
        # 7) status (match Addition endpoint)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 8) severity (only when slp)
        # -----------------------------
        vf_final = str((vf_res or {}).get("final_label") or "").strip().lower()
        severity_value = (vf_res or {}).get("severity") if vf_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None

        # -----------------------------
        # 9) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 10) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 11) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,

            # Prefer vowel_final.patient_explain if present (same pattern as Addition/Tone/Omission)
            "patient_explain": (
                (check_results.get("vowel_final") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"VowelFinal analysis failed: {str(e)}")
    
# ------------------------------
# API: åˆ†æ InitialConsonant éŒ¯èª¤
# ------------------------------
from fastapi import UploadFile, File, Form, Depends, HTTPException
from fastapi.responses import JSONResponse

def _pinyin_syllable_list(s: str) -> list[str]:
    s = (s or "").strip().lower().replace("/", "")
    s = re.sub(r"\s+", " ", s).strip()
    return s.split() if s else []

def compute_off_target(target_ipa: str, asr_ipa: str) -> dict:
    tgt = _pinyin_syllable_list(target_ipa)
    asr = _pinyin_syllable_list(asr_ipa)
    cr = calc_correct_rate(asr_ipa, target_ipa)

    # ä½ å¯æŒ‰å¯¦æ¸¬èª¿æ•´
    is_off = (cr <= 30 and abs(len(tgt) - len(asr)) >= 1) or (cr == 0)

    return {
        "is_off_target": bool(is_off),
        "correct_rate": cr,
        "target_syllables": len(tgt),
        "asr_syllables": len(asr),
        "syllable_gap": abs(len(tgt) - len(asr)),
    }

# --- EDITED: InitialConsonant endpoint to match Addition process ---
# Key changes vs your current InitialConsonant:
# 1) Run InitialConsonant detector ONLY (like Addition runs addition-only)
# 2) status based on IPA match (same as Addition), NOT "any error or off_target"
# 3) severity ONLY when detector final_label == "slp" (same as Addition)
# 4) subtype Form(...) is treated as legacy/ignored (same as Addition)
# 5) check_results.meta.enabled_checks == ["initial"]

@app.post("/analyze_initial_consonant")
async def analyze_initial_consonant(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    username: str = Form("guest"),
    subtype: int = Form(0),  # legacy; ignored (match Addition behavior)
    category: str = Form("InitialConsonant"),
    pattern: str = Form("InitialConsonant_error"),
    checks: str = Form(""),  # legacy; ignored (initial-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… InitialConsonant-only (script) version â€” aligned to /analyze_addition

    - Only run InitialConsonant detector (rule-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type (subtype): e.g. å£°æ¯çœç•¥ | å£°æ¯æ·»åŠ  | å‘éŸ³éƒ¨ä½é”™è¯¯ | å£°æ¯æ›¿ä»£  (only if slp)
      severity: slight | middle | high                                 (only if slp)

    - Still compute:
        correct_rate (accuracy, 0~100)
        score (0~10) = round(correct_rate / 10)

    - status:
        correct if asr_ipa == target_ipa
        wrong   otherwise

    - severity:
        only from initial.severity AND only when final_label == slp
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        # -----------------------------
        # 3) results
        # -----------------------------
        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 4) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)  # 0~100
        score_points = int(round(correct_rate / 10))           # 0~10

        # -----------------------------
        # 5) meta off_target (still useful)
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 6) InitialConsonant detector only (script-based)
        # IMPORTANT: this requires your detect_initial_consonant_error
        # to return a dict that includes final_label + severity like Addition does.
        # If your current detect_initial_consonant_error does NOT provide these fields,
        # see the notes below ("What may be different vs Addition").
        # -----------------------------
        init_res = detect_initial_consonant_error(
            target_word,
            asr_ipa,
            llm=None,          # âœ… disable LLM explicitly (if supported)
            off_target=off,    # âœ… pass off_target (if supported)
            correct_rate=correct_rate,  # âœ… pass correct_rate (if supported)
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["initial"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "initial": init_res,
        }

        # -----------------------------
        # 7) status (match Addition)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 8) severity (only when slp)
        # -----------------------------
        init_res = check_results.get("initial") or {}
        init_final = str(init_res.get("final_label") or "").strip().lower()

        severity_value = init_res.get("severity", None) if init_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None

        # -----------------------------
        # 9) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 10) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 11) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,

            # Prefer initial.patient_explain if present (same pattern as Addition)
            "patient_explain": (
                (check_results.get("initial") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"InitialConsonant analysis failed: {str(e)}")


# ------------------------------
# Addition API
# ------------------------------
@app.post("/analyze_addition")
async def analyze_addition(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    username: str = Form("guest"),
    subtype: int = Form(0),  # legacy; ignored
    category: str = Form("Addition"),
    pattern: str = Form("Addition_error"),
    checks: str = Form(""),  # legacy; ignored (addition-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… Addition-only (script) version

    - Only run Addition detector (rule-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type (subtype): å£°æ¯æ·»åŠ  | éŸµæ¯æ·»åŠ  | éŸµå°¾æ·»åŠ  | æ’éŸ³  (only if slp)
      severity: slight | middle | high                 (only if slp)

    - Still compute:
        correct_rate (accuracy, 0~100)
        score (0~10) = round(correct_rate / 10)

    - status:
        wrong if addition.final_label in {slp, äº‚ç­”}
        correct if addition.final_label == no_problem

    - severity:
        only from addition.severity AND only when final_label == slp
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        # -----------------------------
        # 3) results
        # -----------------------------
        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 4) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)     # âœ… accuracy (0~100)
        score_points = int(round(correct_rate / 10))              # âœ… 0~10

        # -----------------------------
        # 5) meta off_target (still useful)
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 6) Addition detector only (script-based)
        # -----------------------------
        add_res = detect_addition_error_1(
            target_word,
            asr_ipa,
            llm=None,                 # âœ… disable LLM explicitly
            off_target=off,
            correct_rate=correct_rate,
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["addition"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "addition": add_res,
        }

        # -----------------------------
        # 7) status (addition-only)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 8) severity (only when slp)
        # -----------------------------
        add_res = check_results.get("addition") or {}
        add_final = str(add_res.get("final_label") or "").strip().lower()

        severity_value = add_res.get("severity", None) if add_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None


        # -----------------------------
        # 9) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 10) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 11) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,          # âœ… accuracy
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,

            # Prefer addition.patient_explain if present
            "patient_explain": (
                (check_results.get("addition") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Addition analysis failed: {str(e)}")

# ------------------------------
# Omission API
# ------------------------------
@app.post("/analyze_omission")
async def analyze_omission(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    username: str = Form("guest"),
    subtype: int = Form(0),  # legacy; ignored (match Addition behavior)
    category: str = Form("Omission"),
    pattern: str = Form("Omission_error"),
    checks: str = Form(""),  # legacy; ignored (omission-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… Omission-only (script) version â€” aligned to /analyze_addition

    - Only run Omission detector (rule-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type (subtype): å£°æ¯è„±è½ | éŸµæ¯è„±è½ | éŸµå°¾è„±è½ | å£°è°ƒè„±è½ (only if slp)
      severity: slight | middle | high                                 (only if slp)

    - Still compute:
        correct_rate (accuracy, 0~100)
        score (0~10) = round(correct_rate / 10)

    - status:
        (match current addition endpoint implementation)
        correct if asr_ipa == target_ipa
        wrong   otherwise

    - severity:
        only from omission.severity AND only when final_label == slp
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        # -----------------------------
        # 3) results
        # -----------------------------
        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 4) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)  # 0~100
        score_points = int(round(correct_rate / 10))           # 0~10

        # -----------------------------
        # 5) meta off_target (still useful)
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 6) Omission detector only (script-based)
        # IMPORTANT: detect_omission_error must return Addition-style fields:
        # final_label + severity (canonical) + type (subtype) etc.
        # -----------------------------
        omit_res = detect_omission_error_1(
            target_word,
            asr_ipa,
            llm=None,                 # âœ… disable LLM explicitly (if supported)
            off_target=off,           # âœ… pass off_target (if supported)
            correct_rate=correct_rate # âœ… pass correct_rate (if supported)
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["omission"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "omission": omit_res,
        }

        # -----------------------------
        # 7) status (match Addition endpoint current implementation)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 8) severity (only when slp)
        # -----------------------------
        omit_res = check_results.get("omission") or {}
        omit_final = str(omit_res.get("final_label") or "").strip().lower()

        severity_value = omit_res.get("severity", None) if omit_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None

        # -----------------------------
        # 9) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 10) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 11) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,

            # Prefer omission.patient_explain if present (same pattern as Addition)
            "patient_explain": (
                (check_results.get("omission") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Omission analysis failed: {str(e)}")


# ------------------------------
# Tone API
# ------------------------------

@app.post("/analyze_tone")
async def analyze_tone(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    username: str = Form("guest"),
    subtype: int = Form(0),          # legacy; ignored (match Addition behavior)
    category: str = Form("Tone"),
    pattern: str = Form("Tone_error"),
    checks: str = Form(""),          # legacy; ignored (tone-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… Tone-only (script) version â€” aligned to /analyze_addition & /analyze_omission

    - Only run Tone detector (rule-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type: å£°è°ƒæ›¿ä»£ | å£°è°ƒé”™ä½ | è½»å£°é”™è¯¯ (only if slp)
      severity: slight | middle | high               (only if slp)

    - Still compute:
        correct_rate (accuracy, 0~100)
        score (0~10) = round(correct_rate / 10)

    - status:
        correct if asr_ipa == target_ipa
        wrong   otherwise

    - severity:
        only from tone.severity AND only when final_label == slp
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        # -----------------------------
        # 3) results
        # -----------------------------
        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 4) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)  # 0~100
        score_points = int(round(correct_rate / 10))           # 0~10

        # -----------------------------
        # 5) meta off_target (still useful)
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 6) Tone detector only (script-based)
        # IMPORTANT: detect_tone_error must return Addition-style fields:
        # final_label + severity (canonical) + type etc.
        # -----------------------------
        tone_res = detect_tone_error(
            target_word,
            asr_ipa,
            llm=None,                 # âœ… disable LLM explicitly (if supported)
            off_target=off,           # âœ… pass off_target
            correct_rate=correct_rate # âœ… pass correct_rate
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["tone"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "tone": tone_res,
        }

        # -----------------------------
        # 7) status (match Addition endpoint)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 8) severity (only when slp)
        # -----------------------------
        tone_final = str((tone_res or {}).get("final_label") or "").strip().lower()
        severity_value = (tone_res or {}).get("severity") if tone_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None

        # -----------------------------
        # 9) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 10) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 11) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,

            # Prefer tone.patient_explain if present (same pattern as Addition/Omission)
            "patient_explain": (
                (check_results.get("tone") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Tone analysis failed: {str(e)}")

# ------------------------------
# Distortion API
# ------------------------------


@app.post("/analyze_distortion")
async def analyze_distortion(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    username: str = Form("guest"),
    subtype: int = Form(0),             # legacy; ignored (distortion uses bank subtype keys)
    category: str = Form("Distortion"),
    pattern: str = Form("Distortion_error"),
    checks: str = Form(""),             # legacy; ignored (distortion-only)
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Form("å°å­¸"),
):
    """
    âœ… Distortion-only version (aligned with analyze_addition process)

    - Only run Distortion detector (bank-based; no LLM).
      final_label: no_problem | slp | äº‚ç­”
      type (subtype): Distortion.json key (e.g., é½¿é¾ˆæ‘©æ“¦éŸ³æ­ªæ›² / å¡æ“¦éŸ³æ­ªæ›²) (only if slp)
      severity: slight | middle | high (only if slp; subtype-specific)

    - Still compute:
        correct_rate (accuracy, 0~100)
        score (0~10) = round(correct_rate / 10)

    - status (same as addition page for consistency):
        correct if asr_ipa == target_ipa else wrong

    - severity:
        only from distortion.severity AND only when final_label == slp
    """
    try:
        # -----------------------------
        # 1) read audio
        # -----------------------------
        content = await file.read()

        # -----------------------------
        # 2) ASR
        # -----------------------------
        asr_result = transcribe_bytes(
            audio_bytes=content,
            filename=file.filename,
            target_word=target_word,
            difficulty_level=difficulty_level,
        )

        # -----------------------------
        # 3) results
        # -----------------------------
        asr_ipa = asr_result.get("asr_ipa", "") or ""
        target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

        asr_word = asr_result.get("asr_word", "") or ""
        if not asr_word:
            if asr_ipa.strip() == target_ipa.strip():
                asr_word = target_word
            else:
                asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

        # -----------------------------
        # 4) accuracy + score points
        # -----------------------------
        correct_rate = calc_correct_rate(asr_ipa, target_ipa)     # 0~100
        score_points = int(round(correct_rate / 10))              # 0~10

        # -----------------------------
        # 5) meta off_target
        # -----------------------------
        off = compute_off_target(target_ipa, asr_ipa)
        is_off_target = bool(off.get("is_off_target"))

        # -----------------------------
        # 6) Distortion detector only
        # -----------------------------
        dis_res = detect_distortion_error(
            target_word,
            asr_ipa,
            llm=None,                 # keep signature compatible; not used
            off_target=off,
            correct_rate=correct_rate,
        )

        check_results = {
            "meta": {
                "off_target": off,
                "enabled_checks": ["distortion"],
                "pattern": pattern,
                "category": category,
                "llm_model_repo": None,
                "llm_model_file": None,
            },
            "distortion": dis_res,
        }

        # -----------------------------
        # 7) status (distortion-only; align to addition)
        # -----------------------------
        ipa_match = asr_ipa.strip() == target_ipa.strip()
        status = "correct" if ipa_match else "wrong"

        # -----------------------------
        # 8) severity (only when slp)
        # -----------------------------
        dis_final = str((dis_res or {}).get("final_label") or "").strip().lower()

        severity_value = (dis_res or {}).get("severity", None) if dis_final == "slp" else None
        if severity_value not in ("slight", "middle", "high"):
            severity_value = None

        # -----------------------------
        # 9) DB save
        # -----------------------------
        record_id = save_records_analysis_v2(
            user_id=current_user_id,
            language="Chinese",
            test_type=category,
            category=pattern,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # -----------------------------
        # 10) add points
        # -----------------------------
        if score_points > 0:
            conn = get_db()
            cur = conn.cursor()
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (score_points, current_user_id),
            )
            conn.commit()
            conn.close()

        # -----------------------------
        # 11) return
        # -----------------------------
        return JSONResponse({
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "revise_ipa": target_ipa,
            "asr_word": asr_word,
            "correct_rate": correct_rate,
            "status": status,
            "check_results": check_results,
            "difficulty_level": difficulty_level,
            "severity": severity_value,
            "is_off_target": is_off_target,
            "score": score_points,
            "record_id": record_id,

            # Prefer distortion.patient_explain if exists (old style), else fallback
            "patient_explain": (
                (check_results.get("distortion") or {}).get("patient_explain")
                or patient_friendly_explain(check_results)
            ),
        })

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Distortion analysis failed: {str(e)}")

def normalize_practice_language(lang: str | None) -> str:
    """
    practice_progress.language çš„å€¼åªç”¨: 'en' | 'cn'
    - default: en
    """
    s = (lang or "").strip().lower()
    if s in ("cn", "zh", "zh-cn", "chinese", "china"):
        return "cn"
    return "en"

# ------------------------------
# CORS è¨­å®š
# ------------------------------
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # é–‹ç™¼éšæ®µå…è¨±æ‰€æœ‰ï¼Œæ­£å¼ç’°å¢ƒå»ºè­°æ”¹æˆ ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ------------------------------
# User APIs (JSON)
# ------------------------------
class UserRegister(BaseModel):
    username: str
    password: str
    name: Optional[str] = None
    age: Optional[int] = None
    email: Optional[str] = None
    language: Optional[str] = "en"

# ------------------------------
# API: å–å¾— InitialConsonant è©èª
# ------------------------------
@app.get("/get_word_from_initial_consonant")
async def get_word_from_initial_consonant(errorType: str = Query(..., description="Initial consonant error type")):
    """
    å¾ InitialConsonant.json æ ¹æ“š errorType æŠ½ä¸€å€‹è©å›å‚³
    - errorType: "å£°æ¯çœç•¥" / "å£°æ¯æ›¿ä»£" / "å£°æ¯æ·»åŠ " / "å‘éŸ³éƒ¨ä½é”™è¯¯"
    """
    try:
        if not errorType or errorType not in InitialConsonant:
            raise HTTPException(status_code=400, detail="Invalid errorType")

        word = random.choice(InitialConsonant[errorType])
        return {"word": word}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å–è©å¤±æ•—: {str(e)}")



# ===========================
# âœ… Updated Register Function (with email verify)
# ===========================
@app.post("/auth/register")
def register(data: UserRegister):
    conn = get_db()
    cur = conn.cursor()

    # ==========================
    # âœ… æª¢æŸ¥ç”¨æˆ¶åæ˜¯å¦å·²å­˜åœ¨
    # ==========================
    cur.execute("SELECT 1 FROM patients WHERE username=?", (data.username,))
    if cur.fetchone():
        conn.close()
        raise HTTPException(status_code=400, detail="âŒ Username already exists, please choose another one")

    # ==========================
    # âœ… æª¢æŸ¥ Email æ˜¯å¦å·²å­˜åœ¨
    # ==========================
    if data.email:
        cur.execute("SELECT 1 FROM patients WHERE email=?", (data.email,))
        if cur.fetchone():
            conn.close()
            raise HTTPException(status_code=400, detail="âŒ Email already registered, please use another email")

    # ==========================
    # âœ… ç”¢ç”Ÿ 6 ä½é©—è­‰ç¢¼
    # ==========================
    verify_code = str(random.randint(100000, 999999))

    # ==========================
    # âœ… å¯„é€é©—è­‰ä¿¡
    # ==========================
    try:
        sender = "aaa2025819@gmail.com"
        smtp_host = "smtp.gmail.com"
        smtp_port = 587
        smtp_user = "aaa2025819@gmail.com"
        smtp_pass = "ssjuayuhpfugwltp"   # âš ï¸ Gmail App Password

        subject = "ASR Verification Code"
        body = f"""
Hello {data.username},

Your verification code is: {verify_code}

Please copy this code into the website to activate your account.

Thank you,
ASR+LLM System
"""

        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = data.email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [data.email], msg.as_string())

    except Exception as e:
        conn.close()
        raise HTTPException(status_code=500, detail=f"Email send failed: {e}")

    # ==========================
    # âœ… å»ºç«‹æ–°å¸³è™Ÿï¼ˆverify=0ï¼‰
    # ==========================
    patient_id = str(uuid.uuid4())
    email_value = data.email or ""
    language_value = data.language or "en"

    cur.execute("""
        INSERT INTO patients
        (id, username, password_hash, name, age, email, language, integral, verify)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, 0)
    """, (
        patient_id,
        data.username,
        hash_password(data.password),
        data.name,
        data.age,
        email_value,
        language_value,
        0
    ))

    # ==========================
    # âœ… å„²å­˜é©—è­‰ç¢¼
    # ==========================
    cur.execute("""
        CREATE TABLE IF NOT EXISTS email_verifies (
          username TEXT PRIMARY KEY,
          code TEXT,
          created_at TIMESTAMP
        )
    """)
    cur.execute("REPLACE INTO email_verifies (username, code, created_at) VALUES (?, ?, ?)",
                (data.username, verify_code, datetime.now()))

    conn.commit()
    conn.close()

    return {
        "msg": f"ğŸ“© Verification code sent to {data.email}. Please check your inbox.",
        "username": data.username,
        "email": data.email
    }

class UserLogin(BaseModel):
    email: str
    password: str

@app.get("/api/leaderboard")
def get_leaderboard(limit: int = 100):
    """
    ğŸ“Š å–å¾—ç©åˆ†æ’è¡Œæ¦œå‰ N å (æ’é™¤ admin å¸³è™Ÿ)
    """
    conn = get_db()
    cur = conn.cursor()
    # ğŸš« æ’é™¤ç®¡ç†è€…
    cur.execute("""
        SELECT username, integral
        FROM patients
        WHERE username IS NOT NULL
          AND username NOT IN ('admin', 'bbb')
        ORDER BY integral DESC
        LIMIT ?
    """, (limit,))

    rows = cur.fetchall()
    conn.close()

    # çµ„æˆ JSON
    leaderboard = [
        {"rank": i + 1, "username": r[0], "integral": r[1] or 0}
        for i, r in enumerate(rows)
    ]
    return {"leaderboard": leaderboard}

@app.post("/auth/login")
def login(
    request: Request,
    data: UserLogin,
    response: Response,
    send_cookie: bool = Query(SEND_USERNAME_COOKIE_DEFAULT, description="æ˜¯å¦ä¸‹ç™¼ email cookie"),
):
    # ğŸ”’ Admin still limited to localhost (but now identified by email)
    if data.email == f"{ADMIN_LOCAL_ONLY}@example.com":
        client_host = request.client.host
        if client_host not in ["127.0.0.1", "::1"]:
            raise HTTPException(status_code=403, detail="Admin account can only login from localhost")

    # âœ… æŸ¥è©¢ email è€Œé username
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT id, username, password_hash FROM patients WHERE email=?", (data.email,))
    row = cur.fetchone()
    conn.close()

    if not row or not verify_password(data.password, row[2]):
        raise HTTPException(status_code=401, detail="Invalid email or password")

    user_id = row[0]
    username = row[1]

    expire = datetime.utcnow() + timedelta(hours=12)
    token_data = {"sub": user_id, "exp": expire}
    token = jwt.encode(token_data, SECRET_KEY, algorithm=ALGORITHM)

    # ğŸ”‘ åªæœ‰ send_cookie=True æ™‚æ‰é€
    if send_cookie:
        response.set_cookie(
            key="email",
            value=data.email,
            httponly=False,  # å‰ç«¯ JS ä»å¯å­˜å–
            samesite="Lax"
        )

    # âœ… å–å¾—ä½¿ç”¨è€…é ­åƒè·¯å¾‘ä¸¦è¨­ç½® Cookie
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT user_picture FROM patients WHERE id=?", (user_id,))
    row = cur.fetchone()
    conn.close()

    picture_url = None
    if row and row[0]:
        picture_url = f"/{row[0]}"
        response.set_cookie(
            key="user_picture_url",
            value=picture_url,
            path="/",
            samesite="Lax",
            secure=True
        )

    return {
        "msg": "Login successful",
        "email": data.email,
        "username": username,
        "id": user_id,
        "token": token,
        "picture": picture_url
    }


# âœ… æ–°å¢ï¼šChange Password API
class ChangePasswordRequest(BaseModel):
    username: str
    old_password: str
    new_password: str


@app.post("/auth/change-password")
def change_password(data: ChangePasswordRequest):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT password_hash FROM patients WHERE username=?", (data.username,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")
    if not verify_password(data.old_password, row[0]):
        conn.close()
        raise HTTPException(status_code=400, detail="Old password is incorrect")

    cur.execute("UPDATE patients SET password_hash=? WHERE username=?",
                (hash_password(data.new_password), data.username))
    conn.commit()
    conn.close()
    return {"msg": "Password updated successfully"}

# âœ… æ–°å¢ï¼šUpdate Profile API
class UpdateProfileRequest(BaseModel):
    username: str
    name: Optional[str] = None
    age: Optional[int] = None
    diagnosis: Optional[str] = None
    email: Optional[str] = None
    language: Optional[str] = None
    integral: Optional[int] = None
    verify: Optional[int] = None
    old_password: Optional[str] = None
    new_password: Optional[str] = None

# âœ… æ–°å¢ï¼šUpdate Profile API
class UpdateProfileRequest(BaseModel):
    username: str
    name: Optional[str] = None
    age: Optional[int] = None
    diagnosis: Optional[str] = None
    email: Optional[str] = None
    language: Optional[str] = None
    integral: Optional[int] = None
    verify: Optional[int] = None
    old_password: Optional[str] = None
    new_password: Optional[str] = None


@app.post("/auth/update-profile")
def update_profile(data: UpdateProfileRequest):
    """
    æ ¹æ“šå‚³å…¥æ¬„ä½å‹•æ…‹æ›´æ–°æ‚£è€…è³‡æ–™ã€‚
    - æ²’æœ‰å‚³å…¥çš„æ¬„ä½ä¸æœƒæ›´æ”¹ã€‚
    - æ”¯æ´æ›´æ–° language, email, integral, verifyã€‚
    - ä¿®æ”¹å¯†ç¢¼éœ€åŒæ™‚å¸¶ old_password + new_passwordã€‚
    """
    conn = get_db()
    cur = conn.cursor()

    # å…ˆç¢ºèªå¸³è™Ÿå­˜åœ¨
    cur.execute("SELECT id, password_hash FROM patients WHERE username=?", (data.username,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")

    user_id, stored_hash = row

    updates = []
    params = []

    # âœ… å‹•æ…‹æ¬„ä½ï¼ˆåªæ›´æ–°æœ‰å‚³é€²ä¾†çš„ï¼‰
    if data.name is not None:
        updates.append("name=?")
        params.append(data.name)

    if data.age is not None:
        updates.append("age=?")
        params.append(data.age)

    if data.diagnosis is not None:
        updates.append("diagnosis=?")
        params.append(data.diagnosis)

    if data.email is not None:
        updates.append("email=?")
        params.append(data.email)

    if data.language is not None:
        updates.append("language=?")
        params.append(data.language)

    if data.integral is not None:
        updates.append("integral=?")
        params.append(data.integral)

    if data.verify is not None:
        updates.append("verify=?")
        params.append(data.verify)

    # âœ… è‹¥è¦ä¿®æ”¹å¯†ç¢¼ï¼Œå¿…é ˆåŒæ™‚æª¢æŸ¥èˆŠå¯†ç¢¼
    if data.new_password:
        if not data.old_password or not verify_password(data.old_password, stored_hash):
            conn.close()
            raise HTTPException(status_code=400, detail="Old password incorrect")

        updates.append("password_hash=?")
        params.append(hash_password(data.new_password))

    # æ²’æœ‰ä»»ä½•é …ç›®è¦æ›´æ–°æ™‚
    if not updates:
        conn.close()
        return {"msg": "No fields updated"}

    # âœ… çµ„ UPDATE èªå¥
    sql = f"UPDATE patients SET {', '.join(updates)} WHERE username=?"
    params.append(data.username)
    cur.execute(sql, tuple(params))
    conn.commit()

    # âœ… æ›´æ–°å®Œæˆå¾Œå›å‚³å®Œæ•´è³‡æ–™ï¼ˆä½  Setting é æœƒç”¨åˆ°çš„æ¬„ä½ï¼‰
    cur.execute("""
        SELECT id, username, name, age, diagnosis, email, language, integral, verify, user_picture
        FROM patients WHERE username=?
    """, (data.username,))
    user_row = cur.fetchone()
    conn.close()

    if not user_row:
        raise HTTPException(status_code=404, detail="User not found")

    return {
        "msg": "Profile updated successfully",
        "user": {
            "id": user_row[0],
            "username": user_row[1],
            "name": user_row[2],
            "age": user_row[3],
            "diagnosis": user_row[4],
            "email": user_row[5],
            "language": user_row[6],
            "integral": user_row[7],
            "verify": user_row[8],
            "user_picture": user_row[9],
        }
    }
    

@app.post("/get_word_llm1")
async def get_word_llm1(data: WordRequest):
    error_type = data.errorType
    if error_type not in substitution_errors_llm1:
        raise HTTPException(status_code=400, detail=f"Unknown error type: {error_type}")

    word_list = substitution_errors_llm1[error_type]

    # é€™è£¡å¯ä»¥ä¸ç”¨ LLMï¼Œç›´æ¥éš¨æ©Ÿé¸ä¸€å€‹å°±å¥½
    chosen_word = random.choice(word_list)

    return {"word": chosen_word}
# ------------------------------
# Pronunciation APIs
# ------------------------------
# ------------------------------
# Pronunciation APIs
# ------------------------------
@app.post("/transcribe")
async def transcribe(
    file: UploadFile = File(...),
    target_word: str = Form(...),
    difficulty_level: str = Form("å°å­¸")
):
    """
    æ¥æ”¶éŒ„éŸ³å’Œä¸­æ–‡ç›®æ¨™è©ï¼Œå‚³çµ¦ ASR+LLM åˆ†æï¼Œå›å‚³çµæœ
    """
    try:
        # æš«å­˜éŒ„éŸ³æª”
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(await file.read())
            tmp_path = tmp.name

        # ğŸ”¹ å‘¼å« ASR æ¨¡çµ„ (é€™è£¡ç”¨ recognize_word â†’ å¾—åˆ° ASR IPA)
        audio = load_and_denoise(tmp_path)
        asr_ipa = normalize_ipa(recognize_word(audio))
        os.remove(tmp_path)

        # ğŸ”¹ æŸ¥å­—å…¸è£¡çš„ç›®æ¨™è© IPAï¼ˆå¦‚æœæ²’æœ‰å°±ç”¨ eng_to_ipaï¼‰
        target_ipas = pronunciation_dict.get(target_word.lower(), [ipa.convert(target_word)])
        target_ipa = target_ipas[0]

        # ğŸ”¹ åˆ¤æ–·æ˜¯å¦æ­£ç¢º
        status = "correct" if asr_ipa == target_ipa else "wrong"

        # ğŸ”¹ é€™è£¡ç°¡å–®æ¨¡æ“¬ LLM å»ºè­°ç·´ç¿’è©ï¼ˆå¯¦éš›å¯æ”¹æˆ generate_practice_wordï¼‰
        suggest_word = random.choice([target_word, "åª½åª½", "éº»"])  

        result = {
            "target_word": target_word,
            "asr_ipa": asr_ipa,
            "target_ipa": target_ipa,
            "status": status,
            "suggest_word": suggest_word,
            "audio_url": f"/google_tts/{target_word}"
        }

        return JSONResponse(result)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Transcribe error: {str(e)}")

#-----------English SLP ------------------------------#

def normalize_difficulty_en(difficulty_level: str) -> str:
    """
    Map legacy values to DB/LLM accepted buckets: primary|secondary|advanced
    """
    s = (difficulty_level or "").strip().lower()
    mapping = {
        "primary_school": "primary",
        "primary": "primary",
        "elementary": "primary",
        "secondary": "secondary",
        "middle": "secondary",
        "advanced": "advanced",
        "advance": "advanced",
    }
    return mapping.get(s, "advanced")

def normalize_ipa_simple(s: str) -> str:
    return (s or "").replace("Ëˆ", "").replace("ËŒ", "").replace("Ë", "").strip()

def enforce_word_ipa_consistency(target_word: str, target_ipa: str, asr_word: str, asr_ipa: str):
    tw = (target_word or "").strip()
    aw = (asr_word or "").strip()

    ti = normalize_ipa_simple(target_ipa)
    ai = normalize_ipa_simple(asr_ipa)

    # A) wordç›¸åŒä½†IPAä¸åŒ -> å¼ºåˆ¶IPAä¸€è‡´
    if tw and aw and tw.lower() == aw.lower() and ti and ai and ti != ai:
        asr_ipa = target_ipa
        ai = ti

    # B) IPAç›¸åŒä½†wordä¸åŒ -> å¼ºåˆ¶wordä¸€è‡´
    if ti and ai and ti == ai and tw and aw and tw.lower() != aw.lower():
        asr_word = target_word

    return asr_word, asr_ipa
    
@app.post("/analyze_addition_words")
async def analyze_addition_words(
    file: UploadFile = File(...),
    target_word: str = Form(...),

    # å‰ç«¯å‚³
    test_type: str = Form("addition"),
    category: str = Form(...),

    pattern: str = Form(None),

    # å¯é¸ï¼šLLM åƒæ•¸ï¼ˆä¸å‚³å°±ç”¨é è¨­ï¼‰
    num_cases: Optional[int] = Form(None),
    max_new_tokens: Optional[int] = Form(None),
    temperature: float = Form(0.2),
    top_p: float = Form(1.0),
    repetition_penalty: float = Form(1.05),

    current_user_id: str = Depends(get_current_user_id),
):
    if not file.filename.lower().endswith(".wav"):
        raise HTTPException(status_code=400, detail="Only .wav files supported")

    content = await file.read()

    # 1) ASR
    asr = transcribe_bytes_en_full(content, target_word=target_word)
    target_ipa = asr.get("target_ipa", "")
    asr_ipa = asr.get("asr_ipa", "")
    asr_word = asr.get("asr_word") or "N/A"

    # 2) normalize difficulty
    diff = infer_en_difficulty_from_user_id(current_user_id)
    
    # 3) build required fields for analyze_record_payload
    req_id = str(uuid.uuid4())
    req_date = datetime.now().strftime("%Y-%m-%d")

    payload = analyze_record_payload(
        id=req_id,
        user_id=current_user_id,   # âœ… ç”¨ç™»å…¥è€… id
        date=req_date,
        target_word=target_word,
        target_ipa=target_ipa,
        asr_word=asr_word,
        asr_ipa=asr_ipa,
        difficulty=diff,           # âœ… ç”¨ä½  normalize éçš„ diff
        language="en",
        test_type=test_type,
        category=category,
        num_cases=num_cases,
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        top_p=top_p,
        repetition_penalty=repetition_penalty,
    )

    # optional: keep frontend pattern
    if pattern and isinstance(payload.get("check_results"), dict):
        meta = payload["check_results"].get("meta") or {}
        meta["pattern"] = pattern
        payload["check_results"]["meta"] = meta

    # 4) DB save
    record_id = save_records_analysis_v2(
        user_id=current_user_id,
        language="English",
        test_type=payload["test_type"],
        category=payload["category"],
        target_word=payload["target_word"],
        target_ipa=payload["target_ipa"],
        asr_ipa=payload["asr_ipa"],
        asr_word=payload["asr_word"],
        correct_rate=payload["correct_rate"],
        check_results=payload["check_results"],
        difficulty_level=payload["difficulty"],
        score=payload["score"],
        severity=payload["severity"],
    )

    out = dict(payload)
    out["record_id"] = record_id
    out["revise_ipa"] = payload.get("target_ipa")
    out["addition_check"] = (payload.get("check_results") or {}).get("addition")
    return JSONResponse(out)

@app.post("/analyze_substitution_words")
async def analyze_substitution_words(
    file: UploadFile = File(...),
    target_word: str = Form(...),

    # å‰ç«¯å‚³ï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    test_type: str = Form("substitution"),   # âœ… supertype = substitution
    category: str = Form(...),               # âœ… required (è·Ÿ addition ä¸€æ¨£)
    pattern: str = Form(None),

    # å¯é¸ï¼šLLM åƒæ•¸ï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    num_cases: Optional[int] = Form(None),
    max_new_tokens: Optional[int] = Form(None),
    temperature: float = Form(0.2),
    top_p: float = Form(1.0),
    repetition_penalty: float = Form(1.05),

    current_user_id: str = Depends(get_current_user_id),
):
    if not file.filename.lower().endswith(".wav"):
        raise HTTPException(status_code=400, detail="Only .wav files supported")

    content = await file.read()

    # 1) ASRï¼ˆæ²¿ç”¨ä½  addition_words ç”¨çš„è‹±æ–‡ ASRï¼štranscribe_bytes_en_fullï¼‰
    asr = transcribe_bytes_en_full(content, target_word=target_word)
    target_ipa = asr.get("target_ipa", "")
    asr_ipa = asr.get("asr_ipa", "")
    asr_word = asr.get("asr_word") or "N/A"

    # 2) normalize difficultyï¼ˆè·Ÿ addition ä¸€æ¨£ï¼šç”± user_id æ¨æ–·ï¼‰
    diff = infer_en_difficulty_from_user_id(current_user_id)

    # 3) build required fields for analyze_record_payloadï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    req_id = str(uuid.uuid4())
    req_date = datetime.now().strftime("%Y-%m-%d")

    payload = analyze_record_payload(
        id=req_id,
        user_id=current_user_id,
        date=req_date,
        target_word=target_word,
        target_ipa=target_ipa,
        asr_word=asr_word,
        asr_ipa=asr_ipa,
        difficulty=diff,
        language="en",

        # âœ… substitution é€™è£¡è¦å‚³ substitution
        test_type=test_type,     # default "substitution"
        category=category,

        num_cases=num_cases,
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        top_p=top_p,
        repetition_penalty=repetition_penalty,
    )

    # optional: keep frontend patternï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    if pattern and isinstance(payload.get("check_results"), dict):
        meta = payload["check_results"].get("meta") or {}
        meta["pattern"] = pattern
        payload["check_results"]["meta"] = meta

    # 4) DB saveï¼ˆâœ… ç”¨åŒä¸€å€‹ save_records_analysis_v2ï¼Œåªå­˜ä¸€æ¬¡ï¼‰
    record_id = save_records_analysis_v2(
        user_id=current_user_id,
        language="English",
        test_type=payload["test_type"],     # "substitution"
        category=payload["category"],
        target_word=payload["target_word"],
        target_ipa=payload["target_ipa"],
        asr_ipa=payload["asr_ipa"],
        asr_word=payload["asr_word"],
        correct_rate=payload["correct_rate"],
        check_results=payload["check_results"],
        difficulty_level=payload["difficulty"],
        score=payload["score"],
        severity=payload["severity"],
    )

    out = dict(payload)
    out["record_id"] = record_id
    out["revise_ipa"] = payload.get("target_ipa")

    # âœ… substitution çš„å‰ç«¯è‹¥éœ€è¦å°æ‡‰æ¬„ä½ï¼Œä½ å¯ä»¥åŠ é€™å€‹ï¼ˆå–æ±ºæ–¼ analyze_record_payload çš„çµæ§‹ï¼‰
    out["substitution_check"] = (payload.get("check_results") or {}).get("substitution")

    return JSONResponse(out)

@app.post("/analyze_omission_words")
async def analyze_omission_words(
    file: UploadFile = File(...),
    target_word: str = Form(...),

    # å‰ç«¯å‚³ï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    test_type: str = Form("omission"),   # âœ… supertype = omission
    category: str = Form(...),           # âœ… required
    pattern: str = Form(None),

    # å¯é¸ï¼šLLM åƒæ•¸ï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    num_cases: Optional[int] = Form(None),
    max_new_tokens: Optional[int] = Form(None),
    temperature: float = Form(0.2),
    top_p: float = Form(1.0),
    repetition_penalty: float = Form(1.05),

    current_user_id: str = Depends(get_current_user_id),
):
    if not file.filename.lower().endswith(".wav"):
        raise HTTPException(status_code=400, detail="Only .wav files supported")

    content = await file.read()

    # 1) ASRï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    asr = transcribe_bytes_en_full(content, target_word=target_word)
    target_ipa = asr.get("target_ipa", "")
    asr_ipa = asr.get("asr_ipa", "")
    asr_word = asr.get("asr_word") or "N/A"

    # 2) normalize difficultyï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    diff = infer_en_difficulty_from_user_id(current_user_id)

    # 3) build required fields for analyze_record_payloadï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    req_id = str(uuid.uuid4())
    req_date = datetime.now().strftime("%Y-%m-%d")

    payload = analyze_record_payload(
        id=req_id,
        user_id=current_user_id,
        date=req_date,
        target_word=target_word,
        target_ipa=target_ipa,
        asr_word=asr_word,
        asr_ipa=asr_ipa,
        difficulty=diff,
        language="en",

        # âœ… omission
        test_type=test_type,   # default "omission"
        category=category,

        num_cases=num_cases,
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        top_p=top_p,
        repetition_penalty=repetition_penalty,
    )

    # optional: keep frontend patternï¼ˆè·Ÿ addition ä¸€æ¨£ï¼‰
    if pattern and isinstance(payload.get("check_results"), dict):
        meta = payload["check_results"].get("meta") or {}
        meta["pattern"] = pattern
        payload["check_results"]["meta"] = meta

    # 4) DB saveï¼ˆâœ… åªå­˜é€™ä¸€æ¬¡ï¼‰
    record_id = save_records_analysis_v2(
        user_id=current_user_id,
        language="English",
        test_type=payload["test_type"],     # "omission"
        category=payload["category"],
        target_word=payload["target_word"],
        target_ipa=payload["target_ipa"],
        asr_ipa=payload["asr_ipa"],
        asr_word=payload["asr_word"],
        correct_rate=payload["correct_rate"],
        check_results=payload["check_results"],
        difficulty_level=payload["difficulty"],
        score=payload["score"],
        severity=payload["severity"],
    )

    out = dict(payload)
    out["record_id"] = record_id
    out["revise_ipa"] = payload.get("target_ipa")

    # ï¼ˆå¯é¸ï¼‰å¦‚æœä½ çš„ analyze_record_payload æœ‰ omission keyï¼Œå‰ç«¯è¦ç”¨çš„è©±å¯ä»¥åŠ 
    out["omission_check"] = (payload.get("check_results") or {}).get("omission")

    return JSONResponse(out)
#-----------English SLP ------------------------------#


@app.get("/history/{username}")
def get_history(username: str):
    conn = get_db()
    cur = conn.cursor()

    cur.execute("SELECT id FROM patients WHERE username=?", (username,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")
    patient_id = row[0]

    cur.execute("SELECT id, date FROM sessions WHERE patient_id=? ORDER BY date DESC", (patient_id,))
    sessions = []
    for s_id, s_date in cur.fetchall():
        cur.execute("SELECT word, category, pattern, asr_ipa, revise_ipa, status, audio_path FROM attempts WHERE session_id=?", (s_id,))
        attempts = [
            {
                "word": a[0],
                "category": a[1],
                "pattern": a[2],
                "asr_ipa": a[3],
                "revise_ipa": a[4],
                "status": a[5],
                "audio_path": a[6]
            }
            for a in cur.fetchall()
        ]
        sessions.append({"date": s_date, "attempts": attempts})

    conn.close()
    return {"username": username, "history": sessions}


@app.get("/auth/me")
def get_me(
    username: str = Query(..., alias="username"), 
    simple: bool = Query(False, description="åªå›å‚³ is_admin")
):
    token = username
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid token")
    except JWTError:
        raise HTTPException(status_code=401, detail="Token expired or invalid")

    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT id, username FROM patients WHERE id=?", (user_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found")

    patient_id, username = row
    is_admin = username in ADMIN_USERS

    # âœ… å¦‚æœ simple=true å°±åªå›å‚³é€™å€‹
    if simple:
        conn.close()
        return {
            "id": patient_id,
            "username": username,
            "is_admin": is_admin
        }

    # âœ… å¦å‰‡ç…§èˆŠå›å‚³ sessions
    cur.execute("SELECT id, date FROM sessions WHERE patient_id=? ORDER BY date DESC", (patient_id,))
    sessions = []
    for s_id, s_date in cur.fetchall():
        cur.execute("""
            SELECT word, category, pattern, asr_ipa, revise_ipa, status, audio_path
            FROM attempts WHERE session_id=?""", (s_id,))
        attempts = [
            {
                "word": a[0],
                "category": a[1],
                "pattern": a[2],
                "asr_ipa": a[3],
                "revise_ipa": a[4],
                "status": a[5],
                "audio_path": a[6]
            }
            for a in cur.fetchall()
        ]
        sessions.append({"date": s_date, "attempts": attempts})

    conn.close()
    return {
        "id": patient_id,
        "username": username,
        "sessions": sessions
    }

@app.post("/auth/upload-picture")
async def upload_user_picture(
    file: UploadFile = File(...),
    token: Optional[str] = Cookie(None),
    response: Response = None
):
    """
    ä¸Šå‚³ä½¿ç”¨è€…é ­åƒï¼š
    - æª¢æŸ¥ç™»å…¥ Token
    - æª¢æŸ¥å‰¯æª”åæ ¼å¼ (.png / .jpg / .jpeg)
    - æª¢æŸ¥æª”æ¡ˆå¤§å° ( â‰¤ 1MB)
    - å„²å­˜æ–¼ User/<token>/picture/profile.png
    - æ›´æ–°è³‡æ–™åº« user_picture æ¬„ä½
    - å›å‚³è©³ç´°è¨Šæ¯
    """
    try:
        # ğŸ§© Step 1ï¸âƒ£ é©—è­‰ç™»å…¥ token
        if not token:
            raise HTTPException(
                status_code=401, 
                detail="âŒ è«‹å…ˆç™»å…¥ï¼ˆcookie ä¸­æ²’æœ‰ tokenï¼‰"
            )

        try:
            payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
            user_id = payload.get("sub")
            if not user_id:
                raise HTTPException(status_code=401, detail="âŒ Token ç„¡æ•ˆï¼ŒæœªåŒ…å«ä½¿ç”¨è€… IDã€‚")
        except JWTError as e:
            raise HTTPException(status_code=401, detail=f"âŒ Token éŒ¯èª¤æˆ–éæœŸ: {str(e)}")

        # ğŸ§© Step 2ï¸âƒ£ æª¢æŸ¥æª”æ¡ˆåç¨±
        if not file.filename:
            raise HTTPException(status_code=400, detail="âŒ æœªæ”¶åˆ°æª”æ¡ˆæˆ–æª”åç‚ºç©º")

        filename = file.filename.lower()
        if not (filename.endswith(".png") or filename.endswith(".jpg") or filename.endswith(".jpeg")):
            raise HTTPException(
                status_code=400,
                detail=f"âŒ æª”æ¡ˆæ ¼å¼éŒ¯èª¤ ({filename})ï¼Œåƒ…å…è¨±ä¸Šå‚³ PNG / JPG / JPEG"
            )

        # ğŸ§© Step 3ï¸âƒ£ æª¢æŸ¥æª”æ¡ˆå¤§å°
        contents = await file.read()
        file_size_kb = len(contents) / 1024
        max_size_kb = 1000  # ä½ åŸæœ¬è¨»è§£å¯« 300KBï¼Œä½†å¯¦éš›è¨­å®š 1000KBâ‰ˆ1MB
        if file_size_kb > max_size_kb:
            raise HTTPException(
                status_code=400,
                detail=f"âŒ æª”æ¡ˆå¤§å°è¶…éé™åˆ¶ï¼š{file_size_kb:.1f}KBï¼ˆæœ€å¤§å…è¨± {max_size_kb:.0f}KBï¼‰"
            )

        # ğŸ§© Step 4ï¸âƒ£ å»ºç«‹ä½¿ç”¨è€…ç›®éŒ„ï¼ˆâ—æ”¹æˆä»¥ user_id å‘½åï¼‰
        try:
            user_dir = os.path.join(USER_ROOT_DIR, "patient", str(user_id))
            picture_dir = os.path.join(user_dir, "picture")
            os.makedirs(picture_dir, exist_ok=True)

            # åˆªé™¤èˆŠåœ–
            for old in os.listdir(picture_dir):
                os.remove(os.path.join(picture_dir, old))
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"âŒ ç„¡æ³•å»ºç«‹ä½¿ç”¨è€…è³‡æ–™å¤¾: {str(e)}")

        # ğŸ§© Step 5ï¸âƒ£ å„²å­˜æ–°æª”æ¡ˆï¼ˆé€™è£¡ä¸å‹•ï¼‰
        try:
            ext = ".png" if filename.endswith(".png") else ".jpg"
            file_name = f"profile{ext}"
            save_path = os.path.join(picture_dir, file_name)
            with open(save_path, "wb") as f:
                f.write(contents)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"âŒ å„²å­˜åœ–ç‰‡å¤±æ•—: {str(e)}")

        # ğŸ§© Step 6ï¸âƒ£ æ›´æ–°è³‡æ–™åº«ï¼ˆâ—æ”¹ç‚ºä»¥ user_id å­˜è·¯å¾‘ï¼‰
        try:
            conn = get_db()
            cur = conn.cursor()
            relative_path = f"User/patient/{user_id}/picture/{file_name}"
            cur.execute(
                "UPDATE patients SET user_picture=? WHERE id=?",
                (relative_path, user_id)
            )
            conn.commit()
            conn.close()
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"âŒ æ›´æ–°è³‡æ–™åº«å¤±æ•—: {str(e)}")

        # ğŸ§© Step 7ï¸âƒ£ è¨­å®š Cookie + å›å‚³æˆåŠŸè¨Šæ¯ï¼ˆé€™è£¡å¯ä¿ç•™ï¼‰
        public_url = f"/{relative_path}"
        if response:
            response.set_cookie(
                key="user_picture_url",
                value=public_url,
                httponly=False,
                samesite="Lax",
                secure=True
            )

        return JSONResponse(
            content={
                "msg": f"âœ… ä¸Šå‚³æˆåŠŸï¼æª”æ¡ˆå¤§å° {file_size_kb:.1f}KBï¼Œå·²å­˜è‡³ {public_url}",
                "picture_url": public_url
            },
            headers={"Set-Cookie": f"user_picture_url={public_url}; path=/; SameSite=Lax"}
        )

    except HTTPException:
        raise
    except Exception as e:
        # ğŸ§© æ•æ‰æ‰€æœ‰æœªé æœŸéŒ¯èª¤
        raise HTTPException(status_code=500, detail=f"âŒ æœªçŸ¥éŒ¯èª¤: {str(e)}")


@app.post("/api/ask-route")
async def ask_route(data: dict):
    try:
        question = data.get("question", "")
        if not question.strip():
            raise HTTPException(status_code=400, detail="ç¼ºå°‘å•é¡Œå…§å®¹")
        reply = ask_about_route(question)
        return {"reply": reply}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Route QA error: {str(e)}")

@app.post("/api/ask")
async def ask_api(data: dict):
    username = data.get("username", "")
    question = data.get("question", "")

    if not question.strip():
        raise HTTPException(status_code=400, detail="ç¼ºå°‘å•é¡Œå…§å®¹")

    if username in ADMIN_USERS:   # âœ… æ”¯æ´å¤šå€‹ admin
        reply = main_chat.generate_text(
            question,
            role_instruction="ä½ æ˜¯ä¸€å€‹åŠ©ç†ï¼Œå¯ä»¥è‡ªç”±å›ç­”ä½¿ç”¨è€…ä»»ä½•å•é¡Œã€‚"
        )
        main_chat.save_message(username, "user", question)
        main_chat.save_message(username, "assistant", reply)
        return {"role": "admin", "reply": reply}

    else:
        # æ™®é€šä½¿ç”¨è€…åªèƒ½å•è·¯å¾‘
        if any(kw in question for kw in ["å»å“ªè£¡", "é é¢", "path", "route"]):
            reply = ask_about_route(question)
        else:
            reply = "âŒ æŠ±æ­‰ï¼Œä½ æ²’æœ‰æ¬Šé™è©¢å•èˆ‡è·¯å¾‘ç„¡é—œçš„å•é¡Œã€‚"

        main_chat.save_message(username, "user", question)
        main_chat.save_message(username, "assistant", reply)
        return {"role": "user", "reply": reply}

@app.post("/api/chat")
async def chat_api(data: dict = None):
    try:
        if not data or "message" not in data:
            raise HTTPException(status_code=400, detail="Missing message field")

        message = data["message"]
        user_id = data.get("username", "guest")

        # 1ï¸âƒ£ å­˜ä½¿ç”¨è€…è¨Šæ¯
        main_chat.save_message(user_id, "user", message)

        # 2ï¸âƒ£ æ’ˆæœ€è¿‘ 20 æ¢å°è©±
        recent = main_chat.get_recent_messages(user_id, limit=20)
        history_msgs = [{"role": role, "content": text} for role, text in recent]

        # 3ï¸âƒ£ åŠ å…¥é€™æ¬¡çš„æ–°å•é¡Œ
        history_msgs.append({"role": "user", "content": message})

        # 4ï¸âƒ£ å‘¼å« LLM
        resp = ollama.chat(
            model="gpt-oss:20b",
            messages=history_msgs,
            options={"num_predict": 500}
        )
        reply = resp["message"]["content"]

        # 5ï¸âƒ£ å­˜ AI å›è¦†
        main_chat.save_message(user_id, "assistant", reply)

        return {"reply": reply}

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Chat error: {str(e)}")

# ==============================
# ğŸ’¾ çµ±ä¸€å­˜ DB å‡½å¼
# ==============================
def save_message_to_db(username: str, role: str, message: str, 
                       aitest: str = None, file_type: str = None, file_path: str = None):
    conn = sqlite3.connect("memory.db")
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS messages (
            id TEXT PRIMARY KEY,
            username TEXT,
            role TEXT,
            message TEXT,
            aitest TEXT,
            file_type TEXT,
            file_path TEXT,
            created_at TIMESTAMP,
            is_active BOOLEAN DEFAULT 1
        )
    """)
    cur.execute(
        """INSERT INTO messages 
        (id, username, role, message, aitest, created_at, is_active) 
        VALUES (?, ?, ?, ?, ?, ?, 1)""",
        (str(uuid.uuid4()), username, role, message, aitest, datetime.datetime.now().isoformat())
    )
    conn.commit()
    conn.close()


# -----------------------------
# ä¸Šå‚³éŸ³è¨Š
# -----------------------------
@app.post("/api/chat/upload-audio")
async def chat_audio_api(
    file: UploadFile = File(...),
    username: str = Depends(get_current_username_from_db)
):
    # 1ï¸âƒ£ ç®¡ç†å“¡æª¢æŸ¥
    if ONLY_ADMIN_UPLOAD and username not in ADMIN_USERS:
        raise HTTPException(status_code=403, detail="âŒ åªæœ‰ç®¡ç†å“¡å¯ä»¥ä¸Šå‚³éŸ³è¨Š")

    # 2ï¸âƒ£ æª”æ¡ˆé¡å‹æª¢æŸ¥
    mime = magic.from_buffer(await file.read(2048), mime=True)
    await file.seek(0)
    if not mime.startswith("audio/"):
        raise HTTPException(status_code=400, detail=f"âŒ åƒ…æ”¯æ´éŸ³è¨Šï¼Œä¸Šå‚³é¡å‹ç‚º: {mime}")

    # 3ï¸âƒ£ ä¿å­˜æ–‡ä»¶
    save_path = os.path.join(UPLOAD_AUDIO_DIR, file.filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # âœ… å…ˆè¨˜éŒ„ä¸Šå‚³å‹•ä½œ
    save_message_to_db(
        username,
        "system",
        f"ğŸ™ï¸ éŸ³è¨Šå·²ä¸Šå‚³: {file.filename}",
        file_type="audio",
        file_path=save_path
    )

    # 4ï¸âƒ£ å‘¼å« LLM åˆ†æ
    reply = main_chat.chat_with_audio(save_path)

    # 5ï¸âƒ£ å­˜ AI å›è¦†
    save_message_to_db(username, "llm", reply)

    return {"reply": reply, "filename": file.filename, "mime": mime}


# -----------------------------
# ä¸Šå‚³åœ–ç‰‡
# -----------------------------
@app.post("/api/chat/upload-image")
async def chat_image_api(
    file: UploadFile = File(...),
    username: str = Depends(get_current_username_from_db)
):
    # 1ï¸âƒ£ ç®¡ç†å“¡æª¢æŸ¥
    if ONLY_ADMIN_UPLOAD and username not in ADMIN_USERS:
        raise HTTPException(status_code=403, detail="âŒ åªæœ‰ç®¡ç†å“¡å¯ä»¥ä¸Šå‚³åœ–ç‰‡")

    # 2ï¸âƒ£ æª”æ¡ˆé¡å‹æª¢æŸ¥
    mime = magic.from_buffer(await file.read(2048), mime=True)
    await file.seek(0)
    if not mime.startswith("image/"):
        raise HTTPException(status_code=400, detail=f"âŒ åƒ…æ”¯æ´åœ–ç‰‡ï¼Œä¸Šå‚³é¡å‹ç‚º: {mime}")

    # 3ï¸âƒ£ ä¿å­˜æ–‡ä»¶
    save_path = os.path.join(UPLOAD_IMAGE_DIR, file.filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # âœ… å…ˆè¨˜éŒ„ä¸Šå‚³å‹•ä½œ
    save_message_to_db(
        username,
        "system",
        f"ğŸ–¼ï¸ åœ–ç‰‡å·²ä¸Šå‚³: {file.filename}",
        file_type="image",
        file_path=save_path
    )

    # 4ï¸âƒ£ å‘¼å« LLM åˆ†æ
    with open(save_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    reply = main_chat.chat_with_image(b64)

    # 5ï¸âƒ£ å­˜ AI å›è¦†
    save_message_to_db(username, "llm", reply)

    return {"reply": reply, "filename": file.filename, "mime": mime}


# -----------------------------
# ä¸Šå‚³æ–‡ä»¶ï¼ˆå–®ç´”å­˜æª”ï¼‰
# -----------------------------
@app.post("/upload/document")
async def upload_document(
    file: UploadFile = File(...),
    username: str = Depends(get_current_username_from_db)
):
    if ONLY_ADMIN_UPLOAD and username not in ADMIN_USERS:
        raise HTTPException(status_code=403, detail="âŒ åªæœ‰ç®¡ç†å“¡å¯ä»¥ä¸Šå‚³æ–‡ä»¶")

    mime = magic.from_buffer(await file.read(2048), mime=True)
    await file.seek(0)

    if mime.startswith("image/") or mime.startswith("audio/"):
        raise HTTPException(status_code=400, detail="âŒ ä¸å…è¨±ä¸Šå‚³åœ–ç‰‡æˆ–éŸ³é »æª”æ¡ˆ")

    allowed_types = [
        "application/pdf",
        "application/msword",
        "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        "application/json",
        "text/x-python",
        "text/x-java",
        "application/javascript",
        "text/css",
        "application/x-php",
    ]
    if mime not in allowed_types:
        raise HTTPException(status_code=400, detail=f"âŒ ä¸æ”¯æ´çš„æ–‡ä»¶é¡å‹: {mime}")

    save_path = os.path.join(UPLOAD_DOC_DIR, file.filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # âœ… å­˜é€² memory.db
    save_message_to_db(
        username,
        "system",
        f"ğŸ“„ æ–‡ä»¶å·²ä¸Šå‚³: {file.filename}",
        file_type="document",
        file_path=save_path
    )

    return {
        "msg": "âœ… æ–‡ä»¶ä¸Šå‚³æˆåŠŸ",
        "filename": file.filename,
        "mime": mime,
        "uploaded_by": username,
    }


# -----------------------------
# ä¸Šå‚³ä¸¦å•æ–‡ä»¶
# -----------------------------
@app.post("/upload/document/ask")
async def upload_and_ask_document(
    file: UploadFile = File(...),
    question: str = Form(...),
    username: str = Depends(get_current_username_from_db)   # âœ… æ”¹ç”¨ token æ‹¿ username
):
    # 1ï¸âƒ£ ä¿å­˜æ–‡ä»¶åˆ°ç¡¬ç¢Ÿ
    save_path = os.path.join(UPLOAD_DOC_DIR, file.filename)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    # âœ… å­˜ DB - ä¸Šå‚³å‹•ä½œ
    save_message_to_db(
        username,
        "system",
        f"ğŸ“„ æ–‡ä»¶å·²ä¸Šå‚³: {file.filename}",
        file_type="document",
        file_path=save_path
    )

    # 2ï¸âƒ£ æŠ½å–æ–‡ä»¶å…§å®¹
    text_content = ""
    if file.filename.lower().endswith(".pdf"):
        with pdfplumber.open(save_path) as pdf:
            text_content = "\n".join([page.extract_text() or "" for page in pdf.pages])
    elif file.filename.lower().endswith(".docx"):
        doc = Document(save_path)
        text_content = "\n".join([para.text for para in doc.paragraphs])
    else:
        with open(save_path, "r", encoding="utf-8", errors="ignore") as f:
            text_content = f.read()

    if not text_content.strip():
        raise HTTPException(status_code=400, detail="âŒ æ–‡ä»¶æ²’æœ‰å¯ç”¨çš„æ–‡å­—å…§å®¹")

    # 3ï¸âƒ£ ä¸Ÿçµ¦ LLM
    prompt = f"""
é€™æ˜¯ä½¿ç”¨è€…ä¸Šå‚³çš„æ–‡ä»¶å…§å®¹ï¼š

{text_content}

ä½¿ç”¨è€…å•é¡Œï¼š{question}

è«‹æ ¹æ“šæ–‡ä»¶å…§å®¹ä¾†å›ç­”å•é¡Œã€‚
"""
    resp = ollama.chat(
        model="gpt-oss-20b",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹åŠ©ç†ï¼Œè«‹å¹«åŠ©ä½¿ç”¨è€…ç†è§£æ–‡ä»¶å…§å®¹ã€‚"},
            {"role": "user", "content": prompt}
        ],
        options={"num_predict": 500}
    )
    answer = resp["message"]["content"]

    # âœ… å­˜ DB - ä½¿ç”¨è€…æå•
    save_message_to_db(username, "user", question, file_type="document", file_path=save_path)

    # âœ… å­˜ DB - AI å›ç­”
    save_message_to_db(username, "llm", answer)

    # 4ï¸âƒ£ å›å‚³
    return {
        "filename": file.filename,
        "question": question,
        "answer": answer
    }


# -----------------------------
# èŠå¤©ç´€éŒ„ API
# -----------------------------
@app.get("/api/chat/recent")
def get_recent_history(limit: int = 20):
    conn = sqlite3.connect("memory.db")
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS messages (
            id TEXT PRIMARY KEY,
            username TEXT,
            role TEXT,
            message TEXT,
            aitest TEXT,
            file_type TEXT,
            file_path TEXT,
            created_at TIMESTAMP,
            is_active BOOLEAN DEFAULT 1   -- ğŸ†• åŠ å…¥æ˜¯å¦å•Ÿç”¨ (1=é¡¯ç¤º, 0=åˆªé™¤/éš±è—)
        )
    """)
    cur.execute("""
        SELECT id, username, role, message, created_at
        FROM messages
        WHERE is_active=1
        ORDER BY created_at DESC LIMIT ?
    """, (limit,))
    rows = cur.fetchall()
    conn.close()

    history = [
        {"id": r[0], "username": r[1], "role": r[2], "text": r[3], "timestamp": r[4]}
        for r in reversed(rows)
    ]
    return {"history": history}

@app.delete("/auth/delete-picture")
def delete_user_picture(token: Optional[str] = Cookie(None)):
    """
    åˆªé™¤ç›®å‰ä½¿ç”¨è€…çš„é ­åƒåœ–ç‰‡èˆ‡è³‡æ–™åº«ç´€éŒ„
    """
    if not token:
        raise HTTPException(status_code=401, detail="âŒ æ²’æœ‰ç™»å…¥ Token")

    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="âŒ Token ç„¡æ•ˆ")

        # ğŸ” æ‰¾ä½¿ç”¨è€…è³‡æ–™å¤¾
        user_dir = os.path.join(USER_ROOT_DIR, "patient", str(user_id), "picture")
        if os.path.exists(user_dir):
            for file in os.listdir(user_dir):
                try:
                    os.remove(os.path.join(user_dir, file))
                except Exception as e:
                    print("åˆªé™¤éŒ¯èª¤ï¼š", e)

        # ğŸ”¸ æ¸…é™¤ DB æ¬„ä½
        conn = get_db()
        cur = conn.cursor()
        cur.execute("UPDATE patients SET user_picture=NULL WHERE id=?", (user_id,))
        conn.commit()
        conn.close()

        return {"msg": "âœ… é ­åƒåœ–ç‰‡å·²åˆªé™¤"}

    except JWTError:
        raise HTTPException(status_code=401, detail="âŒ Token éŒ¯èª¤æˆ–éæœŸ")
    
@app.get("/api/patient/profile")
def get_patient_profile(current_user_id: str = Depends(get_current_user_id)):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT
            id, username, name, age, diagnosis, email, language,
            integral, verify, user_picture
        FROM patients WHERE id=?
    """, (current_user_id,))
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=404, detail="User not found")


    # âœ… ç¢ºä¿å‰ç«¯æ‹¿åˆ°æ­£ç¢ºè·¯å¾‘ï¼ˆä¸é‡è¤‡ Userï¼‰
    picture_path = row[9] or "static/default-user.png"
    picture_url = "/" + str(picture_path).lstrip("/")

    return {
        "user": {
            "id": row[0],
            "username": row[1],
            "name": row[2],
            "age": row[3],
            "diagnosis": row[4],
            "email": row[5],
            "language": row[6],
            "integral": row[7],
            "verify": row[8],
            "user_picture": picture_url  # ğŸ‘ˆ æ–°å¢é€™è¡Œï¼Œå‰ç«¯æ‰èƒ½æŠ“åˆ°
        }
    }

@app.get("/api/chat/history")
def get_all_history(limit: int = 50):
    conn = sqlite3.connect("memory.db")
    cur = conn.cursor()
    cur.execute("""
        SELECT id, username, role, message, created_at
        FROM messages
        WHERE is_active=1
        ORDER BY created_at DESC LIMIT ?
    """, (limit,))
    rows = cur.fetchall()
    conn.close()

    history = [
        {"id": r[0], "username": r[1], "role": r[2], "text": r[3], "timestamp": r[4]}
        for r in reversed(rows)
    ]
    return {"history": history}

@app.delete("/api/chat/history/{msg_id}")
def delete_one_message(msg_id: str):
    try:
        conn = sqlite3.connect("memory.db")
        cur = conn.cursor()
        cur.execute("UPDATE messages SET is_active=0 WHERE id=?", (msg_id,))
        conn.commit()
        conn.close()
        return {"msg": f"âœ… å·²éš±è—è¨Šæ¯ {msg_id}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆªé™¤è¨Šæ¯å¤±æ•—: {str(e)}")
    
@app.post("/api/chat/hide-all")
def hide_all_messages():
    try:
        conn = sqlite3.connect("memory.db")  # âœ… correct database
        cur = conn.cursor()
        cur.execute("UPDATE messages SET is_active=0")  # âœ… correct table
        conn.commit()
        conn.close()
        return {"msg": "æ‰€æœ‰è¨Šæ¯å·²æ¨™è¨˜ç‚ºéš±è—"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±æ•—: {str(e)}")
    
@app.post("/auth/resend-verify")
def resend_verify_email(username: str):
    conn = get_db()
    cur = conn.cursor()

    # å…è¨±å‚³ email æˆ– username éƒ½å¯åŒ¹é…
    cur.execute("""
        SELECT email FROM patients WHERE username=? OR email=?
    """, (username, username))
    row = cur.fetchone()

    if not row or not row[0]:
        conn.close()
        raise HTTPException(status_code=404, detail="User not found or no email")

    email = row[0]
    verify_code = str(random.randint(100000, 999999))

    # å„²å­˜æ­¤é©—è­‰ç¢¼
    cur.execute("""
        CREATE TABLE IF NOT EXISTS email_verifies (
            username TEXT PRIMARY KEY,
            code TEXT,
            created_at TIMESTAMP
        )
    """)
    cur.execute("REPLACE INTO email_verifies (username, code, created_at) VALUES (?, ?, ?)",
                (username, verify_code, datetime.now()))

    conn.commit()
    conn.close()

    # âœ… Gmail å¯„ä¿¡è¨­å®š
    sender = "aaa2025819@gmail.com"
    smtp_host = "smtp.gmail.com"
    smtp_port = 587
    smtp_user = "aaa2025819@gmail.com"
    smtp_pass = "ssjuayuhpfugwltp"

    try:
        subject = "ASR Verification Code"
        body = f"""
Hello {username},

Your verification code is: {verify_code}

Please copy this code into the website to activate your account.

Thank you,
ASR+LLM System
"""
        import smtplib
        from email.mime.text import MIMEText
        from email.header import Header

        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [email], msg.as_string())

        return {"msg": f"ğŸ“© é©—è­‰ä¿¡å·²æˆåŠŸå¯„è‡³ {email}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯„ä¿¡å¤±æ•—: {str(e)}")
    
# ==========================================
# âœ… å¿˜è¨˜å¯†ç¢¼ï¼šSend Verify Code + Reset Password
# ==========================================
class ForgotPasswordRequest(BaseModel):
    email: str

class VerifyResetCodeRequest(BaseModel):
    email: str
    code: str

class ResetPasswordRequest(BaseModel):
    email: str
    code: str
    new_password: str


@app.post("/auth/forgot-password/send-code")
def send_reset_code(data: ForgotPasswordRequest):
    """
    ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨è€…è¼¸å…¥ Email â†’ å¯„å‡ºé©—è­‰ç¢¼
    """
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT username FROM patients WHERE email=?", (data.email,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="æŸ¥ç„¡æ­¤ Emailï¼Œè«‹ç¢ºèªè¼¸å…¥æ˜¯å¦æ­£ç¢º")

    username = row[0]
    reset_code = str(random.randint(100000, 999999))

    # å»ºç«‹è¡¨æ ¼å­˜æ”¾ reset code
    cur.execute("""
        CREATE TABLE IF NOT EXISTS password_resets (
            email TEXT PRIMARY KEY,
            code TEXT,
            created_at TIMESTAMP
        )
    """)
    cur.execute("REPLACE INTO password_resets (email, code, created_at) VALUES (?, ?, ?)",
                (data.email, reset_code, datetime.now()))
    conn.commit()
    conn.close()

    # å¯„ä¿¡
    sender = "aaa2025819@gmail.com"
    smtp_host = "smtp.gmail.com"
    smtp_port = 587
    smtp_user = "aaa2025819@gmail.com"
    smtp_pass = "ssjuayuhpfugwltp"  # âš ï¸ Gmail æ‡‰ç”¨å°ˆç”¨å¯†ç¢¼

    subject = "ASR Password Reset Code"
    body = f"""
Hello {username},

Your password reset code is: {reset_code}

Please enter this code on the website to reset your password.

Thank you,
ASR+LLM System
"""

    try:
        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = data.email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [data.email], msg.as_string())

        return {"msg": f"ğŸ“© é©—è­‰ç¢¼å·²å¯„å‡ºè‡³ {data.email}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯„ä¿¡å¤±æ•—: {str(e)}")


@app.post("/auth/forgot-password/verify-code")
def verify_reset_code(data: VerifyResetCodeRequest):
    """
    ç¬¬äºŒæ­¥ï¼šä½¿ç”¨è€…è¼¸å…¥é©—è­‰ç¢¼ â†’ é©—è­‰
    """
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT code, created_at FROM password_resets WHERE email=?", (data.email,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°é©—è­‰ç¢¼è¨˜éŒ„")

    saved_code, created_at = row
    if data.code.strip() != saved_code:
        conn.close()
        raise HTTPException(status_code=400, detail="é©—è­‰ç¢¼éŒ¯èª¤")

    return {"msg": "âœ… é©—è­‰æˆåŠŸï¼Œè«‹è¨­å®šæ–°å¯†ç¢¼"}


import sys
from fastapi import HTTPException

import sys
from fastapi import HTTPException

@app.post("/auth/forgot-password/reset")
def reset_password(data: ResetPasswordRequest):
    conn = get_db()
    cur = conn.cursor()

    # 1) æª¢æŸ¥ reset code
    cur.execute("SELECT code FROM password_resets WHERE email=?", (data.email,))
    row = cur.fetchone()
    if not row or data.code.strip() != row[0].strip():
        conn.close()
        raise HTTPException(status_code=400, detail="é©—è­‰ç¢¼éŒ¯èª¤ï¼Œè«‹é‡æ–°è¼¸å…¥")

    # 2) æ›´æ–°å¯†ç¢¼
    new_hash = hash_password(data.new_password)
    cur.execute(
        "UPDATE patients SET password_hash=? WHERE email=?",
        (new_hash, data.email),
    )
    conn.commit()

    # â˜…é—œéµï¼šçœ‹æœ‰æ²’æœ‰çœŸçš„æ›´æ–°åˆ°è³‡æ–™
    print("DEBUG updated rows:", cur.rowcount); sys.stdout.flush()
    if cur.rowcount != 1:
        conn.close()
        raise HTTPException(status_code=404, detail="No patient row updated (email not found?)")

    # 3) æ¸…é™¤ reset code
    cur.execute("DELETE FROM password_resets WHERE email=?", (data.email,))
    conn.commit()
    conn.close()

    return {"msg": "âœ… å¯†ç¢¼å·²é‡è¨­æˆåŠŸï¼Œè«‹é‡æ–°ç™»å…¥"}

# --- å»ºç«‹è¡¨æ ¼ï¼ˆå®‰å…¨ä¿éšªï¼Œè‹¥è¡¨ä¸å­˜åœ¨è‡ªå‹•å»ºç«‹ä¸€æ¬¡ï¼‰ ---
def ensure_task_table():
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS tasks (
        id TEXT PRIMARY KEY,
        title TEXT NOT NULL,
        description TEXT,
        category TEXT CHECK(category IN ('daily','weekly','monthly')) NOT NULL,
        due_date TEXT,
        total_times INTEGER DEFAULT 0,
        progress_times INTEGER DEFAULT 0,
        integral INTEGER DEFAULT 0,
        status TEXT DEFAULT 'pending',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """)
    conn.commit()
    conn.close()

def ensure_task_table_v2():
    """
    âœ… tasks table v2
    - æ”¯æ´ user å¤š task
    - æ”¯æ´ training task: super_type/sub_type/language/day_index/allocated_at
    - æ”¯æ´ sentence/vocab: task_kind
    - é ç•™ task_key
    """
    conn = get_db()
    cur = conn.cursor()

    # 1) å…ˆç¢ºä¿èˆŠè¡¨å­˜åœ¨ï¼ˆæ²¿ç”¨ä½ åŸæœ¬çµæ§‹ï¼‰
    cur.execute("""
    CREATE TABLE IF NOT EXISTS tasks (
        id TEXT PRIMARY KEY,
        title TEXT NOT NULL,
        description TEXT,
        category TEXT CHECK(category IN ('daily','weekly','monthly')) NOT NULL,
        due_date TEXT,
        total_times INTEGER DEFAULT 0,
        progress_times INTEGER DEFAULT 0,
        integral INTEGER DEFAULT 0,
        status TEXT DEFAULT 'pending',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """)
    conn.commit()

    # 2) å¢åŠ æ¬„ä½ï¼ˆSQLite å…è¨±é€å€‹ ADD COLUMNï¼‰
    cur.execute("PRAGMA table_info(tasks);")
    cols = {r[1] for r in cur.fetchall()}

    def add_col(sql: str):
        cur.execute(sql)
        conn.commit()

    # âœ… reward claim (one-time +50 from Task page)
    if "reward_claimed" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN reward_claimed INTEGER NOT NULL DEFAULT 0;")

    if "reward_claimed_at" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN reward_claimed_at TIMESTAMP;")

    if "user_id" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN user_id TEXT;")  # èˆŠè³‡æ–™å¯ NULL

    if "super_type" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN super_type TEXT;")

    if "sub_type" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN sub_type TEXT;")

    if "language" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN language TEXT NOT NULL DEFAULT 'en';")

    if "allocated_at" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN allocated_at TIMESTAMP;")

    if "valid_days" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN valid_days INTEGER NOT NULL DEFAULT 7;")

    if "day_index" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN day_index INTEGER NOT NULL DEFAULT 1;")

    if "is_active" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN is_active INTEGER NOT NULL DEFAULT 1;")

    # ä½ è¦çš„ï¼šsentence/vocab
    if "task_kind" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN task_kind TEXT NOT NULL DEFAULT 'vocab';")

    # é ç•™ï¼šåŒæ—¥åŒ subtype å¤š task æ™‚ç”¨
    if "task_key" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN task_key TEXT;")

    if "updated_at" not in cols:
        add_col("ALTER TABLE tasks ADD COLUMN updated_at TIMESTAMP;")
        # å…ˆæŠŠç¾æœ‰ row è£œå€¼
        cur.execute("UPDATE tasks SET updated_at = COALESCE(updated_at, CURRENT_TIMESTAMP)")
    # 3) indexesï¼ˆé¿å…æŸ¥è©¢æ…¢ï¼‰
    cur.execute("""
        CREATE INDEX IF NOT EXISTS idx_tasks_user_training
        ON tasks(user_id, super_type, sub_type, language, is_active, allocated_at, day_index);
    """)
    cur.execute("""
        CREATE INDEX IF NOT EXISTS idx_tasks_user_created
        ON tasks(user_id, created_at);
    """)

    conn.commit()
    conn.close()


def _task_allowed_day_index(allocated_at: str | None) -> int | None:
    """
    allocated_at: DB å­—ä¸²ï¼ˆYYYY-MM-DD HH:MM:SSï¼‰æˆ– None
    å›å‚³ allowed_day_index = days_since + 1 (1..7)
    è¶…é 7 æ—¥å›å‚³ None
    """
    if not allocated_at:
        return None
    try:
        base_date = datetime.strptime(str(allocated_at)[:19], "%Y-%m-%d %H:%M:%S").date()
    except Exception:
        # æœ‰äº› sqlite timestamp å¯èƒ½æ˜¯ ISO
        try:
            base_date = datetime.fromisoformat(str(allocated_at)).date()
        except Exception:
            return None

    today = datetime.now().date()
    days_since = (today - base_date).days
    if days_since < 0 or days_since > 6:
        return None
    return days_since + 1

class TodayTrainingTaskResp(BaseModel):
    available: bool
    allowed_day_index: Optional[int] = None
    reason: Optional[str] = None
    task: Optional[dict] = None

@app.get("/api/tasks/training/today", response_model=TodayTrainingTaskResp)
def api_tasks_training_today(
    super_type: str = Query(...),
    sub_type: str = Query(...),
    language: str = Query("cn"),
    task_kind: str = Query("vocab"),
    current_user_id: str = Depends(get_current_user_id),
):
    lang = normalize_practice_language(language)
    super_type = (super_type or "").strip()
    sub_type = (sub_type or "").strip()
    task_kind = (task_kind or "vocab").strip().lower()

    if task_kind not in ("vocab", "sentence"):
        raise HTTPException(status_code=400, detail="Invalid task_kind (vocab|sentence)")

    conn = get_db()
    cur = conn.cursor()
    try:
        # 1) æ‰¾æœ€æ–°ä¸€æ‰¹ allocated_atï¼ˆbatchï¼‰
        cur.execute("""
            SELECT allocated_at
            FROM tasks
            WHERE user_id=?
              AND super_type=?
              AND sub_type=?
              AND language=?
              AND task_kind=?
              AND is_active=1
              AND allocated_at IS NOT NULL
            ORDER BY datetime(allocated_at) DESC
            LIMIT 1
        """, (current_user_id, super_type, sub_type, lang, task_kind))
        r = cur.fetchone()
        if not r or not r[0]:
            return TodayTrainingTaskResp(available=False, reason="NO_TASK")

        allocated_at = r[0]

        # 2) ç®—ä»Šæ—¥ allowed day (1..7)ï¼ŒéæœŸå°± EXPIRED
        allowed = _task_allowed_day_index(allocated_at)
        if allowed is None:
            return TodayTrainingTaskResp(available=False, reason="EXPIRED", allowed_day_index=None)

        # 3) ç›´æ¥æ”ã€Œä»Šæ—¥å—°ä¸€æ—¥ã€(day_index == allowed) å—°ç­† task
        cur.execute("""
            SELECT
              id, user_id, super_type, sub_type, task_kind, language,
              allocated_at, day_index, total_times, progress_times, status, is_active
            FROM tasks
            WHERE user_id=?
              AND super_type=?
              AND sub_type=?
              AND language=?
              AND task_kind=?
              AND is_active=1
              AND datetime(allocated_at)=datetime(?)
              AND day_index=?
            LIMIT 1
        """, (current_user_id, super_type, sub_type, lang, task_kind, allocated_at, int(allowed)))
        row = cur.fetchone()

        # ä»Šæ—¥æ‡‰åšå—°ç­†éƒ½æµå””åˆ°ï¼šå°±å””æä¾›
        if not row:
            return TodayTrainingTaskResp(
                available=False,
                reason="NOT_TODAY_TASK_DAY",
                allowed_day_index=allowed
            )

        (tid, uid, st, sb, kind, lg, alloc, day_index,
         total_times, progress_times, status, is_active) = row

        task_obj = {
            "id": tid,
            "user_id": uid,
            "super_type": st,
            "sub_type": sb,
            "type": kind,  # ä½ å‰ç«¯ç”¨ taskInfo.type
            "language": lg,
            "allocated_at": alloc,
            "day_index": int(day_index),
            "total_times": int(total_times or 0),
            "progress_times": int(progress_times or 0),
            "status": status,
            "is_active": int(is_active or 0),
        }

        return TodayTrainingTaskResp(
            available=True,
            allowed_day_index=allowed,
            reason=None,
            task=task_obj
        )

    finally:
        conn.close()

class TrainingTaskIncrementReq(BaseModel):
    task_id: str
    increment: int = 1

class TrainingTaskIncrementResp(BaseModel):
    msg: str
    task_id: str
    progress_times: int
    total_times: int
    status: str

@app.post("/api/tasks/training/increment", response_model=TrainingTaskIncrementResp)
def api_tasks_training_increment(
    data: TrainingTaskIncrementReq,
    current_user_id: str = Depends(get_current_user_id),
):
    inc = int(data.increment or 1)
    if inc <= 0 or inc > 10:
        raise HTTPException(status_code=400, detail="Invalid increment")

    conn = get_db()
    cur = conn.cursor()

    # 1) load task
    cur.execute("""
        SELECT
          id, user_id, super_type, sub_type, task_kind, language,
          allocated_at, day_index, total_times, progress_times, status, is_active
        FROM tasks
        WHERE id=?
        LIMIT 1
    """, (data.task_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="Task not found")

    (tid, uid, super_type, sub_type, task_kind, lang,
     allocated_at, day_index, total_times, progress_times, status, is_active) = row

    if uid != current_user_id:
        conn.close()
        raise HTTPException(status_code=403, detail="Not allowed")

    if int(is_active or 0) != 1:
        conn.close()
        raise HTTPException(status_code=400, detail="Task inactive")

    allowed = _task_allowed_day_index(allocated_at)
    if allowed is None:
        conn.close()
        raise HTTPException(status_code=400, detail="Task expired")

    if int(day_index) != int(allowed):
        conn.close()
        raise HTTPException(status_code=400, detail=f"Not allowed day. allowed_day_index={allowed}")

    # 2) increment
    total = int(total_times or 0)
    prog = int(progress_times or 0)
    new_prog = prog + inc
    if total > 0:
        new_prog = min(new_prog, total)

    was_completed = (str(status or "").lower() == "completed")

    new_status = status
    if total > 0 and new_prog >= total:
        new_status = "completed"

    cur.execute("""
        UPDATE tasks
        SET progress_times=?,
            status=?
        WHERE id=?
    """, (new_prog, new_status, tid))

    # âœ… è‹¥é€™ä¸€æ—¥è®Š completedï¼Œå˜—è©¦æŠŠæ•´æ‰¹ day1..7 åšå®Œå°±é—œé–‰ï¼ˆis_active=0ï¼‰
    if str(new_status or "").lower() == "completed":
        deactivate_batch_if_fully_completed(
            cur,
            user_id=current_user_id,
            super_type=super_type,
            sub_type=sub_type,
            language=lang,        # é€™è£¡æ˜¯ tasks.language å€¼ï¼ˆcn/enï¼‰
            task_kind=task_kind,
            allocated_at=allocated_at,
        )

    became_completed_now = (not was_completed) and (str(new_status).lower() == "completed")
    if became_completed_now:
        award_points_on_task_completed(cur, current_user_id, tid, points=100)

    conn.commit()
    conn.close()

    return TrainingTaskIncrementResp(
        msg="ok",
        task_id=tid,
        progress_times=new_prog,
        total_times=total,
        status=new_status
    )
# ------------------------------------------------------------
# ğŸ“Œ 1ï¸âƒ£ å»ºç«‹ä»»å‹™ï¼ˆç®¡ç†å“¡æˆ–å¤–éƒ¨é é¢å‘¼å«ï¼‰
# ------------------------------------------------------------
@app.post("/api/tasks/create")
def create_task(
    title: str = Form(...),
    description: str = Form(""),
    category: str = Form(...),
    due_date: str = Form(None),
    total_times: int = Form(0),
    integral: int = Form(0),
):
    conn = get_db()
    cur = conn.cursor()
    task_id = str(uuid.uuid4())

    try:
        cur.execute("""
            INSERT INTO tasks (id, title, description, category, due_date, total_times, progress_times, integral)
            VALUES (?, ?, ?, ?, ?, ?, 0, ?)
        """, (task_id, title, description, category, due_date, total_times, integral))
        conn.commit()
        return {"msg": "âœ… ä»»å‹™å»ºç«‹æˆåŠŸ", "task_id": task_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å»ºç«‹ä»»å‹™å¤±æ•—ï¼š{str(e)}")
    finally:
        conn.close()


# ------------------------------------------------------------
# ğŸ“Œ 2ï¸âƒ£ ä½¿ç”¨è€…é ˜å–ä»»å‹™ï¼ˆå°‡ task_id å­˜å…¥ patientsï¼‰
# ------------------------------------------------------------
@app.post("/api/tasks/take")
def take_task(
    task_id: str = Form(...),
    current_user_id: str = Depends(get_current_user_id)
):
    conn = get_db()
    cur = conn.cursor()

    # ç¢ºèªä»»å‹™å­˜åœ¨
    cur.execute("SELECT id FROM tasks WHERE id=?", (task_id,))
    task = cur.fetchone()
    if not task:
        conn.close()
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    # æ›´æ–°ç”¨æˆ¶ task_id
    cur.execute("UPDATE patients SET task_id=? WHERE id=?", (task_id, current_user_id))
    conn.commit()
    conn.close()
    return {"msg": f"âœ… å·²é ˜å–ä»»å‹™ {task_id}"}


# ------------------------------------------------------------
# ğŸ“Œ 3ï¸âƒ£ æ›´æ–°ä»»å‹™é€²åº¦èˆ‡ç©åˆ†ï¼ˆä½¿ç”¨è€…å®Œæˆä¸€æ¬¡ä»»å‹™ï¼‰
# ------------------------------------------------------------
@app.post("/api/tasks/set-progress")
def set_task_progress(
    increment: int = Form(1),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    ç•¶ä½¿ç”¨è€…å®Œæˆä¸€æ¬¡ä»»å‹™æ™‚å‘¼å«æ­¤APIï¼š
    - é€²åº¦ + increment
    - è‹¥å®Œæˆå…¨éƒ¨æ¬¡æ•¸ â†’ ç‹€æ…‹æ”¹ç‚º completed
    - ä¸¦å¢åŠ ä½¿ç”¨è€…ç©åˆ†
    """
    conn = get_db()
    cur = conn.cursor()
    try:
        # æŸ¥å‡ºè©²ä½¿ç”¨è€…çš„ä»»å‹™ ID
        cur.execute("SELECT task_id FROM patients WHERE id=?", (current_user_id,))
        row = cur.fetchone()
        if not row or not row[0]:
            raise HTTPException(status_code=400, detail="æ­¤ä½¿ç”¨è€…ç›®å‰æ²’æœ‰ä»»å‹™")

        task_id = row[0]

        # æŸ¥ä»»å‹™è³‡æ–™
        cur.execute("SELECT total_times, progress_times, integral FROM tasks WHERE id=?", (task_id,))
        trow = cur.fetchone()
        if not trow:
            raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°ä»»å‹™")

        total, progress, task_integral = trow
        new_progress = min(progress + increment, total)
        status = "completed" if new_progress >= total and total > 0 else "pending"

        # æ›´æ–°ä»»å‹™ç‹€æ…‹èˆ‡é€²åº¦
        cur.execute(
            "UPDATE tasks SET progress_times=?, status=? WHERE id=?",
            (new_progress, status, task_id)
        )

        # è‹¥é”æˆ -> å¢åŠ ç©åˆ†çµ¦è©²ä½¿ç”¨è€…
        if status == "completed":
            cur.execute(
                "UPDATE patients SET integral = integral + ? WHERE id=?",
                (task_integral, current_user_id)
            )

        conn.commit()
        return {
            "msg": f"âœ… ä»»å‹™é€²åº¦æ›´æ–°æˆåŠŸ ({new_progress}/{total})",
            "status": status,
            "added_integral": task_integral if status == "completed" else 0
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ä»»å‹™é€²åº¦ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
    finally:
        conn.close()


# ------------------------------------------------------------
# ğŸ“Œ 4ï¸âƒ£ ç€è¦½ä»»å‹™æ¸…å–®ï¼ˆåˆ†é¡ daily/weekly/monthlyï¼‰
# ------------------------------------------------------------
@app.get("/api/tasks/list")
def list_tasks(
    category: str = Query(None),
    current_user_id: str = Depends(get_current_user_id)
):
    conn = get_db()
    cur = conn.cursor()
    sql = "SELECT id, title, description, category, due_date, total_times, progress_times, integral, status FROM tasks"
    params = []
    if category:
        sql += " WHERE category=?"
        params.append(category)
    sql += " ORDER BY created_at DESC"
    cur.execute(sql, params)
    rows = cur.fetchall()
    conn.close()

    result = [
        {
            "id": r[0],
            "title": r[1],
            "description": r[2],
            "category": r[3],
            "due_date": r[4],
            "total_times": r[5],
            "progress_times": r[6],
            "integral": r[7],
            "status": r[8],
        }
        for r in rows
    ]
    return {"tasks": result}

def ensure_staff_verify_table():
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS staff_email_verifies (
        email TEXT,
        role TEXT,
        code TEXT,
        created_at TIMESTAMP,
        PRIMARY KEY (email, role)
    )
    """)
    conn.commit()
    conn.close()
# ==============================
# âœ… Staff (SLP / Admin) Auth APIs
# ==============================

class StaffRegister(BaseModel):
    username: str
    password: str
    email: Optional[str] = None
    name: Optional[str] = None
    role: str  # 'slp' or 'admin'
    license_number: Optional[str] = None
    organization: Optional[str] = None
    description: Optional[str] = None   # âœ… æ–°å¢
    language: Optional[str] = "en"

class StaffLogin(BaseModel):
    email: str
    password: str
    role: str   # 'slp' or 'admin'

def get_current_staff_id(token: str = Depends(oauth2_scheme)):
    """
    staffToken ä½¿ç”¨åŒä¸€å€‹ oauth2_schemeï¼Œä½† payload æœƒå¸¶ staff=1
    """
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        staff_id = payload.get("sub")
        is_staff = payload.get("staff")
        if not staff_id or is_staff != 1:
            raise HTTPException(status_code=401, detail="Invalid staff token")
        return staff_id
    except JWTError:
        raise HTTPException(status_code=401, detail="Token expired or invalid")


@app.post("/staff/register")
def staff_register(data: StaffRegister):
    ensure_staff_verify_table()
    """
    SLP/Admin ç”³è«‹å¸³è™Ÿï¼š
    - å»ºç«‹ staff_users (verify=0, is_approved=0)
    - å¯„å‡º email é©—è­‰ç¢¼ï¼Œå¯«å…¥ staff_email_verifies
    - âœ… åªæœ‰ verify=1 æ‰ç®—å®Œæˆç”³è«‹ï¼ˆå¾ŒçºŒæ‰å…è¨±ç™»å…¥ / æ‰å…è¨±é€²å¯©æ ¸æµç¨‹ï¼‰
    """
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role (must be 'slp' or 'admin')")

    if not data.email:
        raise HTTPException(status_code=400, detail="Email is required")

    if role == "slp" and (not data.license_number or not data.license_number.strip()):
        raise HTTPException(status_code=400, detail="License number is required for SLP")

    conn = get_db()
    cur = conn.cursor()

    # username unique
    cur.execute("SELECT 1 FROM staff_users WHERE username=?", (data.username,))
    if cur.fetchone():
        conn.close()
        raise HTTPException(status_code=400, detail="âŒ Username already exists")

    # âœ… email+role uniqueï¼ˆç¬¦åˆä½ è¦çš„ï¼šåŒ role ä¸å¯é‡è¤‡ï¼Œä¸åŒ role å¯é‡è¤‡ï¼‰
    cur.execute("SELECT 1 FROM staff_users WHERE email=? AND role=?", (data.email, role))
    if cur.fetchone():
        conn.close()
        raise HTTPException(status_code=400, detail="âŒ Email already exists for this role")

    # ç”¢ç”Ÿ 6 ä½é©—è­‰ç¢¼
    verify_code = str(random.randint(100000, 999999))

    # å¯„é€é©—è­‰ä¿¡ï¼ˆæ²¿ç”¨ä½  patient çš„å¯„ä¿¡è¨­å®šï¼‰
    try:
        sender = "aaa2025819@gmail.com"
        smtp_host = "smtp.gmail.com"
        smtp_port = 587
        smtp_user = "aaa2025819@gmail.com"
        smtp_pass = "ssjuayuhpfugwltp"

        subject = "Staff Email Verification Code"
        body = f"""
Hello {data.username},

Your staff verification code is: {verify_code}

Role: {role}

Please enter this code to verify your staff email before your application can be submitted.

Thank you,
ASR+LLM System
"""
        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = data.email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [data.email], msg.as_string())

    except Exception as e:
        conn.close()
        raise HTTPException(status_code=500, detail=f"Email send failed: {e}")

    # å»ºç«‹ staff_usersï¼ˆverify=0ï¼‰
    staff_id = str(uuid.uuid4())
    cur.execute("""
        INSERT INTO staff_users
        (id, username, password_hash, name, email, role, license_number, organization, description, language,
        verify, staff_picture, is_approved)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 0, NULL, 0)
    """, (
        staff_id,
        data.username,
        hash_password(data.password),
        data.name,
        data.email,
        role,
        data.license_number,
        data.organization,
        data.description,      # âœ… æ–°å¢
        data.language
    ))

    # âœ… å„²å­˜é©—è­‰ç¢¼ï¼ˆç”¨ email+role åš key æ‰ä¸æœƒæ’ï¼‰
    # ä½ çš„ staff_email_verifies ç›®å‰åªæœ‰ email PKï¼Œæœƒæ’ä¸åŒ roleã€‚
    # ğŸ‘‰ å»ºè­°ä½ æŠŠ staff_email_verifies æ”¹æˆ (email, role) è¤‡åˆ PKã€‚
    # æš«æ™‚å…ˆç”¨ email+role æ‹¼æˆä¸€å€‹ key å­—ä¸²ä¾†é¿é–‹æ’ï¼ˆä¸æ”¹ DB çš„æƒ…æ³ä¸‹ï¼‰ã€‚
    cur.execute(
        "INSERT OR REPLACE INTO staff_email_verifies (email, role, code, created_at) VALUES (?, ?, ?, ?)",
        (data.email, role, verify_code, datetime.now())
    )

    conn.commit()
    conn.close()

    return {
        "msg": f"ğŸ“© Staff verification code sent to {data.email}. Please verify before your application is submitted.",
        "id": staff_id,
        "username": data.username,
        "email": data.email,
        "role": role,
        "verify": 0,
        "is_approved": 0
    }

@app.post("/staff/login")
def staff_login(
    data: StaffLogin,
    response: Response,
    send_cookie: bool = Query(SEND_USERNAME_COOKIE_DEFAULT, description="æ˜¯å¦ä¸‹ç™¼ staff_email cookie"),
):
    print("DEBUG staff_login role =", repr(data.role))
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role")

    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT id, password_hash, role, is_approved, username, email, verify
        FROM staff_users
        WHERE email=? AND role=?
    """, (data.email, role))
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=401, detail="Invalid email or password")

    staff_id, password_hash_db, role, is_approved, username, email, verify = row

    if not verify_password(data.password, password_hash_db):
        raise HTTPException(status_code=401, detail="Invalid email or password")

    # âœ… å¿…é ˆ email verify=1 æ‰èƒ½ç™»å…¥ï¼ˆç¬¦åˆä½ çš„è¦å‰‡ï¼‰
    if int(verify) != 1:
        raise HTTPException(status_code=403, detail="Email not verified")

    # approval gate
    if int(is_approved) == 0:
        raise HTTPException(status_code=403, detail="Account pending approval")
    if int(is_approved) == 2:
        raise HTTPException(status_code=403, detail="Account rejected")

    expire = datetime.utcnow() + timedelta(hours=12)
    token_data = {"sub": staff_id, "exp": expire, "staff": 1, "role": role}
    staff_token = jwt.encode(token_data, SECRET_KEY, algorithm=ALGORITHM)

    if send_cookie and email:
        response.set_cookie(
            key="staff_email",
            value=email,
            httponly=False,
            samesite="Lax",
        )

    return {
        "msg": "Staff login successful",
        "staffToken": staff_token,
        "id": staff_id,
        "username": username,
        "email": email,
        "role": role
    }

@app.get("/staff/me")
def staff_me(current_staff_id: str = Depends(get_current_staff_id)):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT id, username, name, email, role, license_number, organization,
               description, language, verify, is_approved, created_at, staff_picture
        FROM staff_users
        WHERE id=?
    """, (current_staff_id,))
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=404, detail="Staff not found")

    return {
        "staff": {
            "id": row[0],
            "username": row[1],
            "name": row[2],
            "email": row[3],
            "role": row[4],
            "license_number": row[5],
            "organization": row[6],
            "description": row[7],
            "language": row[8],
            "verify": row[9],
            "is_approved": row[10],
            "created_at": row[11],
            "staff_picture": row[12],
        }
    }
class StaffVerifyCodeRequest(BaseModel):
    email: str
    role: str
    code: str

@app.post("/staff/verify-code")
def staff_verify_code(data: StaffVerifyCodeRequest):
    """
    staff email é©—è­‰ï¼š
    - æ¯”å° staff_email_verifies çš„ codeï¼ˆç”¨ email + roleï¼‰
    - æˆåŠŸå¾ŒæŠŠ staff_users.verify è¨­ç‚º 1
    - åˆªé™¤é©—è­‰ç¢¼
    """
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role")

    email = (data.email or "").strip()
    if not email:
        raise HTTPException(status_code=400, detail="Email is required")

    conn = get_db()
    cur = conn.cursor()
    try:
        # âœ… ç”¨ (email, role) æŸ¥é©—è­‰ç¢¼
        cur.execute(
            "SELECT code FROM staff_email_verifies WHERE email=? AND role=?",
            (email, role)
        )
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Verification code not found")

        db_code = row[0]
        if str(data.code).strip() != str(db_code).strip():
            raise HTTPException(status_code=400, detail="Incorrect verification code")

        # âœ… æ›´æ–° staff_users.verify=1
        cur.execute(
            "UPDATE staff_users SET verify=1 WHERE email=? AND role=?",
            (email, role)
        )
        conn.commit()

        # âœ… åˆªé™¤é©—è­‰ç¢¼ï¼ˆåŒæ¨£ç”¨ email + roleï¼‰
        cur.execute(
            "DELETE FROM staff_email_verifies WHERE email=? AND role=?",
            (email, role)
        )
        conn.commit()

        return {"msg": "âœ… Staff email verified. Your application is now submitted."}

    finally:
        conn.close()

@app.post("/staff/upload-picture")
async def upload_staff_picture(
    file: UploadFile = File(...),
    staff_token: Optional[str] = Cookie(None),
    token: Optional[str] = Cookie(None),   # ä¿ç•™å…¼å®¹èˆŠçš„
    response: Response = None
):
    jwt_token = staff_token or token
    if not jwt_token:
        raise HTTPException(status_code=401, detail="âŒ æ²’æœ‰ç™»å…¥ Token")

    # âœ… æ­£ç¢ºï¼šç”¨ jwt_token decode
    try:
        payload = jwt.decode(jwt_token, SECRET_KEY, algorithms=[ALGORITHM])
        staff_id = payload.get("sub")
        is_staff = payload.get("staff")
        if not staff_id or is_staff != 1:
            raise HTTPException(status_code=401, detail="âŒ Token ä¸æ˜¯ staff")
    except JWTError as e:
        raise HTTPException(status_code=401, detail=f"âŒ Token éŒ¯èª¤æˆ–éæœŸ: {str(e)}")

    if not file.filename:
        raise HTTPException(status_code=400, detail="âŒ æœªæ”¶åˆ°æª”æ¡ˆæˆ–æª”åç‚ºç©º")

    filename = file.filename.lower()
    if not (filename.endswith(".png") or filename.endswith(".jpg") or filename.endswith(".jpeg")):
        raise HTTPException(status_code=400, detail="âŒ åƒ…å…è¨± PNG / JPG / JPEG")

    contents = await file.read()
    file_size_kb = len(contents) / 1024
    if file_size_kb > 1000:
        raise HTTPException(status_code=400, detail="âŒ æª”æ¡ˆå¤§å°è¶…éé™åˆ¶ï¼ˆæœ€å¤§ 1MBï¼‰")

    # å­˜æª”è·¯å¾‘
    staff_dir = os.path.join(USER_ROOT_DIR, "staff", str(staff_id), "picture")
    os.makedirs(staff_dir, exist_ok=True)

    # åˆªèˆŠåœ–
    for old in os.listdir(staff_dir):
        try:
            os.remove(os.path.join(staff_dir, old))
        except Exception:
            pass

    ext = ".png" if filename.endswith(".png") else ".jpg"
    file_name = f"profile{ext}"
    save_path = os.path.join(staff_dir, file_name)
    with open(save_path, "wb") as f:
        f.write(contents)

    # æ›´æ–° DB
    relative_path = f"User/staff/{staff_id}/picture/{file_name}"
    conn = get_db()
    cur = conn.cursor()
    cur.execute("UPDATE staff_users SET staff_picture=? WHERE id=?", (relative_path, staff_id))
    conn.commit()
    conn.close()

    public_url = f"/{relative_path}"

    # å¯é¸å¯« cookie
    if response:
        response.set_cookie(
            key="staff_picture_url",
            value=public_url,
            httponly=False,
            samesite="Lax",
            secure=True
        )

    return {"msg": "âœ… ä¸Šå‚³æˆåŠŸ", "staff_picture_url": public_url}


class StaffResendVerifyRequest(BaseModel):
    email: str
    role: str

@app.post("/staff/resend-verify")
def staff_resend_verify(data: StaffResendVerifyRequest):
    ensure_staff_verify_table()
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role")

    email = (data.email or "").strip()
    if not email:
        raise HTTPException(status_code=400, detail="Email is required")

    conn = get_db()
    cur = conn.cursor()

    # ç¢ºèª staff å¸³è™Ÿå­˜åœ¨ï¼ˆemail+roleï¼‰
    cur.execute("SELECT username FROM staff_users WHERE email=? AND role=?", (email, role))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="Staff account not found")

    username = row[0]
    verify_code = str(random.randint(100000, 999999))

    # æ›´æ–°/å¯«å…¥é©—è­‰ç¢¼
    cur.execute(
        "INSERT OR REPLACE INTO staff_email_verifies (email, role, code, created_at) VALUES (?, ?, ?, ?)",
        (email, role, verify_code, datetime.now())
    )
    conn.commit()
    conn.close()

    # å¯„ä¿¡ï¼ˆæ²¿ç”¨ä½ æ—¢æœ‰ Gmail è¨­å®šï¼‰
    try:
        sender = "aaa2025819@gmail.com"
        smtp_host = "smtp.gmail.com"
        smtp_port = 587
        smtp_user = "aaa2025819@gmail.com"
        smtp_pass = "ssjuayuhpfugwltp"

        subject = "Staff Email Verification Code"
        body = f"""
Hello {username},

Your staff verification code is: {verify_code}

Role: {role}

Thank you,
ASR+LLM System
"""
        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [email], msg.as_string())

        return {"msg": f"ğŸ“© Staff verification code resent to {email}"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Email send failed: {str(e)}")


# ==========================================
# âœ… Staff Forgot Password (SLP/Admin)
# ==========================================
class StaffForgotPasswordRequest(BaseModel):
    email: str
    role: str  # slp | admin

class StaffVerifyResetCodeRequest(BaseModel):
    email: str
    role: str
    code: str

class StaffResetPasswordRequest(BaseModel):
    email: str
    role: str
    code: str
    new_password: str

def ensure_staff_password_reset_table():
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS staff_password_resets (
            email TEXT NOT NULL,
            role TEXT NOT NULL,
            code TEXT NOT NULL,
            created_at TIMESTAMP,
            PRIMARY KEY(email, role)
        )
    """)
    conn.commit()
    conn.close()


@app.post("/staff/forgot-password/send-code")
def staff_send_reset_code(data: StaffForgotPasswordRequest):
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role")

    email = (data.email or "").strip()
    if not email:
        raise HTTPException(status_code=400, detail="Email is required")

    conn = get_db()
    cur = conn.cursor()

    cur.execute("SELECT username FROM staff_users WHERE email=? AND role=?", (email, role))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="Staff account not found")

    username = row[0]
    reset_code = str(random.randint(100000, 999999))

    ensure_staff_password_reset_table()
    cur.execute(
        "INSERT OR REPLACE INTO staff_password_resets (email, role, code, created_at) VALUES (?, ?, ?, ?)",
        (email, role, reset_code, datetime.now())
    )
    conn.commit()
    conn.close()

    # send email (reuse your Gmail settings)
    sender = "aaa2025819@gmail.com"
    smtp_host = "smtp.gmail.com"
    smtp_port = 587
    smtp_user = "aaa2025819@gmail.com"
    smtp_pass = "ssjuayuhpfugwltp"

    subject = "ASR Staff Password Reset Code"
    body = f"""
Hello {username},

Your staff password reset code is: {reset_code}

Role: {role}

If you did not request this, please ignore this email.
"""

    try:
        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [email], msg.as_string())

        return {"msg": f"ğŸ“© Reset code sent to {email}"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Email send failed: {str(e)}")


@app.post("/staff/forgot-password/verify-code")
def staff_verify_reset_code(data: StaffVerifyResetCodeRequest):
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role")

    email = (data.email or "").strip()
    if not email:
        raise HTTPException(status_code=400, detail="Email is required")

    ensure_staff_password_reset_table()

    conn = get_db()
    cur = conn.cursor()
    cur.execute(
        "SELECT code, created_at FROM staff_password_resets WHERE email=? AND role=?",
        (email, role)
    )
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=404, detail="Reset code not found")

    saved_code = row[0]
    if str(data.code).strip() != str(saved_code).strip():
        raise HTTPException(status_code=400, detail="Incorrect reset code")

    return {"msg": "âœ… Code verified. Please set a new password."}


@app.post("/staff/forgot-password/reset")
def staff_reset_password(data: StaffResetPasswordRequest):
    role = (data.role or "").strip()
    if role not in ("slp", "admin"):
        raise HTTPException(status_code=400, detail="Invalid role")

    email = (data.email or "").strip()
    if not email:
        raise HTTPException(status_code=400, detail="Email is required")

    ensure_staff_password_reset_table()

    conn = get_db()
    cur = conn.cursor()

    # 1) verify code
    cur.execute(
        "SELECT code FROM staff_password_resets WHERE email=? AND role=?",
        (email, role)
    )
    row = cur.fetchone()
    if not row or str(data.code).strip() != str(row[0]).strip():
        conn.close()
        raise HTTPException(status_code=400, detail="Incorrect reset code")

    # 2) update password
    new_hash = hash_password(data.new_password)
    cur.execute(
        "UPDATE staff_users SET password_hash=? WHERE email=? AND role=?",
        (new_hash, email, role)
    )
    conn.commit()

    if cur.rowcount != 1:
        conn.close()
        raise HTTPException(status_code=404, detail="No staff row updated")

    # 3) clear reset code
    cur.execute(
        "DELETE FROM staff_password_resets WHERE email=? AND role=?",
        (email, role)
    )
    conn.commit()
    conn.close()

    return {"msg": "âœ… Password reset successful. Please login again."}


class CreateServiceSessionReq(BaseModel):
    topic: Optional[str] = None
    first_message: str

@app.post("/api/service/session")
def api_create_service_session(
    data: CreateServiceSessionReq,
    current_user_id: str = Depends(get_current_user_id)
):

    session_id = str(uuid.uuid4())
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            INSERT INTO service_sessions (id, patient_id, slp_id, topic, priority, status)
            VALUES (?, ?, NULL, ?, 0, 'queued')
        """, (session_id, current_user_id, data.topic))

        # ç¬¬ä¸€å‰‡è¨Šæ¯
        msg_id = str(uuid.uuid4())
        cur.execute("""
            INSERT INTO service_messages (id, session_id, sender_type, sender_id, message, message_type)
            VALUES (?, ?, 'patient', ?, ?, 'text')
        """, (msg_id, session_id, current_user_id, data.first_message))

        cur.execute("""
            UPDATE service_sessions
            SET last_message_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (session_id,))

        conn.commit()
    finally:
        conn.close()

    audit_log(
        "patient",
        current_user_id,
        "CREATE_SERVICE_SESSION",
        "service_session",
        session_id,
        metadata=json.dumps({"topic": data.topic}, ensure_ascii=False),
    )

    # âœ… å»ºç«‹å¾Œå˜—è©¦ auto allocateï¼ˆè¦å‰‡ï¼šåªæœ‰ waiting SLP æ‰æœƒæ´¾ï¼‰
    system_auto_allocate_one_db()

    return {"session_id": session_id}


@app.get("/api/service/session/{session_id}")

def api_get_service_session(
    session_id: str,
    current_user_id: str = Depends(get_current_user_id)
):

    conn = get_db()
    cur = conn.cursor()
    refresh_one_session_priority(cur, session_id)
    conn.commit()
    cur.execute("""
        SELECT id, patient_id, slp_id, topic, priority, status, created_at, last_message_at, closed_at, closed_by
        FROM service_sessions
        WHERE id=?
    """, (session_id,))
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=404, detail="session not found")

    # âœ… åªæœ‰è©²ç—…æ‚£æœ¬äººå¯ä»¥çœ‹ï¼ˆSLP ç‰ˆå¦å¤–åšï¼‰
    if row[1] != current_user_id:
        raise HTTPException(status_code=403, detail="not allowed")

    return {
        "id": row[0],
        "patient_id": row[1],
        "slp_id": row[2],
        "topic": row[3],
        "priority": row[4],
        "status": row[5],
        "created_at": row[6],
        "last_message_at": row[7],
        "closed_at": row[8],
        "closed_by": row[9],
    }


@app.get("/api/service/session/{session_id}/messages")
def api_get_service_messages(
    session_id: str,
    current_user_id: str = Depends(get_current_user_id)
):
    ensure_customer_service_tables()

    conn = get_db()
    cur = conn.cursor()

    # æ¬Šé™ï¼šç—…æ‚£æœ¬äºº
    cur.execute("SELECT patient_id FROM service_sessions WHERE id=?", (session_id,))
    srow = cur.fetchone()
    if not srow:
        conn.close()
        raise HTTPException(status_code=404, detail="session not found")
    if srow[0] != current_user_id:
        conn.close()
        raise HTTPException(status_code=403, detail="not allowed")

    cur.execute("""
        SELECT id, sender_type, sender_id, message, message_type, created_at
        FROM service_messages
        WHERE session_id=?
        ORDER BY created_at ASC
    """, (session_id,))
    items = [
        {
            "id": r[0],
            "sender_type": r[1],
            "sender_id": r[2],
            "message": r[3],
            "message_type": r[4],
            "created_at": r[5],
        }
        for r in cur.fetchall()
    ]
    conn.close()
    return {"items": items}

class PostServiceMessageReq(BaseModel):
    message: str

@app.post("/api/service/session/{session_id}/messages")
def api_post_service_message(
    session_id: str,
    data: PostServiceMessageReq,
    current_user_id: str = Depends(get_current_user_id)
):
    ensure_customer_service_tables()

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("SELECT patient_id, status FROM service_sessions WHERE id=?", (session_id,))
        srow = cur.fetchone()
        if not srow:
            raise HTTPException(status_code=404, detail="session not found")
        if srow[0] != current_user_id:
            raise HTTPException(status_code=403, detail="not allowed")
        if srow[1] in ("closed", "cancelled"):
            raise HTTPException(status_code=400, detail="session already closed")

        msg_id = str(uuid.uuid4())
        cur.execute("""
            INSERT INTO service_messages (id, session_id, sender_type, sender_id, message, message_type)
            VALUES (?, ?, 'patient', ?, ?, 'text')
        """, (msg_id, session_id, current_user_id, data.message))

        cur.execute("UPDATE service_sessions SET last_message_at=CURRENT_TIMESTAMP WHERE id=?", (session_id,))
        conn.commit()

        audit_log("patient", current_user_id, "POST_SERVICE_MESSAGE", "service_message", msg_id,
                  metadata=json.dumps({"session_id": session_id}, ensure_ascii=False))
        return {"message_id": msg_id}
    finally:
        conn.close()

@app.post("/api/service/session/{session_id}/close")
def api_close_service_session_customer(
    session_id: str,
    current_user_id: str = Depends(get_current_user_id)
):
    ensure_customer_service_tables()

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("SELECT patient_id, status FROM service_sessions WHERE id=?", (session_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="session not found")
        if row[0] != current_user_id:
            raise HTTPException(status_code=403, detail="not allowed")
        if row[1] == "closed":
            return {"msg": "already closed"}

        cur.execute("""
            UPDATE service_sessions
            SET status='closed', closed_at=CURRENT_TIMESTAMP, closed_by='patient'
            WHERE id=?
        """, (session_id,))
        conn.commit()

        audit_log("patient", current_user_id, "CLOSE_SERVICE_SESSION", "service_session", session_id)
        return {"msg": "closed"}
    finally:
        conn.close()


def get_current_staff_payload(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        staff_id = payload.get("sub")
        is_staff = payload.get("staff")
        if not staff_id or is_staff != 1:
            raise HTTPException(status_code=401, detail="Invalid staff token")
        return payload
    except JWTError:
        raise HTTPException(status_code=401, detail="Token expired or invalid")
    
def require_admin(payload: dict):
    if not payload or payload.get("staff") != 1 or payload.get("role") != "admin":
        raise HTTPException(status_code=403, detail="Admin only")
    

class SLPOnlineReq(BaseModel):
    online: bool

@app.post("/api/slp/online")
def api_slp_set_online(
    data: SLPOnlineReq,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP can set online")

    slp_id = payload["sub"]
    slp_set_online_db(slp_id, bool(data.online))
    audit_log("slp", slp_id, "SLP_SET_ONLINE", "slp_presence", slp_id,
              metadata=json.dumps({"online": bool(data.online)}, ensure_ascii=False))
    return {"slp_id": slp_id, "online": bool(data.online)}

class SLPWaitReq(BaseModel):
    waiting: bool  # True=é–‹å§‹ç­‰å¾…ï¼›False=å–æ¶ˆç­‰å¾…

@app.post("/api/slp/wait")
def api_slp_wait(
    data: SLPWaitReq,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP can wait")

    slp_id = payload["sub"]
    slp_wait_db(slp_id, bool(data.waiting))

    audit_log("slp", slp_id, "SLP_SET_WAITING", "slp_presence", slp_id,
              metadata=json.dumps({"waiting": bool(data.waiting)}, ensure_ascii=False))

    # âœ… é–‹å§‹ç­‰å¾…å¾Œï¼Œè®“ç³»çµ±å˜—è©¦æ´¾ä¸€å–®ï¼ˆå¦‚æœæœ‰ queuedï¼‰
    if data.waiting:
        system_auto_allocate_one_db()

    return {"slp_id": slp_id, "waiting": bool(data.waiting)}

@app.post("/api/slp/heartbeat")
def api_slp_heartbeat(payload: dict = Depends(get_current_staff_payload)):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    slp_heartbeat_db(slp_id)
    return {"slp_id": slp_id, "ok": True}

@app.get("/api/slp/sessions")
def api_slp_my_sessions(payload: dict = Depends(get_current_staff_payload)):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    conn = get_db()
    cur = conn.cursor()

    # âœ… refresh priority by waiting minutes (only increase)
    cur.execute("""
        UPDATE service_sessions
        SET priority = MAX(
            priority,
            CASE
                WHEN CAST((julianday('now') - julianday(created_at)) * 24 * 60 AS INTEGER) <= 5 THEN 0
                WHEN CAST((julianday('now') - julianday(created_at)) * 24 * 60 AS INTEGER) <= 10 THEN 1
                ELSE 2
            END
        )
        WHERE status IN ('queued','assigned','open')
    """)
    conn.commit()

    cur.execute("""
        SELECT id, patient_id, topic, priority, status, created_at, last_message_at
        FROM service_sessions
        WHERE slp_id=? AND status IN ('assigned','open')  
        ORDER BY created_at ASC
    """, (slp_id,))
    rows = cur.fetchall()
    conn.close()

    return {
        "items": [
            {
                "id": r[0],
                "patient_id": r[1],
                "topic": r[2],
                "priority": r[3],
                "status": r[4],
                "created_at": r[5],
                "last_message_at": r[6],
            }
            for r in rows
        ]
    }


def _parse_ymd(s: str) -> str:
    # å›å‚³ YYYY-MM-DDï¼ˆçµ¦ sqlite ç”¨ï¼‰
    try:
        return datetime.strptime(s, "%Y-%m-%d").strftime("%Y-%m-%d")
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid date format, use YYYY-MM-DD")

@app.get("/api/slp/stats")
def api_slp_stats(
    date_from: str = Query(..., alias="from", description="YYYY-MM-DD"),
    date_to: str = Query(..., alias="to", description="YYYY-MM-DD"),
    payload: dict = Depends(get_current_staff_payload),
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    d1 = _parse_ymd(date_from)
    d2 = _parse_ymd(date_to)

    conn = get_db()
    cur = conn.cursor()
    try:
        # -------------------------
        # 1) Sessions count (æœŸé–“å…§ created_at)
        # -------------------------
        cur.execute("""
            SELECT
              COUNT(*) AS total,
              SUM(CASE WHEN status='closed' THEN 1 ELSE 0 END) AS closed,
              SUM(CASE WHEN status IN ('assigned','open') THEN 1 ELSE 0 END) AS open_like
            FROM service_sessions
            WHERE slp_id=?
              AND date(created_at) BETWEEN date(?) AND date(?)
        """, (slp_id, d1, d2))
        r = cur.fetchone()
        sessions_total = int(r[0] or 0)
        sessions_closed = int(r[1] or 0)
        sessions_open_like = int(r[2] or 0)

        # -------------------------
        # 2) Avg close minutes (åªç®— closed ä¸” closed_at æœ‰å€¼)
        # -------------------------
        cur.execute("""
            SELECT
              AVG((julianday(closed_at) - julianday(created_at)) * 24 * 60)
            FROM service_sessions
            WHERE slp_id=?
              AND status='closed'
              AND closed_at IS NOT NULL
              AND date(closed_at) BETWEEN date(?) AND date(?)
        """, (slp_id, d1, d2))
        avg_close_minutes = cur.fetchone()[0]
        avg_close_minutes = float(avg_close_minutes) if avg_close_minutes is not None else None

        # -------------------------
        # 3) Messages count (æœŸé–“å…§ message created_at)
        # -------------------------
        cur.execute("""
            SELECT
              SUM(CASE WHEN m.sender_type='slp' THEN 1 ELSE 0 END) AS slp_messages,
              SUM(CASE WHEN m.sender_type='patient' THEN 1 ELSE 0 END) AS patient_messages
            FROM service_messages m
            JOIN service_sessions s ON s.id = m.session_id
            WHERE s.slp_id=?
              AND date(m.created_at) BETWEEN date(?) AND date(?)
        """, (slp_id, d1, d2))
        r = cur.fetchone()
        slp_messages = int(r[0] or 0)
        patient_messages = int(r[1] or 0)

        # -------------------------
        # 4) Avg first response minutes
        # å®šç¾©ï¼šåŒä¸€ session ä¸­
        # - first_patient_at = MIN(patient msg time)
        # - first_slp_at = MIN(slp msg time)
        # åªè¨ˆç®— first_slp_at >= first_patient_at ä¸”å…©è€…çš†å­˜åœ¨
        # -------------------------
        cur.execute("""
            WITH firsts AS (
              SELECT
                s.id AS session_id,
                MIN(CASE WHEN m.sender_type='patient' THEN m.created_at END) AS first_patient_at,
                MIN(CASE WHEN m.sender_type='slp' THEN m.created_at END)     AS first_slp_at
              FROM service_sessions s
              JOIN service_messages m ON m.session_id = s.id
              WHERE s.slp_id=?
                AND date(s.created_at) BETWEEN date(?) AND date(?)
              GROUP BY s.id
            )
            SELECT AVG((julianday(first_slp_at) - julianday(first_patient_at)) * 24 * 60)
            FROM firsts
            WHERE first_patient_at IS NOT NULL
              AND first_slp_at IS NOT NULL
              AND julianday(first_slp_at) >= julianday(first_patient_at)
        """, (slp_id, d1, d2))
        avg_first_response_minutes = cur.fetchone()[0]
        avg_first_response_minutes = float(avg_first_response_minutes) if avg_first_response_minutes is not None else None

        return {
            "slp_id": slp_id,
            "range": {"from": d1, "to": d2},
            "sessions": {
                "total": sessions_total,
                "closed": sessions_closed,
                "open_like": sessions_open_like
            },
            "messages": {
                "slp": slp_messages,
                "patient": patient_messages
            },
            "timing": {
                "avg_first_response_minutes": avg_first_response_minutes,
                "avg_close_minutes": avg_close_minutes
            }
        }
    finally:
        conn.close()

@app.get("/api/slp/stats/daily")
def api_slp_stats_daily(
    date_from: str = Query(..., alias="from", description="YYYY-MM-DD"),
    date_to: str = Query(..., alias="to", description="YYYY-MM-DD"),
    payload: dict = Depends(get_current_staff_payload),
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    d1 = _parse_ymd(date_from)
    d2 = _parse_ymd(date_to)

    conn = get_db()
    cur = conn.cursor()
    try:
        # ä»¥ session.created_at ç•¶ä½œã€Œè©²å–®å±¬æ–¼å“ªå¤©ã€çš„çµ±è¨ˆåŸºæº–
        # closed_countï¼šç”¨ closed_at è½åœ¨è©²æ—¥çš„æ•¸é‡ï¼ˆè¼ƒç¬¦åˆã€Œå“ªå¤©çµæ¡ˆã€ï¼‰
        # messagesï¼šç”¨ message.created_at è½åœ¨è©²æ—¥çš„æ•¸é‡ï¼ˆè¨Šæ¯ç™¼ç”Ÿåœ¨å“ªå¤©ï¼‰
        cur.execute("""
            WITH RECURSIVE dates(d) AS (
              SELECT date(?)
              UNION ALL
              SELECT date(d, '+1 day') FROM dates WHERE d < date(?)
            ),
            closed AS (
              SELECT date(closed_at) AS d, COUNT(*) AS closed_count
              FROM service_sessions
              WHERE slp_id=?
                AND status='closed'
                AND closed_at IS NOT NULL
                AND date(closed_at) BETWEEN date(?) AND date(?)
              GROUP BY date(closed_at)
            ),
            msgs AS (
              SELECT date(m.created_at) AS d,
                     SUM(CASE WHEN m.sender_type='slp' THEN 1 ELSE 0 END) AS slp_messages,
                     SUM(CASE WHEN m.sender_type='patient' THEN 1 ELSE 0 END) AS patient_messages
              FROM service_messages m
              JOIN service_sessions s ON s.id=m.session_id
              WHERE s.slp_id=?
                AND date(m.created_at) BETWEEN date(?) AND date(?)
              GROUP BY date(m.created_at)
            )
            SELECT
              dates.d,
              COALESCE(closed.closed_count, 0) AS closed_count,
              COALESCE(msgs.slp_messages, 0) AS slp_messages,
              COALESCE(msgs.patient_messages, 0) AS patient_messages
            FROM dates
            LEFT JOIN closed ON closed.d = dates.d
            LEFT JOIN msgs   ON msgs.d   = dates.d
            ORDER BY dates.d ASC
        """, (d1, d2, slp_id, d1, d2, slp_id, d1, d2))

        items = [
            {
                "date": r[0],
                "closed_count": int(r[1] or 0),
                "slp_messages": int(r[2] or 0),
                "patient_messages": int(r[3] or 0),
            }
            for r in cur.fetchall()
        ]

        return {"slp_id": slp_id, "range": {"from": d1, "to": d2}, "items": items}
    finally:
        conn.close()

@app.post("/api/system/allocate")
def api_system_allocate():
    ensure_customer_service_tables()
    out = system_auto_allocate_one_db()
    return {"result": out}


# ==============================
# âœ… Staff Update Profile API
# ==============================

class StaffUpdateProfileRequest(BaseModel):
    username: Optional[str] = None
    name: Optional[str] = None
    email: Optional[str] = None
    license_number: Optional[str] = None
    organization: Optional[str] = None
    description: Optional[str] = None
    language: Optional[str] = None

# ==============================
# âœ… Staff Update Profile API
# ==============================

class StaffUpdateProfileRequest(BaseModel):
    username: Optional[str] = None
    name: Optional[str] = None
    email: Optional[str] = None
    license_number: Optional[str] = None
    organization: Optional[str] = None
    description: Optional[str] = None
    language: Optional[str] = None
    password: Optional[str] = None          # âœ… allow password update (>=6) without old password? (we will NOT use here)
    old_password: Optional[str] = None      # âœ… optional (not used here)
    new_password: Optional[str] = None      # âœ… optional (not used here)

@app.post("/staff/update-profile")
def staff_update_profile(
    data: StaffUpdateProfileRequest,
    payload: dict = Depends(get_current_staff_payload),
):
    """
    Staff è‡ªå·±æ›´æ–°å€‹äººè³‡æ–™ï¼ˆçµ¦ SLP Settings ç”¨ï¼‰
    - ç”¨ staffToken é©—è­‰ï¼ˆpayload.staff==1ï¼‰
    - email è‹¥è®Šæ›´ï¼šå¼·åˆ¶ verify=0 ä¸¦å¯„å‡ºæ–°çš„é©—è­‰ç¢¼
    - å¯†ç¢¼æ›´æ–°ï¼šè«‹èµ° /staff/change-passwordï¼ˆé¿å…æ··åœ¨åŒä¸€æ”¯ï¼‰
    """
    staff_id = payload.get("sub")
    role_from_token = payload.get("role")

    if not staff_id:
        raise HTTPException(status_code=401, detail="Invalid staff token")

    # ä¸å…è¨±ç”¨ update-profile æ”¹å¯†ç¢¼ï¼ˆé¿å…å®‰å…¨å•é¡Œï¼‰
    if data.password is not None or data.old_password is not None or data.new_password is not None:
        raise HTTPException(status_code=400, detail="Use /staff/change-password to update password")

    allowed_fields = {
        "username": data.username,
        "name": data.name,
        "email": data.email,
        "license_number": data.license_number,
        "organization": data.organization,
        "description": data.description,
        "language": data.language,
    }
    patch = {k: v for k, v in allowed_fields.items() if v is not None}

    if not patch:
        return {"msg": "No fields updated", "staff": None}

    # åŸºæœ¬æ ¼å¼æª¢æŸ¥
    if "email" in patch:
        em = str(patch["email"]).strip()
        # âœ… enforce gmail only
        if not re.match(r"^[A-Za-z0-9._%+-]+@gmail\.com$", em, re.IGNORECASE):
            raise HTTPException(status_code=400, detail="Email must be ...@gmail.com")
        patch["email"] = em

    if "username" in patch:
        patch["username"] = str(patch["username"]).strip()
        if not patch["username"]:
            raise HTTPException(status_code=400, detail="Username cannot be empty")

    conn = get_db()
    cur = conn.cursor()
    try:
        # å…ˆæŸ¥ç›®å‰ staff è³‡æ–™
        cur.execute("SELECT id, username, email, role, verify FROM staff_users WHERE id=?", (staff_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Staff not found")

        current_email = row[2] or ""
        current_role = row[3]
        current_verify = int(row[4] or 0)

        # username unique
        if "username" in patch:
            cur.execute("SELECT 1 FROM staff_users WHERE username=? AND id<>?", (patch["username"], staff_id))
            if cur.fetchone():
                raise HTTPException(status_code=400, detail="Username already exists")

        # email+role unique
        if "email" in patch:
            cur.execute(
                "SELECT 1 FROM staff_users WHERE email=? AND role=? AND id<>?",
                (patch["email"], current_role, staff_id)
            )
            if cur.fetchone():
                raise HTTPException(status_code=400, detail="Email already exists for this role")

        # âœ… if email changes => force verify=0 and send verify code
        email_changed = ("email" in patch) and (patch["email"].lower() != str(current_email).lower())

        # çµ„ UPDATE
        updates = []
        params = []
        for k, v in patch.items():
            updates.append(f"{k}=?")
            params.append(v)

        if email_changed:
            updates.append("verify=?")
            params.append(0)

        sql = f"UPDATE staff_users SET {', '.join(updates)} WHERE id=?"
        params.append(staff_id)
        cur.execute(sql, tuple(params))
        conn.commit()

        # è‹¥ email è®Šæ›´ => å»ºç«‹/æ›´æ–°é©—è­‰ç¢¼ä¸¦å¯„ä¿¡
        if email_changed:
            ensure_staff_verify_table()
            verify_code = str(random.randint(100000, 999999))

            # store code by (email, role)
            cur.execute(
                "INSERT OR REPLACE INTO staff_email_verifies (email, role, code, created_at) VALUES (?, ?, ?, ?)",
                (patch["email"], current_role, verify_code, datetime.now())
            )
            conn.commit()

            # send email (reuse your Gmail settings)
            try:
                sender = "aaa2025819@gmail.com"
                smtp_host = "smtp.gmail.com"
                smtp_port = 587
                smtp_user = "aaa2025819@gmail.com"
                smtp_pass = "ssjuayuhpfugwltp"

                subject = "Staff Email Verification Code"
                body = f"""
Hello {row[1]},

Your staff verification code is: {verify_code}

Role: {current_role}

You changed your email, so verification is required again.

Thank you,
ASR+LLM System
"""
                msg = MIMEText(body, "plain", "utf-8")
                msg["Subject"] = Header(subject, "utf-8")
                msg["From"] = sender
                msg["To"] = patch["email"]

                with smtplib.SMTP(smtp_host, smtp_port) as server:
                    server.starttls()
                    server.login(smtp_user, smtp_pass)
                    server.sendmail(sender, [patch["email"]], msg.as_string())

            except Exception as e:
                # email sending failure should be visible
                raise HTTPException(status_code=500, detail=f"Email send failed: {e}")

        # audit log
        try:
            audit_log(
                actor_type=role_from_token if role_from_token in ("slp", "admin") else "slp",
                actor_id=staff_id,
                action="STAFF_UPDATE_PROFILE",
                resource_type="staff_users",
                resource_id=staff_id,
                metadata=json.dumps({"patch": patch, "email_changed": email_changed}, ensure_ascii=False),
            )
        except Exception:
            pass

        # å›å‚³æ›´æ–°å¾Œè³‡æ–™
        cur.execute("""
            SELECT id, username, name, email, role, license_number, organization,
                   description, language, verify, is_approved, created_at, staff_picture
            FROM staff_users WHERE id=?
        """, (staff_id,))
        s = cur.fetchone()

        return {
            "msg": "Profile updated successfully",
            "staff": {
                "id": s[0],
                "username": s[1],
                "name": s[2],
                "email": s[3],
                "role": s[4],
                "license_number": s[5],
                "organization": s[6],
                "description": s[7],
                "language": s[8],
                "verify": s[9],
                "is_approved": s[10],
                "created_at": s[11],
                "staff_picture": s[12],
            }
        }

    finally:
        conn.close()


class StaffChangePasswordRequest(BaseModel):
    old_password: str
    new_password: str

@app.post("/staff/change-password")
def staff_change_password(
    data: StaffChangePasswordRequest,
    payload: dict = Depends(get_current_staff_payload)
):
    """
    Staff å·²ç™»å…¥æ”¹å¯†ç¢¼
    - é©— old_password
    - new_password é•·åº¦ >= 6
    """
    staff_id = payload.get("sub")
    if not staff_id:
        raise HTTPException(status_code=401, detail="Invalid staff token")

    if not data.new_password or len(data.new_password) < 6:
        raise HTTPException(status_code=400, detail="Password must be at least 6 characters")

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("SELECT password_hash FROM staff_users WHERE id=?", (staff_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Staff not found")

        if not verify_password(data.old_password, row[0]):
            raise HTTPException(status_code=400, detail="Old password is incorrect")

        cur.execute(
            "UPDATE staff_users SET password_hash=? WHERE id=?",
            (hash_password(data.new_password), staff_id)
        )
        conn.commit()

        return {"msg": "âœ… Password updated successfully"}
    finally:
        conn.close()

@app.delete("/staff/delete-picture")
def delete_staff_picture(
    payload: dict = Depends(get_current_staff_payload)
):
    """
    åˆªé™¤ staff é ­åƒï¼š
    - å¾ User/staff/<staff_id>/picture åˆªé™¤æª”æ¡ˆ
    - DB staff_users.staff_picture è¨­ç‚º NULL
    """
    staff_id = payload.get("sub")
    if not staff_id:
        raise HTTPException(status_code=401, detail="Invalid staff token")

    staff_dir = os.path.join(USER_ROOT_DIR, "staff", str(staff_id), "picture")

    # 1) delete files on disk
    if os.path.exists(staff_dir):
        for fn in os.listdir(staff_dir):
            try:
                os.remove(os.path.join(staff_dir, fn))
            except Exception:
                pass

    # 2) update DB
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("UPDATE staff_users SET staff_picture=NULL WHERE id=?", (staff_id,))
        conn.commit()
    finally:
        conn.close()

    return {"msg": "âœ… Staff avatar deleted"}
        
@app.get("/api/slp/session/{session_id}")
def api_slp_get_one_session(
    session_id: str,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT id, patient_id, slp_id, topic, priority, status, created_at, last_message_at, closed_at, closed_by
        FROM service_sessions
        WHERE id=?
    """, (session_id,))
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=404, detail="session not found")

    # âœ… åªèƒ½çœ‹åˆ†é…çµ¦è‡ªå·±çš„å–®
    if row[2] != slp_id:
        raise HTTPException(status_code=403, detail="not allowed")

    return {
        "id": row[0],
        "patient_id": row[1],
        "slp_id": row[2],
        "topic": row[3],
        "priority": row[4],
        "status": row[5],
        "created_at": row[6],
        "last_message_at": row[7],
        "closed_at": row[8],
        "closed_by": row[9],
    }

@app.get("/api/slp/session/{session_id}/messages")
def api_slp_get_session_messages(
    session_id: str,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    conn = get_db()
    cur = conn.cursor()

    # âœ… ç¢ºèªæ­¤ session å±¬æ–¼è©² SLP
    cur.execute("SELECT slp_id FROM service_sessions WHERE id=?", (session_id,))
    srow = cur.fetchone()
    if not srow:
        conn.close()
        raise HTTPException(status_code=404, detail="session not found")
    if srow[0] != slp_id:
        conn.close()
        raise HTTPException(status_code=403, detail="not allowed")

    cur.execute("""
        SELECT id, sender_type, sender_id, message, message_type, created_at
        FROM service_messages
        WHERE session_id=?
        ORDER BY created_at ASC
    """, (session_id,))
    items = [
        {
            "id": r[0],
            "sender_type": r[1],
            "sender_id": r[2],
            "message": r[3],
            "message_type": r[4],
            "created_at": r[5],
        }
        for r in cur.fetchall()
    ]
    conn.close()
    return {"items": items}

class PostSlpServiceMessageReq(BaseModel):
    message: str

@app.post("/api/slp/session/{session_id}/messages")
def api_slp_post_session_message(
    session_id: str,
    data: PostSlpServiceMessageReq,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    msg = (data.message or "").strip()
    if not msg:
        raise HTTPException(status_code=400, detail="message is empty")

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("SELECT slp_id, status FROM service_sessions WHERE id=?", (session_id,))
        srow = cur.fetchone()
        if not srow:
            raise HTTPException(status_code=404, detail="session not found")
        if srow[0] != slp_id:
            raise HTTPException(status_code=403, detail="not allowed")
        if srow[1] in ("closed", "cancelled"):
            raise HTTPException(status_code=400, detail="session already closed")

        msg_id = str(uuid.uuid4())
        cur.execute("""
            INSERT INTO service_messages (id, session_id, sender_type, sender_id, message, message_type)
            VALUES (?, ?, 'slp', ?, ?, 'text')
        """, (msg_id, session_id, slp_id, msg))

        # âœ… update last message + last slp activity + open
        cur.execute("""
            UPDATE service_sessions
            SET last_message_at=CURRENT_TIMESTAMP,
                last_slp_activity_at=CURRENT_TIMESTAMP,
                status=CASE WHEN status='assigned' THEN 'open' ELSE status END
            WHERE id=?
        """, (session_id,))

        conn.commit()

        audit_log("slp", slp_id, "POST_SERVICE_MESSAGE", "service_message", msg_id,
                  metadata=json.dumps({"session_id": session_id}, ensure_ascii=False))

        return {"message_id": msg_id}
    finally:
        conn.close()

@app.post("/api/slp/session/{session_id}/close")
def api_slp_close_session(
    session_id: str,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("SELECT slp_id, status FROM service_sessions WHERE id=?", (session_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="session not found")
        if row[0] != slp_id:
            raise HTTPException(status_code=403, detail="not allowed")
        if row[1] in ("closed", "cancelled"):
            return {"msg": "already closed"}

        # âœ… å¼·åˆ¶è¦å‰‡ï¼šç—…äºº 5 åˆ†é˜æœªå›è¦† SLP æ‰èƒ½é—œ
        if not patient_inactive_after_slp_reply(cur, session_id, SLP_INACTIVE_CLOSE_MINUTES):
            raise HTTPException(
                status_code=400,
                detail=f"ç—…äººå°šæœªé”åˆ° {SLP_INACTIVE_CLOSE_MINUTES} åˆ†é˜æœªå›è¦†ï¼Œä¸èƒ½é—œé–‰ã€‚"
            )

        cur.execute("""
            UPDATE service_sessions
            SET status='closed', closed_at=CURRENT_TIMESTAMP, closed_by='slp'
            WHERE id=?
        """, (session_id,))

        # âœ… å¯«å…¥ system_eventï¼ˆè®“èŠå¤©ç´€éŒ„å¯è¿½æº¯ï¼‰
        sys_id = str(uuid.uuid4())
        cur.execute("""
            INSERT INTO service_messages (id, session_id, sender_type, sender_id, message, message_type)
            VALUES (?, ?, 'system', NULL, ?, 'system_event')
        """, (sys_id, session_id, f"SLP å› ç—…äººé€¾æ™‚æœªå›è¦†ï¼ˆ{SLP_INACTIVE_CLOSE_MINUTES} åˆ†é˜ï¼‰è€Œé—œé–‰æ­¤æœå‹™ã€‚"))

        conn.commit()

        audit_log("slp", slp_id, "CLOSE_SERVICE_SESSION", "service_session", session_id,
                  metadata=json.dumps({"rule": "patient_inactive", "minutes": SLP_INACTIVE_CLOSE_MINUTES}, ensure_ascii=False))

        return {"msg": "closed_due_to_inactivity"}
    finally:
        conn.close()

@app.post("/api/slp/session/{session_id}/close-inactive")
def api_slp_close_session_inactive(
    session_id: str,
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("SELECT slp_id, status FROM service_sessions WHERE id=?", (session_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="session not found")
        if row[0] != slp_id:
            raise HTTPException(status_code=403, detail="not allowed")
        if row[1] in ("closed", "cancelled"):
            return {"msg": "already closed"}

        # âœ… æ ¸å¿ƒè¦å‰‡ï¼šç—…äºº 5 åˆ†é˜æœªå›è¦† SLP æ‰èƒ½é—œ
        if not patient_inactive_after_slp_reply(cur, session_id, SLP_INACTIVE_CLOSE_MINUTES):
            raise HTTPException(
                status_code=400,
                detail=f"ç—…äººå°šæœªé”åˆ° {SLP_INACTIVE_CLOSE_MINUTES} åˆ†é˜æœªå›è¦†ï¼Œä¸èƒ½ç”¨é€¾æ™‚é—œå–®ã€‚"
            )

        cur.execute("""
            UPDATE service_sessions
            SET status='closed', closed_at=CURRENT_TIMESTAMP, closed_by='slp'
            WHERE id=?
        """, (session_id,))

        # ï¼ˆå¯é¸ï¼‰æ’å…¥ system_event è¨Šæ¯ï¼Œè®“èŠå¤©ç´€éŒ„çœ‹åˆ°åŸå› 
        sys_id = str(uuid.uuid4())
        cur.execute("""
            INSERT INTO service_messages (id, session_id, sender_type, sender_id, message, message_type)
            VALUES (?, ?, 'system', NULL, ?, 'system_event')
        """, (sys_id, session_id, f"SLP å› ç—…äººé€¾æ™‚æœªå›è¦†ï¼ˆ{SLP_INACTIVE_CLOSE_MINUTES} åˆ†é˜ï¼‰è€Œé—œé–‰æ­¤æœå‹™ã€‚"))

        conn.commit()

        audit_log("slp", slp_id, "CLOSE_SERVICE_SESSION_INACTIVE", "service_session", session_id,
                  metadata=json.dumps({"minutes": SLP_INACTIVE_CLOSE_MINUTES}, ensure_ascii=False))

        return {"msg": "closed_due_to_inactivity"}
    finally:
        conn.close()

@app.get("/api/slp/patient/{patient_id}/tests/stats")
def api_slp_patient_tests_stats(
    patient_id: str,
    days: int = Query(365, ge=1, le=3650),
    date_from: Optional[str] = Query(None, alias="from"),
    date_to: Optional[str] = Query(None, alias="to"),
    language: Optional[str] = Query(None, description="cn|en (optional)"),
    a: Optional[str] = Query(None),
    b: Optional[str] = Query(None),
    payload: dict = Depends(get_current_staff_payload),
):
    # 1) auth: only slp
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]

    # 2) permission: slp must have sessions with this patient
    ensure_customer_service_tables()
    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        # 3) Now run the SAME logic as /api/patient/tests/stats,
        #    but using patient_id as the target user.
        # ---- copy of api_patient_tests_stats body starts ----
        d1_def, d2_def = _ymd_default_range(days)
        d1 = _parse_ymd_or_default(date_from, d1_def)
        d2 = _parse_ymd_or_default(date_to, d2_def)

        where_lang = ""
        params: list[Any] = [patient_id, d1, d2]
        if language is not None and str(language).strip() != "":
            lang = normalize_practice_language(language)  # cn|en
            where_lang = " AND language=?"
            params.append(lang)

        cur.execute(f"""
            SELECT
              id, test_name, status, language, threshold, words_per_subtype,
              progress_cursor, total_questions, current_question_index,
              has_slp, date, updated_at, finished_at, result
            FROM tests
            WHERE patient_id=?
              AND status='finished'
              AND date(COALESCE(finished_at, updated_at, date)) BETWEEN date(?) AND date(?)
              {where_lang}
            ORDER BY datetime(COALESCE(finished_at, updated_at, date)) DESC
        """, tuple(params))
        tests = cur.fetchall()

        items: List[dict] = []
        for t in tests:
            test_id = t["id"]

            cur.execute("""
                SELECT score, correct_rate, severity, check_results
                FROM test_records
                WHERE test_id=?
            """, (test_id,))
            rec_rows = cur.fetchall()
            recordsAgg = _test_agg_from_rows(rec_rows)

            cur.execute("""
                SELECT super_type, sub_type
                FROM slp_patient
                WHERE test_id=?
            """, (test_id,))
            slp_rows = cur.fetchall()
            slpAgg = _slp_agg_from_rows(slp_rows)

            items.append({
                "test": {
                    "id": test_id,
                    "test_name": t["test_name"],
                    "status": t["status"],
                    "language": t["language"],
                    "threshold": int(t["threshold"] or 0),
                    "words_per_subtype": int(t["words_per_subtype"] or 0),
                    "progress_cursor": int(t["progress_cursor"] or 0),
                    "total_questions": int(t["total_questions"] or 0),
                    "current_question_index": int(t["current_question_index"] or 0),
                    "has_slp": int(t["has_slp"] or 0),
                    "created_at": t["date"],
                    "updated_at": t["updated_at"],
                    "finished_at": t["finished_at"],
                    "result": _safe_json_loads(t["result"]),
                },
                "recordsAgg": recordsAgg,
                "slpAgg": slpAgg,
            })

        latest = items[0] if len(items) >= 1 else None
        prev = items[1] if len(items) >= 2 else None

        default_compare = None
        if latest and prev:
            default_compare = {
                "a": prev["test"]["id"],
                "b": latest["test"]["id"],
                "delta": _compare_metrics(prev, latest),
            }

        custom_compare = None
        if a and b:
            map_by_id = {it["test"]["id"]: it for it in items}
            if a in map_by_id and b in map_by_id:
                A = map_by_id[a]
                B = map_by_id[b]
                custom_compare = {"a": a, "b": b, "delta": _compare_metrics(A, B)}

        return {
            "range": {"from": d1, "to": d2},
            "items": items,
            "latest_finished": latest,
            "prev_finished": prev,
            "default_compare": default_compare,
            "custom_compare": custom_compare,
        }
        # ---- copy ends ----
    finally:
        conn.close()
        
@app.get("/api/slp/patient/{patient_id}/summary")
def api_slp_patient_summary(
    patient_id: str,
    limit: int = Query(50),
    payload: dict = Depends(get_current_staff_payload)
):
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    ensure_customer_service_tables()

    slp_id = payload["sub"]
    conn = get_db()
    cur = conn.cursor()
    try:
        # âœ… æ¬Šé™ï¼šåªèƒ½æŸ¥ã€Œåˆ†é…çµ¦è‡ªå·±ã€çš„ session ä¸­å‡ºç¾çš„ç—…äºº
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        # 1) patient åŸºæœ¬è³‡æ–™ + task_id
        cur.execute("""
            SELECT id, username, name, age, diagnosis, language, email, task_id
            FROM patients
            WHERE id=?
        """, (patient_id,))
        p = cur.fetchone()
        if not p:
            raise HTTPException(status_code=404, detail="patient not found")

        patient = {
            "id": p[0],
            "username": p[1],
            "name": p[2],
            "age": p[3],
            "diagnosis": p[4],
            "language": p[5],
            "email": p[6],
            "task_id": p[7],
        }

        # 2) task è©³ç´°ï¼ˆè‹¥æœ‰ï¼‰
        task = None
        if patient["task_id"]:
            cur.execute("""
                SELECT id, title, description, category, due_date, total_times, progress_times, integral, status, created_at
                FROM tasks
                WHERE id=?
            """, (patient["task_id"],))
            t = cur.fetchone()
            if t:
                task = {
                    "id": t[0],
                    "title": t[1],
                    "description": t[2],
                    "category": t[3],
                    "due_date": t[4],
                    "total_times": t[5],
                    "progress_times": t[6],
                    "integral": t[7],
                    "status": t[8],
                    "created_at": t[9],
                }

        # 3) è¨“ç·´ç´€éŒ„ï¼ˆCN/EN éƒ½åˆ—å‡ºï¼Œç°¡å–® listï¼‰
        cur.execute("""
            SELECT date, language, test_type, category, target_word, asr_word, correct_rate, difficulty
            FROM records_analysis
            WHERE user_id=?
            ORDER BY created_at DESC
            LIMIT ?
        """, (patient_id, int(limit)))
        records = [
            {
                "date": r[0],
                "language": r[1],
                "test_type": r[2],
                "category": r[3],
                "target_word": r[4],
                "asr_word": r[5],
                "correct_rate": r[6],
                "difficulty": r[7],
            }
            for r in cur.fetchall()
        ]

        return {"patient": patient, "task": task, "records": records}

    finally:
        conn.close()

@app.get("/api/slp/sessions/history")
def api_slp_sessions_history(
    status: str = Query("all", description="all|assigned|open|closed|cancelled"),
    limit: int = Query(80),
    payload: dict = Depends(get_current_staff_payload)
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]

    status = (status or "all").strip().lower()
    allowed = {"all", "assigned", "open", "closed", "cancelled"}
    if status not in allowed:
        raise HTTPException(status_code=400, detail="Invalid status")

    conn = get_db()
    cur = conn.cursor()
    try:
        where_status = ""
        params = [slp_id]

        if status != "all":
            where_status = " AND status=?"
            params.append(status)

        # å– session + ç—…äºº id + topic + priority + ç‹€æ…‹ + å»ºç«‹/æœ€å¾Œè¨Šæ¯/é—œé–‰æ™‚é–“
        cur.execute(f"""
            SELECT id, patient_id, topic, priority, status, created_at, last_message_at, closed_at, closed_by
            FROM service_sessions
            WHERE slp_id=?
            {where_status}
            ORDER BY COALESCE(last_message_at, created_at) DESC
            LIMIT ?
        """, (*params, int(limit)))

        rows = cur.fetchall()

        return {
            "items": [
                {
                    "id": r[0],
                    "patient_id": r[1],
                    "topic": r[2],
                    "priority": r[3],
                    "status": r[4],
                    "created_at": r[5],
                    "last_message_at": r[6],
                    "closed_at": r[7],
                    "closed_by": r[8],
                }
                for r in rows
            ]
        }
    finally:
        conn.close()

class UpdateUsernameRequest(BaseModel):
    username: str

@app.patch("/api/patient/update-username")
def update_username(
    data: UpdateUsernameRequest,
    current_user_id: str = Depends(get_current_user_id),
):
    new_username = (data.username or "").strip()

    if not new_username:
        raise HTTPException(status_code=400, detail="Username cannot be empty")

    # ä½ ä¹Ÿå¯ä»¥åŠ æ›´åš´æ ¼è¦å‰‡ï¼ˆåªå…è¨±è‹±æ–‡æ•¸å­—åº•ç·šï¼‰
    if len(new_username) < 3 or len(new_username) > 24:
        raise HTTPException(status_code=400, detail="Username must be 3-24 characters")

    conn = get_db()
    cur = conn.cursor()

    # æª¢æŸ¥æ˜¯å¦è¢«å…¶ä»–äººä½¿ç”¨
    cur.execute("SELECT 1 FROM patients WHERE username=? AND id<>?", (new_username, current_user_id))
    if cur.fetchone():
        conn.close()
        raise HTTPException(status_code=400, detail="Username already exists")

    # æ›´æ–°è‡ªå·±çš„ username
    cur.execute("UPDATE patients SET username=? WHERE id=?", (new_username, current_user_id))
    conn.commit()

    # å›å‚³æœ€æ–°è³‡æ–™
    cur.execute("""
        SELECT id, username, name, age, diagnosis, email, language, integral, verify, user_picture
        FROM patients WHERE id=?
    """, (current_user_id,))
    row = cur.fetchone()
    conn.close()

    return {
        "msg": "Username updated successfully",
        "user": {
            "id": row[0],
            "username": row[1],
            "name": row[2],
            "age": row[3],
            "diagnosis": row[4],
            "email": row[5],
            "language": row[6],
            "integral": row[7],
            "verify": row[8],
            "user_picture": row[9],
        }
    }    

from pydantic import BaseModel
from fastapi import Query

class PracticeProgressResp(BaseModel):
    super_type: str
    sub_type: str
    language: str
    chunk_size: int
    next_start_index: int
    next_range_start: int   # 1-based for UI
    next_range_end: int     # 1-based for UI
    last_range_end: int

@app.get("/api/practice/progress", response_model=PracticeProgressResp)
def get_practice_progress(
    super_type: str = Query(...),
    sub_type: str = Query(...),
    language: str = Query("en"),
    chunk_size: int = Query(50),
    current_user_id: str = Depends(get_current_user_id),
):
    ensure_practice_progress_table()

    lang = normalize_practice_language(language)

    chunk_size = int(chunk_size)
    if chunk_size <= 0 or chunk_size > 200:
        raise HTTPException(status_code=400, detail="Invalid chunk_size")

    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT chunk_size, next_start_index, last_range_end
        FROM practice_progress
        WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
    """, (current_user_id, super_type, sub_type, lang))
    row = cur.fetchone()
    conn.close()

    if row:
        cs, next_start_index, last_range_end = int(row[0]), int(row[1]), int(row[2] or 0)
    else:
        cs, next_start_index, last_range_end = chunk_size, 0, 0

    next_range_start = next_start_index + 1
    next_range_end = next_start_index + cs

    return PracticeProgressResp(
        super_type=super_type,
        sub_type=sub_type,
        language=lang,
        chunk_size=cs,
        next_start_index=next_start_index,
        next_range_start=next_range_start,
        next_range_end=next_range_end,
        last_range_end=last_range_end,
    )

class CommitRangeReq(BaseModel):
    super_type: str
    sub_type: str
    language: str = "en"
    chunk_size: int = 50
    total_items: int

class CommitRangeResp(BaseModel):
    committed_range_start: int  # 1-based
    committed_range_end: int    # 1-based
    next_start_index: int

@app.post("/api/practice/commit-range", response_model=CommitRangeResp)
def commit_practice_range(
    data: CommitRangeReq,
    current_user_id: str = Depends(get_current_user_id),
):
    ensure_practice_progress_table()

    super_type = (data.super_type or "").strip()
    sub_type = (data.sub_type or "").strip()
    lang = normalize_practice_language(data.language)

    chunk_size = int(data.chunk_size or 50)
    total_items = int(data.total_items or 0)

    if not super_type or not sub_type:
        raise HTTPException(status_code=400, detail="Missing super_type/sub_type")
    if chunk_size <= 0 or chunk_size > 200:
        raise HTTPException(status_code=400, detail="Invalid chunk_size")
    if total_items <= 0:
        raise HTTPException(status_code=400, detail="Invalid total_items")

    conn = get_db()
    cur = conn.cursor()
    try:
        # âœ… ç”¨ language å®šä½
        cur.execute("""
            SELECT id, next_start_index
            FROM practice_progress
            WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
        """, (current_user_id, super_type, sub_type, lang))
        row = cur.fetchone()

        if row:
            prog_id, next_start_index = row[0], int(row[1] or 0)
        else:
            prog_id, next_start_index = str(uuid.uuid4()), 0
            cur.execute("""
                INSERT INTO practice_progress
                (id, user_id, super_type, sub_type, language, chunk_size, next_start_index, last_range_end)
                VALUES (?, ?, ?, ?, ?, ?, 0, 0)
            """, (prog_id, current_user_id, super_type, sub_type, lang, chunk_size))

        committed_start_idx = next_start_index
        committed_end_idx_excl = min(next_start_index + chunk_size, total_items)  # exclusive

        if committed_start_idx >= total_items:
            raise HTTPException(status_code=400, detail="No more items to commit")

        committed_range_start = committed_start_idx + 1
        committed_range_end = committed_end_idx_excl  # 1-based end
        new_next_start_index = committed_end_idx_excl

        cur.execute("""
            UPDATE practice_progress
            SET chunk_size=?,
                next_start_index=?,
                last_range_end=?,
                updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (chunk_size, new_next_start_index, committed_range_end, prog_id))

        conn.commit()

        return CommitRangeResp(
            committed_range_start=committed_range_start,
            committed_range_end=committed_range_end,
            next_start_index=new_next_start_index,
        )

    finally:
        conn.close()

class NextWordsResp(BaseModel):
    super_type: str
    sub_type: str
    language: str
    range_start: int   # 1-based
    range_end: int     # 1-based
    total_items: int
    items: list[str]

@app.get("/api/practice/instruction")
def practice_instruction(
    super_type: str = Query(...),
    sub_type: str = Query(...),
):
    # å…ˆçµ¦ä½ æœ€ç°¡å–®ç‰ˆæœ¬ï¼šå›ºå®šæ¨¡æ¿
    # ä¹‹å¾Œä½ ä¹Ÿå¯ä»¥é‡å°ä¸åŒ sub_type å¯«æ›´ç´°è¦å‰‡
    return {
        "super_type": super_type,
        "sub_type": sub_type,
        "how_to_read": [
            "1) å…ˆçœ‹ç›®æ¨™å–®å­—ï¼ˆtarget wordï¼‰ã€‚",
            "2) æŒ‰æ’­æ”¾æˆ–çœ‹æç¤ºï¼Œè·Ÿè‘—å”¸ä¸€æ¬¡ã€‚",
            "3) æŒ‰éŒ„éŸ³é–‹å§‹ï¼Œæ¸…æ¥šå”¸å‡ºå–®å­—ã€‚",
            "4) åœæ­¢éŒ„éŸ³ä¸¦é€å‡ºåˆ†æã€‚",
        ],
        "show_answer_tip": "æŒ‰ã€Œé¡¯ç¤ºç­”æ¡ˆã€å¯ä»¥çœ‹åˆ°æ¨™æº–ç™¼éŸ³/æç¤ºï¼ˆè‹¥æœ‰ï¼‰ã€‚"
    }

class PracticeSubmitReq(BaseModel):
    super_type: str
    sub_type: str
    range_start: int  # 1-based
    range_end: int    # 1-based
    items: list[dict] # e.g. [{w:"rescued", ipa:"/ËˆÉ¹É›skjud/", correct:true, ...}, ...]

@app.post("/api/practice/submit")
def practice_submit(
    data: PracticeSubmitReq,
    current_user_id: str = Depends(get_current_user_id),
):
    # é€™è£¡å…ˆåªå­˜æª”ï¼Œä¸åš ASR åˆ†æï¼ˆå› ç‚ºä½ ç¾æœ‰åˆ†ææ˜¯èµ° /analyze_*_wordsï¼‰
    payload = {
        "super_type": data.super_type,
        "sub_type": data.sub_type,
        "range": {"start": data.range_start, "end": data.range_end},
        "items": data.items,
    }

    # ä½ å·²æœ‰ save_analysis_recordï¼Œä½†åƒæ•¸ä¸å®Œå…¨ç¬¦åˆè‹±æ–‡/é€™ç¨®ç·´ç¿’
    # é€™è£¡ç°¡åŒ–ï¼šç›´æ¥å¯« records_analysisï¼ˆç”¨ SQLï¼‰
    conn = get_db()
    cur = conn.cursor()
    rid = str(uuid.uuid4())
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    cur.execute("""
        INSERT INTO records_analysis
        (id, user_id, date, target_word, target_ipa, asr_ipa, asr_word, score, correct_rate,
         difficulty, check_results, language, test_type, category, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (
        rid, current_user_id, now,
        None, None, None, None,
        None, None,
        "easy",  # ä½  schema é™åˆ¶ easy/medium/hardï¼›é€™è£¡å…ˆçµ¦ easy
        json.dumps(payload, ensure_ascii=False),
        "English",
        "PracticeBank",
        data.super_type,
        now
    ))
    conn.commit()
    conn.close()

    return {"msg": "saved", "record_id": rid}

def get_current_user_level(current_user_id: str = Depends(get_current_user_id)) -> dict:
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT age FROM patients WHERE id=?", (current_user_id,))
    row = cur.fetchone()
    conn.close()

    age = row[0] if row else None
    try:
        age_int = int(age) if age is not None else None
    except Exception:
        age_int = None

    # default if age is missing
    if age_int is None:
        level = "primary"
    elif age_int < 12:
        level = "primary"
    elif age_int < 18:
        level = "secondary"
    else:
        level = "advanced"

    return {"age": age_int, "level": level}

@app.get("/api/patient/level")
def api_patient_level(payload: dict = Depends(get_current_user_level)):
    return payload

@app.get("/admin/staff-applications")
def admin_list_staff_applications(payload: dict = Depends(get_current_staff_payload)):
    require_admin(payload)

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT id, username, name, email, role, license_number, organization, description, language,
                   verify, is_approved, created_at
            FROM staff_users
            WHERE is_approved=0
            ORDER BY created_at ASC
        """)
        rows = cur.fetchall()

        items = []
        for r in rows:
            items.append({
                "id": r[0],
                "username": r[1],
                "name": r[2],
                "email": r[3],
                "role": r[4],
                "license_number": r[5],
                "organization": r[6],
                "description": r[7],
                "language": r[8],
                "verify": r[9],
                "is_approved": r[10],
                "created_at": r[11],
            })

        return {"items": items}
    finally:
        conn.close()

class AdminDecideStaffApplicationReq(BaseModel):
    staff_id: str
    decision: str  # "approve" | "reject"
    reason: Optional[str] = None

@app.post("/admin/staff-applications/decide")
def admin_decide_staff_application(
    data: AdminDecideStaffApplicationReq,
    payload: dict = Depends(get_current_staff_payload)
):
    require_admin(payload)

    staff_id = (data.staff_id or "").strip()
    decision = (data.decision or "").strip().lower()
    reason = (data.reason or "").strip()

    if not staff_id:
        raise HTTPException(status_code=400, detail="Missing staff_id")
    if decision not in ("approve", "reject"):
        raise HTTPException(status_code=400, detail="Invalid decision")
    if decision == "reject" and not reason:
        raise HTTPException(status_code=400, detail="Reject reason is required")

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT id, username, email, role, is_approved
            FROM staff_users
            WHERE id=?
        """, (staff_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Staff not found")

        _id, username, email, role, is_approved = row
        if int(is_approved) != 0:
            raise HTTPException(status_code=400, detail="This application is not pending")

        if not email:
            raise HTTPException(status_code=400, detail="Staff email is missing")

        new_status = 1 if decision == "approve" else 2
        cur.execute("UPDATE staff_users SET is_approved=? WHERE id=?", (new_status, staff_id))
        conn.commit()

        # --- send email ---
        sender = "aaa2025819@gmail.com"
        smtp_host = "smtp.gmail.com"
        smtp_port = 587
        smtp_user = "aaa2025819@gmail.com"
        smtp_pass = "ssjuayuhpfugwltp"

        if decision == "approve":
            subject = "Your staff application has been approved"
            body = f"""
Hello {username},

Your {role.upper()} staff application has been approved.

You can now login with your email and password.

Thank you,
ASR+LLM System
"""
        else:
            subject = "Your staff application has been rejected"
            body = f"""
Hello {username},

Your {role.upper()} staff application has been rejected.

Reason:
{reason}

You may update your information and apply again if needed.

Thank you,
ASR+LLM System
"""

        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = sender
        msg["To"] = email

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_pass)
            server.sendmail(sender, [email], msg.as_string())

        # optional audit
        try:
            audit_log(
                actor_type="admin",
                actor_id=payload.get("sub"),
                action="ADMIN_DECIDE_STAFF_APPLICATION",
                resource_type="staff_users",
                resource_id=staff_id,
                metadata=json.dumps({"decision": decision, "reason": reason}, ensure_ascii=False),
            )
        except Exception:
            pass

        return {"msg": "ok", "staff_id": staff_id, "is_approved": new_status}

    finally:
        conn.close()


from typing import List, Dict, Any

def _date_series(d1: str, d2: str) -> List[str]:
    """
    Return list of YYYY-MM-DD between [d1, d2]
    """
    start = datetime.strptime(d1, "%Y-%m-%d").date()
    end = datetime.strptime(d2, "%Y-%m-%d").date()
    out = []
    cur = start
    while cur <= end:
        out.append(cur.strftime("%Y-%m-%d"))
        cur = cur + timedelta(days=1)
    return out

@app.get("/admin/stats/overview")
def admin_stats_overview(
    date_from: str = Query(..., alias="from", description="YYYY-MM-DD"),
    date_to: str = Query(..., alias="to", description="YYYY-MM-DD"),
    payload: dict = Depends(get_current_staff_payload),
):
    require_admin(payload)

    d1 = _parse_ymd(date_from)
    d2 = _parse_ymd(date_to)

    conn = get_db()
    cur = conn.cursor()
    try:
        # -------------------------
        # Totals (ALL TIME)
        # -------------------------
        cur.execute("SELECT COUNT(*) FROM patients")
        total_patients = int(cur.fetchone()[0] or 0)

        # only approved staff
        cur.execute("SELECT COUNT(*) FROM staff_users WHERE role='slp' AND is_approved=1")
        total_slp = int(cur.fetchone()[0] or 0)

        cur.execute("SELECT COUNT(*) FROM records_analysis")
        total_practice = int(cur.fetchone()[0] or 0)

        cur.execute("SELECT COUNT(*) FROM service_sessions")
        total_sessions = int(cur.fetchone()[0] or 0)

        # -------------------------
        # Series (by day in range)
        # -------------------------
        days = _date_series(d1, d2)
        base = {d: 0 for d in days}

        # new patients per day
        cur.execute("""
            SELECT date(created_at) AS d, COUNT(*) AS c
            FROM patients
            WHERE date(created_at) BETWEEN date(?) AND date(?)
            GROUP BY date(created_at)
        """, (d1, d2))
        new_patients_map = dict(base)
        for r in cur.fetchall():
            new_patients_map[str(r[0])] = int(r[1] or 0)

        # new slp per day (approved or all? use created_at regardless, but keep role='slp')
        cur.execute("""
            SELECT date(created_at) AS d, COUNT(*) AS c
            FROM staff_users
            WHERE role='slp'
              AND date(created_at) BETWEEN date(?) AND date(?)
            GROUP BY date(created_at)
        """, (d1, d2))
        new_slps_map = dict(base)
        for r in cur.fetchall():
            new_slps_map[str(r[0])] = int(r[1] or 0)

        # sessions created per day
        cur.execute("""
            SELECT date(created_at) AS d, COUNT(*) AS c
            FROM service_sessions
            WHERE date(created_at) BETWEEN date(?) AND date(?)
            GROUP BY date(created_at)
        """, (d1, d2))
        sess_created_map = dict(base)
        for r in cur.fetchall():
            sess_created_map[str(r[0])] = int(r[1] or 0)

        # sessions closed per day
        cur.execute("""
            SELECT date(closed_at) AS d, COUNT(*) AS c
            FROM service_sessions
            WHERE status='closed'
              AND closed_at IS NOT NULL
              AND date(closed_at) BETWEEN date(?) AND date(?)
            GROUP BY date(closed_at)
        """, (d1, d2))
        sess_closed_map = dict(base)
        for r in cur.fetchall():
            sess_closed_map[str(r[0])] = int(r[1] or 0)

        # practice records per day
        cur.execute("""
            SELECT date(created_at) AS d, COUNT(*) AS c
            FROM records_analysis
            WHERE date(created_at) BETWEEN date(?) AND date(?)
            GROUP BY date(created_at)
        """, (d1, d2))
        practice_map = dict(base)
        for r in cur.fetchall():
            practice_map[str(r[0])] = int(r[1] or 0)

        def to_series(m: Dict[str, int]) -> List[Dict[str, Any]]:
            return [{"date": d, "value": int(m.get(d, 0))} for d in days]

        def to_series2(m1: Dict[str, int], m2: Dict[str, int], k1: str, k2: str) -> List[Dict[str, Any]]:
            out = []
            for d in days:
                out.append({"date": d, k1: int(m1.get(d, 0)), k2: int(m2.get(d, 0))})
            return out

        return {
            "range": {"from": d1, "to": d2},
            "totals": {
                "patients": total_patients,
                "slps": total_slp,
                "service_sessions": total_sessions,
                "practice_records": total_practice
            },
            "series": {
                "new_patients_daily": to_series(new_patients_map),
                "new_slps_daily": to_series(new_slps_map),
                "sessions_daily": to_series2(sess_created_map, sess_closed_map, "created", "closed"),
                "practice_daily": to_series(practice_map),
            }
        }
    finally:
        conn.close()



# ------------------------------
# English practice bank helpers
# ------------------------------
EN_BANK_FILES = {
    "Addition": "LLM/Addition.json",
    "Omission": "LLM/Omission.json",
    "Substitution": "LLM/Substitution.json",
}

def infer_en_difficulty_from_user_id(user_id: str) -> str:
    """
    Return primary|secondary|advanced from patients.age
    Same policy as /api/patient/level
    """
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT age FROM patients WHERE id=?", (user_id,))
    row = cur.fetchone()
    conn.close()

    age = row[0] if row else None
    try:
        age_int = int(age) if age is not None else None
    except Exception:
        age_int = None

    if age_int is None:
        return "primary"
    if age_int < 12:
        return "primary"
    if age_int < 18:
        return "secondary"
    return "advanced"

def normalize_difficulty_bucket_en(level: str | None) -> str:
    """
    English bank åªæ¥å—: primary|secondary|advanced
    å…è¨±å‰ç«¯å‚³: primary_school / å°å­¸ / ä¸­å­¸ / å¤§å­¸ ç­‰
    """
    s = (level or "").strip().lower()
    mapping = {
        "primary_school": "primary",
        "primary": "primary",
        "elementary": "primary",
        "å°å­¸": "primary",
        "å°å­¦": "primary",

        "secondary": "secondary",
        "middle": "secondary",
        "ä¸­å­¸": "secondary",
        "ä¸­å­¦": "secondary",

        "advanced": "advanced",
        "advance": "advanced",
        "å¤§å­¸": "advanced",
        "å¤§å­¦": "advanced",
    }
    return mapping.get(s, "advanced")

def load_en_bank_items(super_type: str, sub_type: str, difficulty: str) -> list[dict]:
    """
    å¾ LLM/*.json (NEW format) è®€å–æŒ‡å®š (super_type, sub_type, difficulty) çš„ itemsã€‚
    å›å‚³æ ¼å¼: [{"w": "...", "ipa": "/.../"}, ...]
    """
    super_type = (super_type or "").strip()
    sub_type = (sub_type or "").strip()
    difficulty = normalize_difficulty_bucket_en(difficulty)

    path = EN_BANK_FILES.get(super_type)
    if not path:
        return []

    obj = safe_load_json(path)  # ä½  main.py å·²ç¶“æœ‰ safe_load_json
    banks = obj.get("banks")
    if not isinstance(banks, dict):
        return []

    sub = banks.get(sub_type)
    if not isinstance(sub, dict):
        return []

    lvl = sub.get(difficulty)
    if not isinstance(lvl, dict):
        return []

    items = lvl.get("items", [])
    if not isinstance(items, list):
        return []

    out = []
    for it in items:
        if not isinstance(it, dict):
            continue
        w = it.get("w")
        if not isinstance(w, str) or not w.strip():
            continue
        out.append({
            "w": w.strip(),
            "ipa": str(it.get("ipa") or "").strip()
        })
    return out

class NextWordEnResp(BaseModel):
    super_type: str
    sub_type: str
    language: str
    difficulty: str
    index: int          # 1-based
    total_items: int
    target_word: str
    target_ipa: str
    record_id: str

@app.get("/api/practice/en/next-word", response_model=NextWordEnResp)
def api_practice_next_word_en(
    super_type: str = Query(..., description="Addition|Omission|Substitution"),
    sub_type: str = Query(..., description="Key in LLM/<super>.json banks"),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    English take vocab:
    - difficulty ç”±å¾Œç«¯ä¾ current_user_id -> patients.age è‡ªå‹•æ¨æ–·
    - æ ¹æ“š difficulty å¾ LLM/*.json çš„ banks[sub_type][difficulty].items å–è©
    """
    ensure_practice_progress_table()

    super_type = (super_type or "").strip()
    sub_type = (sub_type or "").strip()

    if super_type not in EN_BANK_FILES:
        raise HTTPException(status_code=400, detail=f"Unsupported super_type: {super_type}")
    if not sub_type:
        raise HTTPException(status_code=400, detail="Missing sub_type")

    # âœ… å¾Œç«¯è‡ªå‹•æ¨æ–· difficulty
    diff = infer_en_difficulty_from_user_id(current_user_id)  # primary|secondary|advanced

    items = load_en_bank_items(super_type, sub_type, diff)
    total_items = len(items)
    if total_items <= 0:
        raise HTTPException(
            status_code=400,
            detail=f"Empty bank: {super_type}/{sub_type} difficulty={diff}"
        )

    lang = "en"

    conn = get_db()
    cur = conn.cursor()

    cur.execute("""
        SELECT id, next_start_index, chunk_size
        FROM practice_progress
        WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
    """, (current_user_id, super_type, sub_type, lang))
    row = cur.fetchone()

    if row:
        prog_id, next_idx, chunk_size = row[0], int(row[1] or 0), int(row[2] or 50)
    else:
        prog_id = str(uuid.uuid4())
        next_idx = 0
        chunk_size = 50
        cur.execute("""
            INSERT INTO practice_progress
            (id, user_id, super_type, sub_type, language, chunk_size, next_start_index, last_range_end)
            VALUES (?, ?, ?, ?, ?, ?, 0, 0)
        """, (prog_id, current_user_id, super_type, sub_type, lang, chunk_size))
        conn.commit()

    if next_idx >= total_items:
        next_idx = 0
        cur.execute("""
            UPDATE practice_progress
            SET next_start_index=0, last_range_end=0, updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (prog_id,))
        conn.commit()

    pick = items[next_idx]
    target_word = pick["w"]
    target_ipa = (pick.get("ipa") or "").replace("/", "").strip()

    record_id = str(uuid.uuid4())

    conn.close()

    return NextWordEnResp(
        super_type=super_type,
        sub_type=sub_type,
        language="en",
        difficulty=diff,
        index=next_idx + 1,
        total_items=total_items,
        target_word=target_word,
        target_ipa=target_ipa,
        record_id=record_id
    )


@app.get("/api/practice/en/subtypes")
def api_practice_en_subtypes(
    super_type: str = Query(...),
):
    super_type = (super_type or "").strip()
    path = EN_BANK_FILES.get(super_type)
    if not path:
        raise HTTPException(status_code=400, detail="Unsupported super_type")

    obj = safe_load_json(path)
    banks = obj.get("banks") or {}
    if not isinstance(banks, dict):
        return {"super_type": super_type, "subtypes": []}

    return {"super_type": super_type, "subtypes": sorted(list(banks.keys()))}
    

#-----Chinese Get Word ---------------
@app.get("/api/practice/next-words", response_model=NextWordsResp)
def api_practice_next_words(
    super_type: str = Query(...),
    sub_type: str = Query(...),
    language: str = Query("en"),
    chunk_size: int = Query(50),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    ç”¨ practice_progress å» slpErrors / bank å–ä¸‹ä¸€æ®µè©
    - ä¸æœƒè‡ªå‹• commitï¼›å‰ç«¯åšå®Œä¸€æ®µå† call /api/practice/commit-range
    """
    ensure_practice_progress_table()

    super_type = (super_type or "").strip()
    sub_type = (sub_type or "").strip()
    lang = normalize_practice_language(language)
    chunk_size = int(chunk_size or 50)

    if not super_type or not sub_type:
        raise HTTPException(status_code=400, detail="Missing super_type/sub_type")
    if chunk_size <= 0 or chunk_size > 200:
        raise HTTPException(status_code=400, detail="Invalid chunk_size")

    # âœ… ç›®å‰ä½ çš„è©åº«æ˜¯ slpErrorsï¼ˆflatten å¾Œ dictï¼‰
    if sub_type not in slpErrors:
        raise HTTPException(status_code=400, detail=f"Unknown sub_type: {sub_type}")

    bank = slpErrors[sub_type]
    total_items = len(bank)
    if total_items == 0:
        raise HTTPException(status_code=400, detail="Empty bank")

    # è®€ progress
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT next_start_index, chunk_size
        FROM practice_progress
        WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
    """, (current_user_id, super_type, sub_type, lang))
    row = cur.fetchone()
    conn.close()

    if row:
        next_start_index = int(row[0] or 0)
        # ä½ å¯ä»¥é¸æ“‡ã€Œç”¨ DB chunk_sizeã€æˆ–ã€Œç”¨ query chunk_sizeã€
        # é€™è£¡æ¡ç”¨ query chunk_sizeï¼ˆå‰ç«¯å¯æ§åˆ¶ï¼‰
    else:
        next_start_index = 0

    start = next_start_index
    end_excl = min(start + chunk_size, total_items)

    # å·²åšå®Œ
    if start >= total_items:
        return NextWordsResp(
            super_type=super_type,
            sub_type=sub_type,
            language=lang,
            range_start=total_items + 1,
            range_end=total_items,
            total_items=total_items,
            items=[]
        )

    items = bank[start:end_excl]

    return NextWordsResp(
        super_type=super_type,
        sub_type=sub_type,
        language=lang,
        range_start=start + 1,
        range_end=end_excl,
        total_items=total_items,
        items=items
    )

def migrate_practice_progress_unique_with_language():
    """
    SQLite migration:
    - Ensure practice_progress has language column
    - Rebuild table with UNIQUE(user_id, super_type, sub_type, language)
    - Preserve existing data (old rows default language='en')
    """
    conn = get_db()
    cur = conn.cursor()

    try:
        # 0) ç¢ºèªèˆŠè¡¨å­˜åœ¨
        cur.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name='practice_progress'
        """)
        if not cur.fetchone():
            # æ²’è¡¨å°±ç›´æ¥å»ºæ–°è¡¨ï¼ˆæŒ‰ä½ æ–° schemaï¼‰
            cur.execute("""
            CREATE TABLE practice_progress (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                super_type TEXT NOT NULL,
                sub_type TEXT NOT NULL,
                language TEXT NOT NULL DEFAULT 'en',
                chunk_size INTEGER NOT NULL DEFAULT 50,
                next_start_index INTEGER NOT NULL DEFAULT 0,
                last_range_end INTEGER NOT NULL DEFAULT 0,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES patients(id) ON DELETE CASCADE,
                UNIQUE(user_id, super_type, sub_type, language)
            )
            """)
            conn.commit()
            print("ğŸ§¿ practice_progress table created (new schema).")
            return

        # 1) æª¢æŸ¥èˆŠè¡¨æœ‰å†‡ language æ¬„ï¼ˆå¦‚æœå†‡ï¼Œæ¬è³‡æ–™æ™‚è¦–ä½œ 'en'ï¼‰
        cur.execute("PRAGMA table_info(practice_progress);")
        cols = [r[1] for r in cur.fetchall()]
        has_language = "language" in cols

        # 2) Rename èˆŠè¡¨
        cur.execute("ALTER TABLE practice_progress RENAME TO practice_progress_old;")

        # 3) å»ºæ–°è¡¨ï¼ˆå« language + æ–° UNIQUEï¼‰
        cur.execute("""
        CREATE TABLE practice_progress (
            id TEXT PRIMARY KEY,
            user_id TEXT NOT NULL,
            super_type TEXT NOT NULL,
            sub_type TEXT NOT NULL,
            language TEXT NOT NULL DEFAULT 'en',
            chunk_size INTEGER NOT NULL DEFAULT 50,
            next_start_index INTEGER NOT NULL DEFAULT 0,
            last_range_end INTEGER NOT NULL DEFAULT 0,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES patients(id) ON DELETE CASCADE,
            UNIQUE(user_id, super_type, sub_type, language)
        )
        """)

        # 4) æ¬è³‡æ–™
        # å¦‚æœèˆŠè¡¨å†‡ languageï¼Œå°±å…¨éƒ¨ç•¶ 'en'
        if has_language:
            cur.execute("""
                INSERT INTO practice_progress
                (id, user_id, super_type, sub_type, language, chunk_size, next_start_index, last_range_end, updated_at)
                SELECT
                  id, user_id, super_type, sub_type,
                  COALESCE(NULLIF(TRIM(language), ''), 'en') AS language,
                  chunk_size, next_start_index, last_range_end,
                  COALESCE(updated_at, CURRENT_TIMESTAMP)
                FROM practice_progress_old
            """)
        else:
            cur.execute("""
                INSERT INTO practice_progress
                (id, user_id, super_type, sub_type, language, chunk_size, next_start_index, last_range_end, updated_at)
                SELECT
                  id, user_id, super_type, sub_type,
                  'en' AS language,
                  chunk_size, next_start_index, last_range_end,
                  COALESCE(updated_at, CURRENT_TIMESTAMP)
                FROM practice_progress_old
            """)

        # 5) å¯é¸ï¼šé‡å»ºå¸¸ç”¨ indexï¼ˆä½  create_db.py æœ‰ï¼Œä½† main.py æœªå¿…éœ€è¦ï¼‰
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_practice_progress_user_bank_lang
            ON practice_progress(user_id, super_type, sub_type, language);
        """)

        # 6) Drop èˆŠè¡¨
        cur.execute("DROP TABLE practice_progress_old;")

        conn.commit()
        print("âœ… practice_progress migrated: UNIQUE(user_id, super_type, sub_type, language)")

    except Exception as e:
        conn.rollback()
        raise
    finally:
        conn.close()

class NextWordResp(BaseModel):
    super_type: str
    sub_type: str
    language: str
    index: int          # 1-based
    total_items: int
    word: str
    record_id: str      # ç”¨æ–¼æŠŠã€Œè®€çš„çµæœã€å¯«å› DBï¼ˆoptional ä½†å»ºè­°ï¼‰

def get_practice_bank_by_super_type(super_type: str) -> dict:
    st = (super_type or "").strip()

    if st == "Substitution":
        # âœ… ä½ æƒ³ç”¨é‚Šä»½ substitution bankï¼Œå°±ç”¨é‚Šå€‹ï¼š
        # 1) å¦‚æœä½ è¦ç”¨ LLM1/substitution.jsonï¼š
        return substitution_errors_llm1
        # 2) å¦‚æœä½ è¦ç”¨ LLM/Substitution.json (banks æ ¼å¼è½‰å®Œå˜… substitution_errors)ï¼š
        # return substitution_errors

    if st == "InitialConsonant":
        return InitialConsonant

    if st == "Omission":
        return omission_errors  # æˆ– omission_errors_llm1ï¼ˆä½ è¦çµ±ä¸€ä¸€ä»½ï¼‰

    if st == "Addition":
        return ADDITION_BANK

    if st == "Tone":
        return Tone_errors_llm1

    if st == "Distortion":
        return distortion_errors_llm1

    if st == "VowelFinal":
        return VowelFinal

    # fallbackï¼ˆå¯ç•™å¯å””ç•™ï¼‰
    return slpErrors

#-------English get word ----------------------------------------
@app.get("/api/practice/next-word", response_model=NextWordResp)
def api_practice_next_word(
    super_type: str = Query(...),
    sub_type: str = Query(...),
    language: str = Query("en"),
    current_user_id: str = Depends(get_current_user_id),
    difficulty_level: str = Query("å°å­¸"),
):
    ensure_practice_progress_table()

    lang = normalize_practice_language(language)

    bank_map = get_practice_bank_by_super_type(super_type)

    if sub_type not in bank_map:
        raise HTTPException(status_code=400, detail=f"Unknown sub_type: {sub_type} (super_type={super_type})")

    bank = bank_map[sub_type]
        
    total_items = len(bank)
    if total_items <= 0:
        raise HTTPException(status_code=400, detail="Empty bank")

    conn = get_db()
    cur = conn.cursor()

    # 1) è®€ progressï¼ˆå†‡å°±å»ºä¸€è¡Œï¼‰
    cur.execute("""
        SELECT id, next_start_index, chunk_size
        FROM practice_progress
        WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
    """, (current_user_id, super_type, sub_type, lang))
    row = cur.fetchone()

    if row:
        prog_id, next_idx, chunk_size = row[0], int(row[1] or 0), int(row[2] or 50)
    else:
        prog_id = str(uuid.uuid4())
        next_idx = 0
        chunk_size = 50
        cur.execute("""
            INSERT INTO practice_progress
            (id, user_id, super_type, sub_type, language, chunk_size, next_start_index, last_range_end)
            VALUES (?, ?, ?, ?, ?, ?, 0, 0)
        """, (prog_id, current_user_id, super_type, sub_type, lang, chunk_size))
        conn.commit()

    # 2) è‹¥åšå®Œå…¨éƒ¨ â†’ é‡ç½®å› 0ï¼ˆå†å›åˆ° 1-50ï¼‰
    if next_idx >= total_items:
        next_idx = 0
        cur.execute("""
            UPDATE practice_progress
            SET next_start_index=0, last_range_end=0, updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (prog_id,))
        conn.commit()

    # 3) å–ä¸‹ä¸€å€‹è©
    word = bank[next_idx]

    # 4) å»ºç«‹ä¸€ç­† records_analysis è¨˜éŒ„ã€Œæ´¾é¡Œã€
    record_id = save_word_take_record(
        user_id=current_user_id,
        language="Chinese" if lang == "cn" else "English",  # ä½ çš„ records_analysis.language ç›®å‰æ˜¯å­˜ "Chinese"/"English"
        test_type=super_type,
        category=sub_type,              # æˆ– patternï¼›ä½†å° practice bank å…ˆç”¨ sub_type è¼ƒåˆç†
        target_word=word,
        difficulty_level=normalize_difficulty(difficulty_level),
    )

    conn.close()

    return NextWordResp(
        super_type=super_type,
        sub_type=sub_type,
        language=lang,
        index=next_idx + 1,
        total_items=total_items,
        word=word,
        record_id=record_id
    )

class CommitOneReq(BaseModel):
    super_type: str
    sub_type: str
    language: str = "en"
    record_id: str

    asr_word: str = ""
    asr_ipa: str = ""

    # âœ… new: score (front-end send back)
    score: Optional[int] = None

    correct_rate: Optional[int] = None
    check_results: dict = {}

    task_id: Optional[str] = None
    task_kind: str = "vocab"
    task_increment: int = 1

@app.post("/api/practice/commit-one")
def api_practice_commit_one(
    data: CommitOneReq,
    current_user_id: str = Depends(get_current_user_id),
):
    ensure_practice_progress_table()
    ensure_task_table_v2()  # âœ… ensure tasks columns exist

    super_type = (data.super_type or "").strip()
    sub_type = (data.sub_type or "").strip()
    lang = normalize_practice_language(data.language)

    if not super_type or not sub_type:
        raise HTTPException(status_code=400, detail="Missing super_type/sub_type")

    task_kind = (data.task_kind or "vocab").strip().lower()
    if task_kind not in ("vocab", "sentence"):
        raise HTTPException(status_code=400, detail="Invalid task_kind (vocab|sentence)")

    inc = int(data.task_increment or 0)
    if inc < 0 or inc > 10:
        raise HTTPException(status_code=400, detail="Invalid task_increment")

    conn = get_db()
    cur = conn.cursor()

    try:
        # -------------------------
        # 0) verify record ownership
        # -------------------------
        cur.execute("SELECT user_id FROM records_analysis WHERE id=?", (data.record_id,))
        r = cur.fetchone()
        if not r:
            raise HTTPException(status_code=404, detail="record_id not found")
        if r[0] != current_user_id:
            raise HTTPException(status_code=403, detail="not allowed")

        # -------------------------
        # 1) TASK gate + increment (if task_id provided & inc>0)
        # today-only + day_index gating + prev day must completed
        # -------------------------
        if data.task_id and inc > 0:
            cur.execute("""
                SELECT
                  id, user_id, super_type, sub_type, task_kind, language,
                  allocated_at, day_index, valid_days,
                  total_times, progress_times, status, is_active
                FROM tasks
                WHERE id=?
                LIMIT 1
            """, (data.task_id,))
            t = cur.fetchone()
            if not t:
                raise HTTPException(status_code=404, detail="task_id not found")

            (tid, uid, t_super, t_sub, t_kind, t_lang,
             allocated_at, day_index, valid_days,
             total_times, progress_times, status, is_active) = t

            if uid != current_user_id:
                raise HTTPException(status_code=403, detail="task not allowed")

            if int(is_active or 0) != 1:
                raise HTTPException(status_code=400, detail="task inactive")

            # must match this practice
            if str(t_super) != super_type or str(t_sub) != sub_type:
                raise HTTPException(status_code=400, detail="task super_type/sub_type mismatch")
            if normalize_practice_language(t_lang) != lang:
                raise HTTPException(status_code=400, detail="task language mismatch")
            if str(t_kind).lower() != task_kind:
                raise HTTPException(status_code=400, detail="task_kind mismatch")

            # âœ… today-only: allowed day index must equal day_index
            allowed = _task_allowed_day_index(allocated_at)
            if allowed is None:
                raise HTTPException(status_code=400, detail="task expired or invalid allocated_at")

            if int(day_index) != int(allowed):
                # today only can do today task; cannot do past/future
                raise HTTPException(status_code=400, detail=f"NOT_TODAY_TASK_DAY allowed_day_index={allowed}")

            # increment task progress
            total = int(total_times or 0)
            prog = int(progress_times or 0)
            new_prog = prog + inc
            if total > 0:
                new_prog = min(new_prog, total)

            new_status = status
            if total > 0 and new_prog >= total:
                new_status = "completed"

            cur.execute("""
                UPDATE tasks
                SET progress_times=?,
                    status=?
                WHERE id=?
            """, (new_prog, new_status, tid))

        # -------------------------
        # 2-0) âœ… prevent double commit points
        # -------------------------
        cur.execute("SELECT check_results FROM records_analysis WHERE id=?", (data.record_id,))
        row = cur.fetchone()
        old_check_results = {}
        if row and row[0]:
            try:
                old_check_results = json.loads(row[0])
            except Exception:
                old_check_results = {}

        already_committed = isinstance(old_check_results, dict) and old_check_results.get("event") == "read_word"

        # -------------------------
        # 2) update records_analysis
        # -------------------------
        cur.execute("""
            UPDATE records_analysis
            SET asr_word=?,
                asr_ipa=?,
                correct_rate=?,
                check_results=?,
                created_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (
            data.asr_word,
            data.asr_ipa,
            str(data.correct_rate) if data.correct_rate is not None else None,
            json.dumps({"event": "read_word", **(data.check_results or {})}, ensure_ascii=False),
            data.record_id
        ))

        # -------------------------
        # 3) push practice_progress +1
        # -------------------------
        cur.execute("""
            UPDATE practice_progress
            SET next_start_index = next_start_index + 1,
                updated_at = CURRENT_TIMESTAMP
            WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
        """, (current_user_id, super_type, sub_type, lang))

        if cur.rowcount != 1:
            raise HTTPException(status_code=400, detail="practice_progress row not found (call next-word first)")
        
        # -------------------------
        # 4) âœ… add integral (score) for patient header
        # -------------------------
        try:
            pts = int(data.score) if data.score is not None else 0
        except Exception:
            pts = 0

        if (not already_committed) and pts > 0:
            cur.execute(
                "UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?",
                (pts, current_user_id)
            )

        conn.commit()
        return {"msg": "ok", "record_id": data.record_id}

    except HTTPException:
        conn.rollback()
        raise
    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=500, detail=f"commit-one failed: {str(e)}")
    finally:
        conn.close()

def save_word_take_record(
    user_id: str,
    language: str,
    test_type: str,
    category: str,
    target_word: str,
    difficulty_level: str = "primary",
):
    return save_records_analysis_v2(
        user_id=user_id,
        language=language,
        test_type=test_type,
        category=category,
        target_word=target_word,
        target_ipa="",
        asr_ipa="",
        asr_word="",
        correct_rate=None,
        check_results={"event": "take_word"},
        difficulty_level=difficulty_level,
        score=None,
        severity=None,
    )

from fastapi import UploadFile, File, Form

@app.post("/api/practice/commit-one-with-audio")
async def api_practice_commit_one_with_audio(
    record_id: str = Form(...),
    super_type: str = Form(...),
    sub_type: str = Form(...),
    language: str = Form("cn"),
    asr_word: str = Form(""),
    asr_ipa: str = Form(""),
    correct_rate: str = Form(""),
    check_results: str = Form("{}"),
    score: str = Form(""),
    file: UploadFile = File(...),
    current_user_id: str = Depends(get_current_user_id),
):
    ensure_practice_progress_table()

    # 0) verify record ownership
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT user_id FROM records_analysis WHERE id=?", (record_id,))
    r = cur.fetchone()
    if not r:
        conn.close()
        raise HTTPException(status_code=404, detail="record_id not found")
    if r[0] != current_user_id:
        conn.close()
        raise HTTPException(status_code=403, detail="not allowed")

    # 1) save audio
    os.makedirs(UPLOAD_AUDIO_DIR, exist_ok=True)
    ext = ".wav"
    fn = f"{record_id}{ext}"
    save_path = os.path.join(UPLOAD_AUDIO_DIR, fn)
    content = await file.read()
    with open(save_path, "wb") as f:
        f.write(content)

    audio_url = f"/uploads/audio/{fn}"

    # 2) parse json
    try:
        check_obj = json.loads(check_results) if check_results else {}
    except Exception:
        check_obj = {"raw": check_results}

    # 3) normalize numeric
    cr = None
    try:
        cr = int(float(correct_rate)) if str(correct_rate).strip() != "" else None
    except Exception:
        cr = None

    sc = None
    try:
        sc = int(float(score)) if str(score).strip() != "" else None
    except Exception:
        sc = None

    # fallback scoring if not provided
    if sc is None and cr is not None:
        sc = int(cr)  # æœ€ç°¡å–®ï¼šscore=correct_rateï¼ˆä½ ä¹‹å¾Œå¯æ”¹è¦å‰‡ï¼‰

    # 4) update records_analysis (store audio path + score)
    cur.execute("""
        UPDATE records_analysis
        SET asr_word=?,
            asr_ipa=?,
            correct_rate=?,
            score=?,
            check_results=?,
            created_at=CURRENT_TIMESTAMP
        WHERE id=?
    """, (
        asr_word,
        asr_ipa,
        str(cr) if cr is not None else None,
        sc,
        json.dumps({"event": "read_word", "audio_url": audio_url, **(check_obj or {})}, ensure_ascii=False),
        record_id
    ))

    # 5) push progress
    lang = normalize_practice_language(language)
    cur.execute("""
        UPDATE practice_progress
        SET next_start_index = next_start_index + 1,
            updated_at = CURRENT_TIMESTAMP
        WHERE user_id=? AND super_type=? AND sub_type=? AND language=?
    """, (current_user_id, super_type, sub_type, lang))

    if cur.rowcount != 1:
        conn.rollback()
        conn.close()
        raise HTTPException(status_code=400, detail="practice_progress row not found (call next-word first)")

    # 6) add integral (score)
    if sc:
        cur.execute("UPDATE patients SET integral = COALESCE(integral,0) + ? WHERE id=?", (sc, current_user_id))

    conn.commit()
    conn.close()


    return {"msg": "ok", "record_id": record_id, "audio_url": audio_url, "score": sc}

def award_points_on_task_completed(cur, user_id: str, task_id: str, points: int = 100):
    """
    ç•¶ task ç¬¬ä¸€æ¬¡å®Œæˆï¼ˆpending -> completedï¼‰æ™‚ï¼ŒåŠ åˆ†ä¸€æ¬¡ã€‚
    ä¾è³´ tasks.status åœ¨åŒä¸€å€‹ transaction å…§æ­£ç¢ºæ›´æ–°ã€‚
    """
    points = int(points or 0)
    if points <= 0:
        return

    # âœ… åŠ åˆ†
    cur.execute(
        "UPDATE patients SET integral = COALESCE(integral, 0) + ? WHERE id=?",
        (points, user_id)
    )

def patient_friendly_explain(check_results: dict) -> dict:
    """
    Convert technical detector outputs into patient-friendly English explanations.

    Return format:
      {
        "summary": "...",
        "items": {
          "substitution": {"explain": "...", "tip": "..."},
          ...
        }
      }
    """
    out = {"summary": "", "items": {}}

    if not isinstance(check_results, dict):
        return {
            "summary": "No analysis details available.",
            "items": {}
        }

    meta = check_results.get("meta", {}) if isinstance(check_results.get("meta", {}), dict) else {}
    off = meta.get("off_target", {}) if isinstance(meta.get("off_target", {}), dict) else {}

    # Off-target first (high priority)
    if isinstance(off, dict) and off.get("is_off_target"):
        out["summary"] = (
            "The system may have recognized your speech as a different word (offâ€‘target). "
            "Try speaking more slowly and clearly syllable by syllable, then try again."
        )

    def add_item(k: str, explain: str, tip: str):
        out["items"][k] = {"explain": explain, "tip": tip}

    # ---- substitution ----
    sub = check_results.get("substitution")
    if isinstance(sub, dict) and sub.get("has_substitution"):
        typ = sub.get("type")
        if typ == "å£°æ¯æ›¿ä»£":
            add_item(
                "substitution",
                "Your initial consonant (the beginning sound) seems to have changed to a different one (e.g., z/zh, c/ch, s/sh).",
                "Exaggerate the initial consonant first, then add the final. Practice: initial â†’ final â†’ full syllable."
            )
        elif typ == "éŸµæ¯æ›¿ä»£":
            add_item(
                "substitution",
                "Your final/vowel part seems to have changed to a different final.",
                "Keep a stable mouth shape (opening, lip rounding, tongue position). Practice the final alone, then combine it with the initial."
            )
        elif typ == "å£°è°ƒæ›¿ä»£":
            add_item(
                "substitution",
                "Your tone pattern does not match the target word.",
                "Hum the tone contour first (Tone 1 level, Tone 2 rising, Tone 3 dipping, Tone 4 falling), then apply it to the syllable."
            )
        else:
            add_item(
                "substitution",
                "A substitution difference was detected between your pronunciation and the target.",
                "Slow down and read syllable by syllable. Check initial consonant, final, and tone."
            )

    # ---- tone ----
    tone = check_results.get("tone")
    if isinstance(tone, dict) and tone.get("has_tone_error"):
        typ = tone.get("type")
        if typ == "å£°è°ƒæ›¿ä»£":
            add_item(
                "tone",
                "The tone (tone number) seems incorrect.",
                "Practice the tone contour alone, then read the word."
            )
        elif typ == "å£°è°ƒé”™ä½":
            add_item(
                "tone",
                "This may involve tone sandhi (tone change rules), such as consecutive third tones or the word 'ä¸€'.",
                "Apply tone sandhi rules slowly (e.g., 3+3 â†’ 2+3). Then speed up gradually."
            )
        elif typ == "è½»å£°é”™è¯¯":
            add_item(
                "tone",
                "The target includes a neutral tone, but you pronounced it with a full tone.",
                "Neutral tone should be lighter and shorter; place the stress on the previous syllable."
            )
        else:
            add_item(
                "tone",
                "A tone-related issue was detected.",
                "Confirm each syllableâ€™s tone first, then read the word smoothly."
            )

    # ---- vowel_final ----
    vf = check_results.get("vowel_final")
    if isinstance(vf, dict) and vf.get("has_vowel_error"):
        typ = vf.get("type")
        if typ == "å•å…ƒéŸ³æ›¿ä»£":
            add_item(
                "vowel_final",
                "A simple vowel (a/o/e/i/u/Ã¼) may have been produced differently than expected.",
                "Use a mirror to stabilize mouth opening, lip rounding, and tongue position."
            )
        elif typ == "å¤åˆéŸµæ¯é”™è¯¯":
            add_item(
                "vowel_final",
                "A compound final (e.g., ai/ao/ou/ang/eng) may be incomplete or in the wrong sequence.",
                "Break the final into parts and say it slowly, then blend it smoothly."
            )
        else:
            add_item(
                "vowel_final",
                "The final (vowel part) does not match the target.",
                "Practice the final first, then add the initial consonant."
            )

    # ---- initial (initial consonant category) ----
    ini = check_results.get("initial")
    if isinstance(ini, dict) and ini.get("has_initial_error"):
        typ = ini.get("type")
        if typ == "å£°æ¯çœç•¥":
            add_item(
                "initial",
                "The initial consonant may have been omitted (it sounds like the syllable starts directly with a vowel).",
                "Practice producing the initial consonant briefly and clearly, then attach the final."
            )
        elif typ == "å£°æ¯æ·»åŠ ":
            add_item(
                "initial",
                "An extra initial consonant may have been added (the target might start without that consonant).",
                "Confirm whether the target syllable needs an initial. Try starting from the final and then adding the correct initial."
            )
        elif typ == "å‘éŸ³éƒ¨ä½é”™è¯¯":
            add_item(
                "initial",
                "The place of articulation may be incorrect (e.g., tongue position for retroflex vs. nonâ€‘retroflex).",
                "Practice tongue placement and airflow. Compare pairs like z vs zh, c vs ch, s vs sh."
            )
        else:  # å£°æ¯æ›¿ä»£
            add_item(
                "initial",
                "The initial consonant seems to have changed to a different consonant.",
                "Slow down and focus on contrasts such as aspiration and retroflex vs. nonâ€‘retroflex."
            )

    # ---- omission ----
    omi = check_results.get("omission")
    if isinstance(omi, dict) and omi.get("has_omission"):
        typ = omi.get("type")
        if typ == "å£°æ¯è„±è½":
            add_item(
                "omission",
                "The initial consonant may be missing.",
                "Slow down and make the initial consonant clear (especially b/p/m, d/t, zh/ch/sh)."
            )
        elif typ == "éŸµå°¾è„±è½":
            add_item(
                "omission",
                "The ending nasal sound (n/ng) may be missing.",
                "Close the ending properly: n uses the tongue tip; ng uses the back of the tongue."
            )
        elif typ == "éŸµæ¯è„±è½":
            add_item(
                "omission",
                "The vowel/final may be shortened or partially missing.",
                "Hold the vowel long enough, then add the tone."
            )
        elif typ == "å£°è°ƒè„±è½":
            add_item(
                "omission",
                "The tone marking may be missing (it sounds like a neutral/untone syllable).",
                "Make sure each syllable carries a tone contour; start slow, then increase speed."
            )
        else:
            add_item(
                "omission",
                "A possible omission was detected.",
                "Read syllable by syllable to ensure each part is fully produced."
            )

    # ---- addition ----
    add = check_results.get("addition")
    if isinstance(add, dict) and add.get("has_addition"):
        typ = add.get("type")
        if typ == "å£°æ¯æ·»åŠ ":
            add_item(
                "addition",
                "An extra initial consonant may have been added.",
                "Avoid extra bursts/friction at the start; enter the correct initial directly."
            )
        elif typ == "éŸµæ¯æ·»åŠ ":
            add_item(
                "addition",
                "An extra vowel/final element may have been added (often from overâ€‘lengthening).",
                "Keep the syllable clean and concise; avoid dragging the vowel."
            )
        elif typ == "éŸµå°¾æ·»åŠ ":
            add_item(
                "addition",
                "An extra ending (n/ng) may have been added.",
                "Shorten the ending and avoid adding nasal sounds."
            )
        else:  # æ’éŸ³
            add_item(
                "addition",
                "An extra transitional sound may have been inserted between syllables.",
                "Slow down and avoid adding a 'bridge sound' when connecting syllables."
            )

    # ---- distortion ----
    dis = check_results.get("distortion")
    if isinstance(dis, dict) and dis.get("has_distortion"):
        add_item(
            "distortion",
            "This word is in the distortion training set and may require extra attention to sound quality.",
            "Practice mouth shape and airflow for the target sound class; start slow and speed up gradually."
        )

    # Default summary if empty
    if not out["summary"]:
        has_any_error = any(
            isinstance(v, dict) and any(v.get(k) for k in (
                "has_addition",
                "has_substitution",
                "has_tone_error",
                "has_distortion",
                "has_omission",
                "has_initial_error",
                "has_vowel_error",
            ))
            for v in check_results.values()
        )

        out["summary"] = (
            "A difference from the target pronunciation was detected. Try slowing down and practicing syllable by syllable."
            if has_any_error
            else "Your pronunciation looks correct overall. Keep the same clarity and pacing."
        )

    return out

TEST_LANG = "cn"  # fixed for this screening test

TEST_BANKS = {
    "Addition": safe_load_json("LLM1/Addition.json"),
    "Distortion": safe_load_json("LLM1/Distortion.json"),
    "Omission": safe_load_json("LLM1/omission.json"),
    "Substitution": safe_load_json("LLM1/substitution.json"),
    "Tone": safe_load_json("LLM1/Tone.json"),
    "VowelFinal": safe_load_json("LLM1/VowelFinal.json"),
    "InitialConsonant": safe_load_json("LLM1/InitialConsonant.json"),
}

def create_test_session_row_v2(
    user_id: str,
    test_name: str,
    *,
    language: str,
    words_per_subtype: int,
    threshold: int,
    plan_obj: dict,
    total_questions: int,
    config_obj: dict | None = None,
) -> str:
    """
    å»ºç«‹ tests(super test) ä¸€ç­†è³‡æ–™ï¼ˆæ–° schemaï¼‰
    - å¿…é ˆå¯«å…¥ planï¼ˆå› ç‚º tests.plan NOT NULLï¼‰
    - å¯«å…¥ total_questions/current_question_indexï¼Œæ–¹ä¾¿ resume
    """
    conn = get_db()
    cur = conn.cursor()
    tid = str(uuid.uuid4())

    cur.execute("""
        INSERT INTO tests (
            id, patient_id,
            test_name, status,
            progress_cursor, total_questions, current_question_index,
            plan, config_json,
            threshold, words_per_subtype, language,
            has_slp, result,
            date, updated_at, finished_at
        ) VALUES (
            ?, ?,
            ?, 'running',

            0, ?, 0,

            ?, ?,

            ?, ?, ?,

            0, NULL,

            CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, NULL
        )
    """, (
        tid, user_id,
        test_name,
        int(total_questions),
        json.dumps(plan_obj, ensure_ascii=False),
        json.dumps(config_obj or {}, ensure_ascii=False),
        int(threshold),
        int(words_per_subtype),
        str(language),
    ))
    conn.commit()
    conn.close()
    return tid


def update_test_session_result(test_id: str, has_slp: int, result_obj: dict):
    conn = get_db()
    cur = conn.cursor()
    cur.execute("""
        UPDATE tests
        SET has_slp=?,
            result=?,
            status='finished',
            updated_at=CURRENT_TIMESTAMP,
            finished_at=CURRENT_TIMESTAMP
        WHERE id=?
    """, (int(has_slp or 0), json.dumps(result_obj, ensure_ascii=False), test_id))
    conn.commit()
    conn.close()


def insert_slp_patient_rows(
    user_id: str,
    test_id: str,
    confirmed: list[tuple[str, str]],  # [(super_type, sub_type), ...]
    language: str = TEST_LANG,
):
    """
    Insert rows into slp_patient for confirmed SLP categories.
    (No de-dup logic enforced by schema, so we do safe dedup in code.)
    """
    if not confirmed:
        return

    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    uniq = []
    seen = set()
    for st, sb in confirmed:
        key = (str(st), str(sb))
        if key not in seen:
            seen.add(key)
            uniq.append(key)

    conn = get_db()
    cur = conn.cursor()

    for st, sb in uniq:
        cur.execute("""
            INSERT INTO slp_patient (id, user_id, test_id, datetime, super_type, sub_type, language)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (str(uuid.uuid4()), user_id, test_id, now, st, sb, language))

    conn.commit()
    conn.close()

from pydantic import BaseModel
from typing import List, Dict, Any

TEST_SUPER_ORDER = [
    "Addition",
    "Distortion",
    "Omission",
    "Substitution",
    "Tone",
    "VowelFinal",
    "InitialConsonant",
]

class TestStartResp(BaseModel):
    test_id: str
    language: str
    words_per_subtype: int
    plan: List[Dict[str, Any]]  # [{super_type, sub_type, words:[...]}]
    total_questions: int


def _pick_n_words(bank_list: list[str], n: int) -> list[str]:
    if not bank_list:
        return []
    if len(bank_list) <= n:
        # shuffle copy
        tmp = list(bank_list)
        random.shuffle(tmp)
        return tmp
    # sample unique
    return random.sample(bank_list, n)


@app.post("/api/test/start", response_model=TestStartResp)
def api_test_start(
    words_per_subtype: int = Query(None, description="optional override; backend default if omitted"),
    current_user_id: str = Depends(get_current_user_id),
):
    n = int(words_per_subtype or TEST_WORDS_PER_SUBTYPE)
    if n <= 0 or n > 20:
        raise HTTPException(status_code=400, detail="Invalid words_per_subtype (1..20)")

    plan: list[dict] = []
    total = 0

    for super_type in TEST_SUPER_ORDER:
        banks = TEST_BANKS.get(super_type, {})
        if not isinstance(banks, dict):
            continue

        for sub_type in sorted(list(banks.keys())):
            words = banks.get(sub_type, [])
            if not isinstance(words, list):
                continue

            picked = _pick_n_words([w for w in words if isinstance(w, str) and w.strip()], n)
            if not picked:
                continue

            plan.append({"super_type": super_type, "sub_type": sub_type, "words": picked})
            total += len(picked)

    if total == 0:
        raise HTTPException(status_code=500, detail="Test banks empty / failed to build plan")

    flat_queue = build_test_flat_queue(plan)
    plan_obj = {
        "language": TEST_LANG,
        "words_per_subtype": n,
        "plan": plan,
        "flatQueue": flat_queue,
        "total_questions": total,
    }

    config_obj = {
        "enabled_super_order": TEST_SUPER_ORDER,
        "enabled_subtypes": {st: sorted(list((TEST_BANKS.get(st) or {}).keys())) for st in TEST_SUPER_ORDER},
    }

    # âœ… é€™è£¡å…ˆ insert testsï¼ˆplan NOT NULLï¼‰
    test_id = create_test_session_row_v2(
        user_id=current_user_id,
        test_name=f"SLP Screening ({TEST_LANG})",
        language=TEST_LANG,
        words_per_subtype=n,
        threshold=TEST_SLP_THRESHOLD,
        plan_obj=plan_obj,
        total_questions=total,
        config_obj=config_obj,
    )

    return TestStartResp(
        test_id=test_id,
        language=TEST_LANG,
        words_per_subtype=n,
        plan=plan,
        total_questions=total,
    )

class TestFinishResp(BaseModel):
    test_id: str
    language: str
    threshold: int
    confirmed: List[Dict[str, Any]]  # [{super_type, sub_type, slp_count}]
    has_slp: int

class TestAnalyzeResp(BaseModel):
    test_record_id: str
    test_id: str
    super_type: str
    sub_type: str
    target_word: str

    asr_ipa: str
    revise_ipa: str
    asr_word: str
    correct_rate: int
    status: str
    severity: Optional[str] = None
    is_off_target: bool = False
    check_results: dict


def _detector_key_for_super(super_type: str) -> str:
    mapping = {
        "Addition": "addition",
        "Distortion": "distortion",
        "Omission": "omission",
        "Substitution": "substitution",
        "Tone": "tone",
        "VowelFinal": "vowel_final",
        "InitialConsonant": "initial",
    }
    return mapping.get(super_type, "")


def _run_detector(super_type: str, target_word: str, asr_ipa: str, off: dict, correct_rate: int) -> dict:
    """
    Run the matching rule-based detector (no LLM) and return its dict result.
    """
    st = (super_type or "").strip()

    if st == "Addition":
        return detect_addition_error_1(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    if st == "Distortion":
        return detect_distortion_error(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    if st == "Omission":
        return detect_omission_error_1(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    if st == "Substitution":
        return detect_substitution_error_1(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    if st == "Tone":
        return detect_tone_error(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    if st == "VowelFinal":
        return detect_vowelfinal_error(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    if st == "InitialConsonant":
        return detect_initial_consonant_error(target_word, asr_ipa, llm=None, off_target=off, correct_rate=correct_rate)

    raise HTTPException(status_code=400, detail=f"Unsupported super_type: {super_type}")


def _normalize_severity_value(v) -> Optional[str]:
    s = str(v or "").strip().lower()
    if s in ("slight", "middle", "high"):
        return s
    if s == "medium":
        return "middle"
    return None


@app.post("/api/test/analyze", response_model=TestAnalyzeResp)
async def api_test_analyze(
    file: UploadFile = File(...),
    test_id: str = Form(...),
    super_type: str = Form(...),
    sub_type: str = Form(...),
    target_word: str = Form(...),
    question_index: int = Form(...),
    difficulty_level: str = Form("å°å­¸"),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Test-only analyze:
    - runs ASR + single detector based on super_type
    - saves into test_records
    - does NOT touch records_analysis
    """
    super_type = (super_type or "").strip()
    sub_type = (sub_type or "").strip()
    target_word = (target_word or "").strip()

    if not test_id:
        raise HTTPException(status_code=400, detail="Missing test_id")
    if not super_type or super_type not in TEST_SUPER_ORDER:
        raise HTTPException(status_code=400, detail="Invalid super_type")
    if not sub_type:
        raise HTTPException(status_code=400, detail="Missing sub_type")
    if not target_word:
        raise HTTPException(status_code=400, detail="Missing target_word")

    # verify test_id belongs to this patient
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT patient_id FROM tests WHERE id=?", (test_id,))
    row = cur.fetchone()
    conn.close()
    if not row:
        raise HTTPException(status_code=404, detail="test_id not found")
    if row[0] != current_user_id:
        raise HTTPException(status_code=403, detail="Not allowed")

    # verify sub_type exists in bank for this super_type (safety)
    bank_map = TEST_BANKS.get(super_type, {})
    if sub_type not in bank_map:
        raise HTTPException(status_code=400, detail=f"sub_type not in bank: {sub_type}")

    content = await file.read()

    # ASR
    asr_result = transcribe_bytes(
        audio_bytes=content,
        filename=file.filename,
        target_word=target_word,
        difficulty_level=difficulty_level,
    )

    asr_ipa = asr_result.get("asr_ipa", "") or ""
    target_ipa = (asr_result.get("target_ipa", "") or "").replace("/", "") or ""

    asr_word = asr_result.get("asr_word", "") or ""
    if not asr_word:
        if asr_ipa.strip() == target_ipa.strip():
            asr_word = target_word
        else:
            asr_word = pinyin_to_chinese_diff(asr_ipa, target_ipa, target_word)

    # accuracy + score
    correct_rate = calc_correct_rate(asr_ipa, target_ipa)
    score_points = int(round(correct_rate / 10))

    # off target
    off = compute_off_target(target_ipa, asr_ipa)
    is_off_target = bool(off.get("is_off_target"))

    # detector
    det_res = _run_detector(super_type, target_word, asr_ipa, off, correct_rate)
    det_key = _detector_key_for_super(super_type)
    if not det_key:
        raise HTTPException(status_code=500, detail="detector key mapping missing")

    # build check_results (include test meta)
    check_results = {
        "meta": {
            "event": "test_analyze",
            "test_id": test_id,
            "language": TEST_LANG,
            "off_target": off,
            "question_index": int(question_index),
            "enabled_checks": [det_key],
            "super_type": super_type,
            "sub_type": sub_type,
        },
        det_key: det_res,
    }

    # status = ipa match (same convention you already use)
    status = "correct" if (asr_ipa.strip() == target_ipa.strip()) else "wrong"

    # severity only when final_label == slp
    final_label = str((det_res or {}).get("final_label") or "").strip().lower()
    severity_value = _normalize_severity_value((det_res or {}).get("severity")) if final_label == "slp" else None

    # âœ… Save test_record + update progress_cursor in ONE transaction
    conn = get_db()
    cur = conn.cursor()
    try:
        # Ensure test still belongs to this user and is running
        cur.execute("SELECT patient_id, status FROM tests WHERE id=?", (test_id,))
        trow = cur.fetchone()
        if not trow:
            raise HTTPException(status_code=404, detail="test_id not found")
        if trow[0] != current_user_id:
            raise HTTPException(status_code=403, detail="Not allowed")
        if str(trow[1] or "").lower() != "running":
            raise HTTPException(status_code=400, detail="Test is not running")

        # 1) insert into test_records (same tx)
        test_record_id = save_test_record_v2_tx(
            cur,
            test_id=test_id,
            question_index=int(question_index),
            user_id=current_user_id,
            language="Chinese",
            test_type=super_type,
            category=sub_type,
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=difficulty_level,
            score=score_points,
            severity=severity_value,
        )

        # 2) recompute cursor (now includes this inserted row)
        cur.execute("SELECT COUNT(DISTINCT question_index) FROM test_records WHERE test_id=?", (test_id,))
        done_count = int(cur.fetchone()[0] or 0)

        cur.execute("""
            UPDATE tests
            SET progress_cursor=?,
                current_question_index=?,
                updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (done_count, done_count, test_id))

        conn.commit()

    except HTTPException:
        conn.rollback()
        raise
    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=500, detail=f"test_analyze failed: {str(e)}")
    finally:
        conn.close()

    return TestAnalyzeResp(
        test_record_id=test_record_id,
        test_id=test_id,
        super_type=super_type,
        sub_type=sub_type,
        target_word=target_word,
        asr_ipa=asr_ipa,
        revise_ipa=target_ipa,
        asr_word=asr_word,
        correct_rate=correct_rate,
        status=status,
        severity=severity_value,
        is_off_target=is_off_target,
        check_results=check_results,
    )

@app.post("/api/test/finish", response_model=TestFinishResp)
def api_test_finish(
    test_id: str = Query(...),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Finish test:
    - read test_records for this test_id (from check_results.meta.test_id)
    - count slp per (super_type, sub_type)
    - if count >= threshold => insert into slp_patient
    - update tests.has_slp and tests.result
    """
    if not test_id:
        raise HTTPException(status_code=400, detail="Missing test_id")

    # verify ownership
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT patient_id FROM tests WHERE id=?", (test_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        raise HTTPException(status_code=404, detail="test_id not found")
    if row[0] != current_user_id:
        conn.close()
        raise HTTPException(status_code=403, detail="Not allowed")

    # load records for this test_id
    cur.execute("""
        SELECT test_type, category, check_results
        FROM test_records
        WHERE test_id=?
        ORDER BY question_index ASC
    """, (test_id,))
    rows = cur.fetchall()
    conn.close()

    # count slp by (super_type, sub_type)
    counter = {}  # (st, sb) -> count
    for st, sb, cr_json in rows:
        try:
            obj = json.loads(cr_json) if cr_json else {}
        except Exception:
            continue

        meta = obj.get("meta", {}) if isinstance(obj.get("meta"), dict) else {}
        if meta.get("test_id") != test_id:
            continue

        super_type = str(meta.get("super_type") or st or "").strip()
        sub_type = str(meta.get("sub_type") or sb or "").strip()
        if not super_type or not sub_type:
            continue

        det_key = _detector_key_for_super(super_type)
        det = obj.get(det_key, {}) if det_key else {}
        final_label = str((det or {}).get("final_label") or "").strip().lower()

        if final_label == "slp":
            counter[(super_type, sub_type)] = counter.get((super_type, sub_type), 0) + 1

    confirmed = []
    confirmed_pairs = []
    for (st, sb), c in sorted(counter.items(), key=lambda x: (-x[1], x[0][0], x[0][1])):
        if c >= TEST_SLP_THRESHOLD:
            confirmed.append({"super_type": st, "sub_type": sb, "slp_count": c})
            confirmed_pairs.append((st, sb))

    # insert slp_patient rows
    insert_slp_patient_rows(
        user_id=current_user_id,
        test_id=test_id,
        confirmed=confirmed_pairs,
        language=TEST_LANG
    )

    has_slp = 1 if confirmed_pairs else 0

    # update tests row
    summary_obj = {
        "language": TEST_LANG,
        "threshold": TEST_SLP_THRESHOLD,
        "confirmed": confirmed,
        "counts": {f"{k[0]}::{k[1]}": v for k, v in counter.items()},
    }
    update_test_session_result(test_id=test_id, has_slp=has_slp, result_obj=summary_obj)

    return TestFinishResp(
        test_id=test_id,
        language=TEST_LANG,
        threshold=TEST_SLP_THRESHOLD,
        confirmed=confirmed,
        has_slp=has_slp
    )

class TestResumeResp(BaseModel):
    available: bool
    test_id: Optional[str] = None
    status: Optional[str] = None
    progress_cursor: int = 0
    plan: Optional[dict] = None
    language: Optional[str] = None

@app.get("/api/test/resume", response_model=TestResumeResp)
def api_test_resume(
    language: str = Query("cn"),
    current_user_id: str = Depends(get_current_user_id)
):
    ensure_tests_table_v2_columns()

    lang = normalize_practice_language(language)  # æœƒè®Šæˆ 'cn' æˆ– 'en'

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT id, status, progress_cursor, plan, language
            FROM tests
            WHERE patient_id=?
              AND status='running'
              AND language=?                     -- âœ… é—œéµï¼šé™åˆ¶èªè¨€
            ORDER BY datetime(updated_at) DESC, datetime(date) DESC
            LIMIT 1
        """, (current_user_id, lang))
        row = cur.fetchone()

        if not row:
            return TestResumeResp(available=False)

        test_id, status, progress_cursor, plan_json, test_lang = row

        plan_obj = None
        if plan_json:
            try:
                plan_obj = json.loads(plan_json)
            except Exception:
                plan_obj = {"raw": plan_json}

        return TestResumeResp(
            available=True,
            test_id=test_id,
            status=status,
            progress_cursor=int(progress_cursor or 0),
            plan=plan_obj,
            language=test_lang
        )
    finally:
        conn.close()

def save_test_record_v2_tx(
    cur,
    *,
    test_id: str,
    question_index: int,
    user_id: str,
    language: str,
    test_type: str,
    category: str,
    target_word: str,
    target_ipa: str,
    asr_ipa: str,
    asr_word: str,
    correct_rate,
    check_results: dict,
    difficulty_level: str = "primary",
    score: int | None = None,
    severity: str | None = None,
    audio_path: str | None = None,
) -> str:
    rid = str(uuid.uuid4())
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    cur.execute("""
        INSERT INTO test_records (
            id,
            test_id, user_id, question_index,
            date,
            target_word, target_ipa, asr_ipa, asr_word,
            score, correct_rate, severity, difficulty,
            check_results, language, test_type, category,
            audio_path,
            created_at, updated_at
        ) VALUES (
            ?,
            ?, ?, ?,
            ?,
            ?, ?, ?, ?,
            ?, ?, ?, ?,
            ?, ?, ?, ?,
            ?,
            CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
        )
    """, (
        rid,
        test_id, user_id, int(question_index),
        now,
        target_word, target_ipa, asr_ipa, asr_word,
        score,
        str(correct_rate) if correct_rate is not None else None,
        severity,
        normalize_difficulty(difficulty_level),
        json.dumps(check_results, ensure_ascii=False),
        language,
        test_type,
        category,
        audio_path,
    ))
    return rid

@app.get("/api/training/confirmed")
def api_training_confirmed(
    test_id: str = Query(None),
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    try:
        pairs = slp_tasks.get_confirmed_slp_pairs(conn, user_id=current_user_id, test_id=test_id)
        return {"items": [{"super_type": a, "sub_type": b} for a, b in pairs], "count": len(pairs)}
    finally:
        conn.close()

from pydantic import BaseModel
from typing import List, Optional

class ChooseTwoReq(BaseModel):
    test_id: Optional[str] = None
    chosen: List[dict]
    language: Optional[str] = None  # âœ… add

@app.post("/api/training/allocate/init")
def api_training_allocate_init(
    test_id: str = Query(...),
    language: Optional[str] = Query(None),   # âœ… add this
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    try:
        # âœ… normalize language (only cn/en)
        L = (language or "").strip().lower()
        if L in ("zh", "zh-cn", "zh_tw", "zh-tw", "chinese", "cn"):
            L = "cn"
        elif L in ("en", "english"):
            L = "en"
        else:
            L = "cn"  # default / fallback

        pairs = slp_tasks.get_confirmed_slp_pairs(conn, user_id=current_user_id, test_id=test_id, language=L)  # âœ… (if you added language filter)

        out = slp_tasks.allocate_training_tasks_for_confirmed(
            conn,
            user_id=current_user_id,
            confirmed_pairs=pairs,
            language=L,              # âœ… use selected language
            task_kind="vocab",
            chosen_pairs=[],         # init: not chosen yet
            preferred_package=(30, 3),
            decreased_package=(20, 2),
        )
        return {"msg": "ok", **out}
    finally:
        conn.close()

class TrainingCommitReq(BaseModel):
    task_id: str
    increment: int = 1

@app.post("/api/training/commit")
def api_training_commit(
    data: TrainingCommitReq,
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    try:
        return slp_tasks.commit_training_task_progress(
            conn,
            user_id=current_user_id,
            task_id=data.task_id,
            increment=data.increment,
            daily_cap=6,   # ä¹‹å¾Œæ”¹æˆå¯é…ç½®
        )
    finally:
        conn.close()

class TrainingBatchTask(BaseModel):
    id: str
    user_id: str
    super_type: Optional[str] = None
    sub_type: Optional[str] = None
    task_kind: str
    language: str
    allocated_at: Optional[str] = None
    day_index: int
    total_times: int
    progress_times: int
    status: str
    is_active: int

class TrainingBatchResp(BaseModel):
    available: bool
    super_type: str
    sub_type: str
    language: str
    task_kind: str
    allocated_at: Optional[str] = None
    allowed_day_index: Optional[int] = None
    tasks: List[TrainingBatchTask] = []
    reason: Optional[str] = None


@app.get("/api/tasks/training/batch", response_model=TrainingBatchResp)
def api_tasks_training_batch(
    super_type: str = Query(...),
    sub_type: str = Query(...),
    language: str = Query("cn"),
    task_kind: str = Query("vocab"),  # vocab | sentence
    current_user_id: str = Depends(get_current_user_id),
):
    lang = normalize_practice_language(language)
    super_type = (super_type or "").strip()
    sub_type = (sub_type or "").strip()
    task_kind = (task_kind or "vocab").strip().lower()

    if task_kind not in ("vocab", "sentence"):
        raise HTTPException(status_code=400, detail="Invalid task_kind (vocab|sentence)")

    conn = get_db()
    cur = conn.cursor()
    try:
        # 1) æ‰¾æœ€æ–°ä¸€æ‰¹ allocated_at
        cur.execute("""
            SELECT allocated_at
            FROM tasks
            WHERE user_id=?
              AND super_type=?
              AND sub_type=?
              AND language=?
              AND task_kind=?
              AND is_active=1
              AND allocated_at IS NOT NULL
            ORDER BY datetime(allocated_at) DESC
            LIMIT 1
        """, (current_user_id, super_type, sub_type, lang, task_kind))
        r = cur.fetchone()
        if not r or not r[0]:
            return TrainingBatchResp(
                available=False,
                super_type=super_type,
                sub_type=sub_type,
                language=lang,
                task_kind=task_kind,
                allocated_at=None,
                allowed_day_index=None,
                tasks=[],
                reason="NO_BATCH"
            )

        allocated_at = r[0]
        allowed = _task_allowed_day_index(allocated_at)

        # 2) å–é€™æ‰¹ day1..day7 tasks
        cur.execute("""
            SELECT
              id, user_id, super_type, sub_type, task_kind, language,
              allocated_at, day_index, total_times, progress_times, status, is_active
            FROM tasks
            WHERE user_id=?
              AND super_type=?
              AND sub_type=?
              AND language=?
              AND task_kind=?
              AND is_active=1
              AND datetime(allocated_at)=datetime(?)
            ORDER BY day_index ASC
        """, (current_user_id, super_type, sub_type, lang, task_kind, allocated_at))
        rows = cur.fetchall()

        tasks = []
        for row in rows:
            (tid, uid, st, sb, kind, lg, alloc, day_idx,
             total, prog, status, is_active) = row

            tasks.append(TrainingBatchTask(
                id=tid,
                user_id=uid,
                super_type=st,
                sub_type=sb,
                task_kind=kind,
                language=lg,
                allocated_at=alloc,
                day_index=int(day_idx or 1),
                total_times=int(total or 0),
                progress_times=int(prog or 0),
                status=str(status or "pending"),
                is_active=int(is_active or 0),
            ))

        return TrainingBatchResp(
            available=True,
            super_type=super_type,
            sub_type=sub_type,
            language=lang,
            task_kind=task_kind,
            allocated_at=str(allocated_at),
            allowed_day_index=allowed,
            tasks=tasks,
            reason=None
        )
    finally:
        conn.close()

@app.post("/api/training/allocate/choose-two")
def api_training_allocate_choose_two(
    data: ChooseTwoReq,
    current_user_id: str = Depends(get_current_user_id),
):
    chosen_pairs = []
    for it in (data.chosen or []):
        st = str((it or {}).get("super_type") or "").strip()
        sb = str((it or {}).get("sub_type") or "").strip()
        if st and sb:
            chosen_pairs.append((st, sb))

    # å»é‡ä¸¦é™åˆ¶æœ€å¤š 2
    uniq = []
    seen = set()
    for p in chosen_pairs:
        if p not in seen:
            seen.add(p)
            uniq.append(p)
    chosen_pairs = uniq[:2]

    # âœ… normalize language (cn/en)
    L = (data.language or "").strip().lower()
    if L in ("zh", "zh-cn", "zh_tw", "zh-tw", "chinese", "cn"):
        L = "cn"
    elif L in ("en", "english"):
        L = "en"
    else:
        L = "cn"  # default

    conn = get_db()
    try:
        # âœ… å»ºè­°ï¼šconfirmed_pairs äº¦ç”¨åŒä¸€èªè¨€ï¼ˆé¿å…æ’ˆåˆ° CN/EN æ··åŸ‹ï¼‰
        confirmed_pairs = slp_tasks.get_confirmed_slp_pairs(
            conn, user_id=current_user_id, test_id=data.test_id, language=L
        )

        confirmed_set = set(confirmed_pairs)
        for p in chosen_pairs:
            if p not in confirmed_set:
                raise HTTPException(status_code=400, detail=f"Chosen pair not confirmed: {p[0]}/{p[1]}")

        out = slp_tasks.allocate_training_tasks_for_confirmed(
            conn,
            user_id=current_user_id,
            confirmed_pairs=confirmed_pairs,
            language=L,  # âœ… FIX: ç”¨ Lï¼Œå””å¥½å¯«æ­» "cn"
            task_kind="vocab",
            chosen_pairs=chosen_pairs,
            preferred_package=(30, 3),
            decreased_package=(20, 2),
        )
        return {"msg": "ok", "chosen": [{"super_type": a, "sub_type": b} for a, b in chosen_pairs], **out}
    finally:
        conn.close()

class TrainingTaskRow(BaseModel):
    id: str
    super_type: Optional[str] = None
    sub_type: Optional[str] = None
    task_kind: str
    language: str
    allocated_at: Optional[str] = None
    day_index: int
    total_times: int
    progress_times: int
    status: str
    is_active: int
    reward_claimed: int = 0
    reward_claimed_at: Optional[str] = None

class TrainingAllActiveResp(BaseModel):
    available: bool
    latest_allocated_at: Optional[str] = None
    latest_allowed_day_index: Optional[int] = None
    tasks: List[TrainingTaskRow] = []
    reason: Optional[str] = None

class ClaimRewardReq(BaseModel):
    task_id: str

class ClaimRewardResp(BaseModel):
    msg: str
    task_id: str
    added: int
    integral: int

@app.post("/api/tasks/training/claim-reward", response_model=ClaimRewardResp)
def api_tasks_training_claim_reward(
    data: ClaimRewardReq,
    current_user_id: str = Depends(get_current_user_id),
):
    ensure_task_table_v2()  # âœ… make sure reward columns exist

    task_id = (data.task_id or "").strip()
    if not task_id:
        raise HTTPException(status_code=400, detail="Missing task_id")

    conn = get_db()
    cur = conn.cursor()
    try:
        # 1) verify task exists + ownership
        cur.execute("""
            SELECT id, user_id, reward_claimed, status, total_times, progress_times
            FROM tasks
            WHERE id=?
            LIMIT 1
        """, (task_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="Task not found")

        tid, uid, claimed, status, total_times, progress_times = row
        if uid != current_user_id:
            raise HTTPException(status_code=403, detail="Not allowed")

        if int(claimed or 0) == 1:
            raise HTTPException(status_code=400, detail="Reward already claimed")

        # âœ… å¿…é ˆå®Œæˆä»»å‹™æ‰å¯é ˜å–
        st = str(status or "").lower()
        total = int(total_times or 0)
        prog = int(progress_times or 0)

        # ä½ çš„ task æœ‰æ™‚ total_times å¯èƒ½æ˜¯ 0ï¼ˆä¸æ­£å¸¸ï¼‰ï¼Œé€™è£¡ä¹Ÿæ“‹æ‰
        if total <= 0:
            raise HTTPException(status_code=400, detail="Task has invalid total_times")

        # å¿…é ˆ completed + é€²åº¦æ»¿
        if st != "completed" or prog < total:
            raise HTTPException(status_code=400, detail="Task not completed yet")
        # 2) atomic claim (prevents double click / race condition)
        cur.execute("""
            UPDATE tasks
            SET reward_claimed=1,
                reward_claimed_at=CURRENT_TIMESTAMP
            WHERE id=?
            AND user_id=?
            AND reward_claimed=0
            AND LOWER(status)='completed'
            AND COALESCE(progress_times,0) >= COALESCE(total_times,0)
            AND COALESCE(total_times,0) > 0
        """, (tid, current_user_id))
        if cur.rowcount != 1:
            raise HTTPException(status_code=400, detail="Reward not claimable (already claimed or not completed)")

        # 3) add points
        added = 50
        cur.execute("""
            UPDATE patients
            SET integral = COALESCE(integral,0) + ?
            WHERE id=?
        """, (added, current_user_id))

        # 4) return latest integral
        cur.execute("SELECT COALESCE(integral,0) FROM patients WHERE id=?", (current_user_id,))
        integral = int(cur.fetchone()[0] or 0)

        conn.commit()
        return {"msg": "ok", "task_id": tid, "added": added, "integral": integral}

    finally:
        conn.close()

@app.get("/api/tasks/training/all-active", response_model=TrainingAllActiveResp)
def api_tasks_training_all_active(
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    cur = conn.cursor()
    try:
        # 1) æ‰¾æœ€æ–° allocated_atï¼ˆç”¨ä¾†ç®—ä»Šå¤© dayï¼‰
        cur.execute("""
            SELECT allocated_at
            FROM tasks
            WHERE user_id=?
              AND is_active=1
              AND allocated_at IS NOT NULL
              AND super_type IS NOT NULL
              AND sub_type IS NOT NULL
            ORDER BY datetime(allocated_at) DESC
            LIMIT 1
        """, (current_user_id,))
        r = cur.fetchone()
        latest_alloc = r[0] if r else None
        latest_allowed = _task_allowed_day_index(latest_alloc) if latest_alloc else None

        # âœ… FIX: Day8+ (expired) => treat as NO active training for today; ask for new SLP test
        # _task_allowed_day_index returns None when days_since <0 or >6
        if latest_alloc and latest_allowed is None:
            return TrainingAllActiveResp(
                available=False,
                latest_allocated_at=latest_alloc,
                latest_allowed_day_index=None,
                tasks=[],
                reason="NEED_NEW_SLP_TEST"
            )

        # 2) å–å…¨éƒ¨ active training tasks
        cur.execute("""
            SELECT
              id, super_type, sub_type, task_kind, language,
              allocated_at, day_index, total_times, progress_times, status, is_active,
              reward_claimed, reward_claimed_at
            FROM tasks
            WHERE user_id=?
              AND is_active=1
              AND super_type IS NOT NULL
              AND sub_type IS NOT NULL
            ORDER BY
              datetime(allocated_at) DESC,
              super_type ASC,
              sub_type ASC,
              language ASC,
              task_kind ASC,
              day_index ASC
        """, (current_user_id,))
        rows = cur.fetchall()

        tasks = []
        for row in rows:
            (tid, st, sb, kind, lang, alloc, day_idx, total, prog, status, is_active, reward_claimed, reward_claimed_at) = row
            tasks.append(TrainingTaskRow(
                id=tid,
                super_type=st,
                sub_type=sb,
                task_kind=str(kind or "vocab"),
                language=str(lang or "cn"),
                allocated_at=alloc,
                day_index=int(day_idx or 1),
                total_times=int(total or 0),
                progress_times=int(prog or 0),
                status=str(status or "pending"),
                is_active=int(is_active or 0),
                reward_claimed=int(reward_claimed or 0),
                reward_claimed_at=reward_claimed_at,
            ))

        # 3) âœ… æ²’æœ‰ä»»ä½• active training tasks
        if not tasks:
            # âœ… æ˜¯å¦æ›¾ç¶“æœ‰ CN trainingï¼ˆä»£è¡¨ã€Œåšå®Œä¸€è¼ªã€æˆ–ã€Œæ›¾ç¶“ allocate éã€ï¼‰
            cur.execute("""
                SELECT 1
                FROM tasks
                WHERE user_id=?
                  AND language='cn'
                  AND task_kind='vocab'
                  AND allocated_at IS NOT NULL
                  AND super_type IS NOT NULL
                  AND sub_type IS NOT NULL
                LIMIT 1
            """, (current_user_id,))
            had_any_cn_training = cur.fetchone() is not None

            return TrainingAllActiveResp(
                available=False,
                latest_allocated_at=latest_alloc,
                latest_allowed_day_index=latest_allowed,
                tasks=[],
                reason="NEED_NEW_SLP_TEST" if had_any_cn_training else "NO_ACTIVE_TRAINING_TASKS"
            )

        # 4) æ­£å¸¸å›å‚³ï¼ˆDay1-7ï¼‰
        return TrainingAllActiveResp(
            available=True,
            latest_allocated_at=latest_alloc,
            latest_allowed_day_index=latest_allowed,
            tasks=tasks,
            reason=None
        )
    finally:
        conn.close()

def deactivate_batch_if_fully_completed(cur, *, user_id: str, super_type: str, sub_type: str, language: str, task_kind: str, allocated_at: str):
    """
    å¦‚æœåŒä¸€æ‰¹ allocated_at çš„ day1..day7 å…¨éƒ¨ completedï¼Œå°‡è©²æ‰¹ tasks.is_active=0
    """
    cur.execute("""
        SELECT COUNT(*) AS total_cnt,
               SUM(CASE WHEN LOWER(status)='completed' THEN 1 ELSE 0 END) AS done_cnt
        FROM tasks
        WHERE user_id=?
          AND super_type=?
          AND sub_type=?
          AND language=?
          AND task_kind=?
          AND is_active=1
          AND allocated_at IS NOT NULL
          AND datetime(allocated_at)=datetime(?)
          AND day_index BETWEEN 1 AND 7
    """, (user_id, super_type, sub_type, language, task_kind, allocated_at))
    row = cur.fetchone()
    total_cnt = int(row[0] or 0)
    done_cnt = int(row[1] or 0)

    # å¿…é ˆæœ‰ 7 ç­†ï¼Œè€Œä¸”å…¨ completed
    if total_cnt >= 7 and done_cnt >= 7:
        cur.execute("""
            UPDATE tasks
            SET is_active=0
            WHERE user_id=?
              AND super_type=?
              AND sub_type=?
              AND language=?
              AND task_kind=?
              AND is_active=1
              AND datetime(allocated_at)=datetime(?)
              AND day_index BETWEEN 1 AND 7
        """, (user_id, super_type, sub_type, language, task_kind, allocated_at))

from pydantic import BaseModel

class TestReportItem(BaseModel):
    id: str
    test_name: Optional[str] = None
    status: str
    language: Optional[str] = None
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    progress_cursor: int = 0

class TestReportsResp(BaseModel):
    items: List[TestReportItem]

@app.get("/api/test/reports", response_model=TestReportsResp)
def api_test_reports(
    limit: int = Query(80),
    language: Optional[str] = Query(None, description="cn|en (optional)"),
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    cur = conn.cursor()
    try:
        where_lang = ""
        params = [current_user_id]

        # normalize to your practice language convention
        lang = None
        if language is not None and str(language).strip() != "":
            lang = normalize_practice_language(language)  # returns "cn" or "en"
            where_lang = " AND language=?"
            params.append(lang)

        params.append(int(limit))

        cur.execute(f"""
            SELECT
                id,
                test_name,
                status,
                language,
                date,
                updated_at,
                progress_cursor
            FROM tests
            WHERE patient_id=?
            {where_lang}
            ORDER BY datetime(updated_at) DESC, datetime(date) DESC
            LIMIT ?
        """, tuple(params))

        rows = cur.fetchall()
        items = []
        for r in rows:
            items.append({
                "id": r[0],
                "test_name": r[1],
                "status": r[2] or "unknown",
                "language": r[3],
                "created_at": r[4],
                "updated_at": r[5],
                "progress_cursor": int(r[6] or 0),
            })

        return {"items": items}
    finally:
        conn.close()

@app.get("/api/training/confirmed-pairs")
def api_training_confirmed_pairs_alias(
    test_id: Optional[str] = Query(None),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Alias for frontend compatibility.
    Returns confirmed (super_type, sub_type) pairs for a given test_id (optional).
    """
    conn = get_db()
    try:
        pairs = slp_tasks.get_confirmed_slp_pairs(conn, user_id=current_user_id, test_id=test_id)
        return {"items": [{"super_type": a, "sub_type": b} for a, b in pairs]}
    finally:
        conn.close()
        
@app.get("/api/patient/tests/stats")
def api_patient_tests_stats(
    days: int = Query(365, ge=1, le=3650, description="default 365"),
    date_from: Optional[str] = Query(None, alias="from", description="YYYY-MM-DD (optional)"),
    date_to: Optional[str] = Query(None, alias="to", description="YYYY-MM-DD (optional)"),
    language: Optional[str] = Query(None, description="cn|en (optional)"),
    a: Optional[str] = Query(None, description="test_id A for compare (older)"),
    b: Optional[str] = Query(None, description="test_id B for compare (newer)"),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Return aggregated finished test stats for the current patient.
    - includes list of tests with aggregated metrics from test_records + slp_patient
    - includes default compare: latest_finished vs prev_finished (if >=2)
    - optional compare for any a/b test_id
    """
    # range
    d1_def, d2_def = _ymd_default_range(days)
    d1 = _parse_ymd_or_default(date_from, d1_def)
    d2 = _parse_ymd_or_default(date_to, d2_def)

    # lang
    where_lang = ""
    params: list[Any] = [current_user_id, d1, d2]
    if language is not None and str(language).strip() != "":
        lang = normalize_practice_language(language)  # your helper returns cn|en
        where_lang = " AND language=?"
        params.append(lang)

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()

    try:
        # 1) fetch finished tests in range
        cur.execute(f"""
            SELECT
              id, test_name, status, language, threshold, words_per_subtype,
              progress_cursor, total_questions, current_question_index,
              has_slp, date, updated_at, finished_at, result
            FROM tests
            WHERE patient_id=?
              AND status='finished'
              AND date(COALESCE(finished_at, updated_at, date)) BETWEEN date(?) AND date(?)
              {where_lang}
            ORDER BY datetime(COALESCE(finished_at, updated_at, date)) DESC
        """, tuple(params))
        tests = cur.fetchall()

        items: List[dict] = []

        for t in tests:
            test_id = t["id"]

            # 2) aggregate test_records
            cur.execute("""
                SELECT score, correct_rate, severity, check_results
                FROM test_records
                WHERE test_id=?
            """, (test_id,))
            rec_rows = cur.fetchall()
            recordsAgg = _test_agg_from_rows(rec_rows)

            # 3) aggregate slp_patient
            cur.execute("""
                SELECT super_type, sub_type
                FROM slp_patient
                WHERE test_id=?
            """, (test_id,))
            slp_rows = cur.fetchall()
            slpAgg = _slp_agg_from_rows(slp_rows)

            items.append({
                "test": {
                    "id": test_id,
                    "test_name": t["test_name"],
                    "status": t["status"],
                    "language": t["language"],
                    "threshold": int(t["threshold"] or 0),
                    "words_per_subtype": int(t["words_per_subtype"] or 0),
                    "progress_cursor": int(t["progress_cursor"] or 0),
                    "total_questions": int(t["total_questions"] or 0),
                    "current_question_index": int(t["current_question_index"] or 0),
                    "has_slp": int(t["has_slp"] or 0),
                    "created_at": t["date"],
                    "updated_at": t["updated_at"],
                    "finished_at": t["finished_at"],
                    "result": _safe_json_loads(t["result"]),
                },
                "recordsAgg": recordsAgg,
                "slpAgg": slpAgg,
            })

        # 4) default latest vs prev
        latest = items[0] if len(items) >= 1 else None
        prev = items[1] if len(items) >= 2 else None

        default_compare = None
        if latest and prev:
            default_compare = {
                "a": prev["test"]["id"],
                "b": latest["test"]["id"],
                "delta": _compare_metrics(prev, latest),
            }

        # 5) optional a/b compare
        custom_compare = None
        if a and b:
            # find in items first
            map_by_id = {it["test"]["id"]: it for it in items}
            if a not in map_by_id or b not in map_by_id:
                # fallback: verify ownership then load on demand
                for tid in (a, b):
                    cur.execute("SELECT patient_id FROM tests WHERE id=?", (tid,))
                    rr = cur.fetchone()
                    if not rr:
                        raise HTTPException(status_code=404, detail=f"test not found: {tid}")
                    if rr["patient_id"] != current_user_id:
                        raise HTTPException(status_code=403, detail="not allowed")

                def load_one(tid: str) -> dict:
                    cur.execute("""
                        SELECT id, test_name, status, language, threshold, words_per_subtype,
                               progress_cursor, total_questions, current_question_index,
                               has_slp, date, updated_at, finished_at, result
                        FROM tests WHERE id=? LIMIT 1
                    """, (tid,))
                    tt = cur.fetchone()
                    if not tt:
                        raise HTTPException(status_code=404, detail=f"test not found: {tid}")
                    cur.execute("SELECT score, correct_rate, severity, check_results FROM test_records WHERE test_id=?", (tid,))
                    rec_rows = cur.fetchall()
                    cur.execute("SELECT super_type, sub_type FROM slp_patient WHERE test_id=?", (tid,))
                    slp_rows = cur.fetchall()
                    return {
                        "test": {
                            "id": tt["id"],
                            "test_name": tt["test_name"],
                            "status": tt["status"],
                            "language": tt["language"],
                            "threshold": int(tt["threshold"] or 0),
                            "words_per_subtype": int(tt["words_per_subtype"] or 0),
                            "progress_cursor": int(tt["progress_cursor"] or 0),
                            "total_questions": int(tt["total_questions"] or 0),
                            "current_question_index": int(tt["current_question_index"] or 0),
                            "has_slp": int(tt["has_slp"] or 0),
                            "created_at": tt["date"],
                            "updated_at": tt["updated_at"],
                            "finished_at": tt["finished_at"],
                            "result": _safe_json_loads(tt["result"]),
                        },
                        "recordsAgg": _test_agg_from_rows(rec_rows),
                        "slpAgg": _slp_agg_from_rows(slp_rows),
                    }

                A = load_one(a)
                B = load_one(b)
            else:
                A = map_by_id[a]
                B = map_by_id[b]

            custom_compare = {
                "a": A["test"]["id"],
                "b": B["test"]["id"],
                "delta": _compare_metrics(A, B),
            }

        return {
            "range": {"from": d1, "to": d2},
            "items": items,
            "latest_finished": latest,
            "prev_finished": prev,
            "default_compare": default_compare,
            "custom_compare": custom_compare,
        }

    finally:
        conn.close()

@app.get("/api/patient/tests")
def api_patient_tests(
    limit: int = Query(80, ge=1, le=500),
    language: str | None = Query(None, description="cn|en (optional)"),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    List tests (super test table) for current patient.
    Exclude cancelled.
    """
    conn = get_db()
    cur = conn.cursor()
    try:
        where_lang = ""
        params: list = [current_user_id]

        if language is not None and str(language).strip() != "":
            lang = normalize_practice_language(language)  # returns "cn" or "en"
            where_lang = " AND language=?"
            params.append(lang)

        params.append(int(limit))

        cur.execute(f"""
            SELECT
                id,
                test_name,
                status,
                language,
                threshold,
                words_per_subtype,
                progress_cursor,
                total_questions,
                current_question_index,
                has_slp,
                date,
                updated_at,
                finished_at
            FROM tests
            WHERE patient_id=?
              AND status <> 'cancelled'
              {where_lang}
            ORDER BY datetime(updated_at) DESC, datetime(date) DESC
            LIMIT ?
        """, tuple(params))

        rows = cur.fetchall()

        items = []
        for r in rows:
            items.append({
                "id": r[0],
                "test_name": r[1],
                "status": r[2],
                "language": r[3],
                "threshold": int(r[4] or 0),
                "words_per_subtype": int(r[5] or 0),
                "progress_cursor": int(r[6] or 0),
                "total_questions": int(r[7] or 0),
                "current_question_index": int(r[8] or 0),
                "has_slp": int(r[9] or 0),
                "created_at": r[10],
                "updated_at": r[11],
                "finished_at": r[12],
            })

        return {"items": items}
    finally:
        conn.close()

@app.get("/api/patient/tests/{test_id}")
def api_patient_test_detail(
    test_id: str,
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT
                id, patient_id, test_name, status,
                progress_cursor, total_questions, current_question_index,
                plan, config_json,
                threshold, words_per_subtype, language,
                has_slp, result,
                date, updated_at, finished_at
            FROM tests
            WHERE id=?
              AND status <> 'cancelled'
            LIMIT 1
        """, (test_id,))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="test not found")

        if row[1] != current_user_id:
            raise HTTPException(status_code=403, detail="not allowed")

        def try_json(s):
            if not s:
                return None
            try:
                return json.loads(s)
            except Exception:
                return {"raw": s}

        return {
            "test": {
                "id": row[0],
                "test_name": row[2],
                "status": row[3],
                "progress_cursor": int(row[4] or 0),
                "total_questions": int(row[5] or 0),
                "current_question_index": int(row[6] or 0),
                "plan": try_json(row[7]),
                "config": try_json(row[8]),
                "threshold": int(row[9] or 0),
                "words_per_subtype": int(row[10] or 0),
                "language": row[11],
                "has_slp": int(row[12] or 0),
                "result": try_json(row[13]),
                "created_at": row[14],
                "updated_at": row[15],
                "finished_at": row[16],
            }
        }
    finally:
        conn.close()

@app.get("/api/patient/tests/{test_id}/records")
def api_patient_test_records(
    test_id: str,
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        # verify ownership + not cancelled
        cur.execute("SELECT patient_id, status FROM tests WHERE id=? LIMIT 1", (test_id,))
        t = cur.fetchone()
        if not t:
            raise HTTPException(status_code=404, detail="test not found")
        if str(t["status"] or "").lower() == "cancelled":
            raise HTTPException(status_code=404, detail="test cancelled")
        if t["patient_id"] != current_user_id:
            raise HTTPException(status_code=403, detail="not allowed")

        cur.execute("""
            SELECT *
            FROM test_records
            WHERE test_id=?
            ORDER BY question_index ASC, datetime(created_at) ASC
        """, (test_id,))
        rows = cur.fetchall()

        return {"items": [dict(r) for r in rows]}
    finally:
        conn.close()

from fastapi import Query, Depends, HTTPException

@app.get("/api/patient/tests/{test_id}/slp")
def api_patient_test_slp(
    test_id: str,
    language: str | None = Query(None, description="cn|en (optional)"),
    current_user_id: str = Depends(get_current_user_id),
):
    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        # verify ownership + not cancelled
        cur.execute("SELECT patient_id, status FROM tests WHERE id=? LIMIT 1", (test_id,))
        t = cur.fetchone()
        if not t:
            raise HTTPException(status_code=404, detail="test not found")
        if str(t["status"] or "").lower() == "cancelled":
            raise HTTPException(status_code=404, detail="test cancelled")
        if t["patient_id"] != current_user_id:
            raise HTTPException(status_code=403, detail="not allowed")

        where_lang = ""
        params = [test_id]

        if language is not None and str(language).strip() != "":
            lang = normalize_practice_language(language)  # "cn" or "en"
            where_lang = " AND language=?"
            params.append(lang)

        cur.execute(f"""
            SELECT
                id, user_id, test_id, datetime,
                super_type, sub_type, language, created_at
            FROM slp_patient
            WHERE test_id=?
            {where_lang}
            ORDER BY datetime(created_at) DESC, datetime(datetime) DESC
        """, tuple(params))

        rows = cur.fetchall()
        return {"items": [dict(r) for r in rows]}
    finally:
        conn.close()

from typing import Optional, Any, Dict, List, Tuple
from fastapi import Query, Depends, HTTPException
from datetime import datetime, timedelta
import json
import sqlite3

# ---------- helpers (stats) ----------

def _ymd_default_range(days: int = 365) -> tuple[str, str]:
    today = datetime.now().date()
    d2 = today.strftime("%Y-%m-%d")
    d1 = (today - timedelta(days=max(0, int(days) - 1))).strftime("%Y-%m-%d")
    return d1, d2

def _parse_ymd_or_default(s: Optional[str], fallback: str) -> str:
    if s is None or str(s).strip() == "":
        return fallback
    try:
        return datetime.strptime(str(s).strip(), "%Y-%m-%d").strftime("%Y-%m-%d")
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid date format, use YYYY-MM-DD")

def _safe_json_loads(s: Any) -> dict:
    if not s:
        return {}
    if isinstance(s, dict):
        return s
    if not isinstance(s, str):
        return {}
    try:
        obj = json.loads(s)
        return obj if isinstance(obj, dict) else {}
    except Exception:
        return {}

def _detect_off_target_from_check_results(check_results_json: Any) -> bool:
    obj = _safe_json_loads(check_results_json)
    off = obj.get("meta", {}).get("off_target", {})
    if isinstance(off, dict) and off.get("is_off_target"):
        return True
    return False

def _normalize_sev_label(sev: Any) -> str:
    s = str(sev or "").strip().lower()
    if s in ("high", "severe", "hard"):
        return "high"
    if s in ("middle", "medium", "moderate"):
        return "middle"
    if s in ("slight", "low", "minor"):
        return "slight"
    if s in ("off_target", "offtarget", "off-target"):
        return "off_target"
    if not s:
        return "unknown"
    return "unknown"

def _safe_int(x) -> Optional[int]:
    try:
        if x is None:
            return None
        return int(float(str(x)))
    except Exception:
        return None

def _avg(nums: List[float]) -> Optional[float]:
    if not nums:
        return None
    return sum(nums) / len(nums)

def _test_agg_from_rows(rows: List[sqlite3.Row]) -> dict:
    """
    rows: test_records rows for one test_id
    returns:
      {
        count,
        avg_correct_rate,
        avg_score,
        off_target_count,
        sev: {high,middle,slight,off_target,unknown},
      }
    """
    count = 0
    cr_list: List[float] = []
    score_list: List[float] = []
    off_target_count = 0
    sev = {"high": 0, "middle": 0, "slight": 0, "off_target": 0, "unknown": 0}

    for r in rows:
        count += 1

        # correct_rate stored as TEXT in db
        cr = _safe_int(r.get("correct_rate") if isinstance(r, dict) else r["correct_rate"])
        if cr is not None:
            cr_list.append(float(max(0, min(100, cr))))

        sc = _safe_int(r.get("score") if isinstance(r, dict) else r["score"])
        if sc is not None:
            score_list.append(float(sc))

        # off-target: prefer meta.off_target
        crj = r.get("check_results") if isinstance(r, dict) else r["check_results"]
        if _detect_off_target_from_check_results(crj):
            off_target_count += 1

        s = r.get("severity") if isinstance(r, dict) else r["severity"]
        lab = _normalize_sev_label(s)
        if lab not in sev:
            lab = "unknown"
        sev[lab] += 1

    avg_cr = _avg(cr_list)
    avg_sc = _avg(score_list)

    return {
        "count": count,
        "avg_correct_rate": None if avg_cr is None else round(avg_cr, 1),
        "avg_score": None if avg_sc is None else round(avg_sc, 2),
        "off_target_count": off_target_count,
        "off_target_rate": 0.0 if count == 0 else round(off_target_count * 100.0 / count, 1),
        "sev": sev,
    }

def _slp_agg_from_rows(rows: List[sqlite3.Row]) -> dict:
    """
    rows: slp_patient rows for one test_id
    returns:
      { confirmed_count, pairs: [{super_type, sub_type, count}] }
    """
    from collections import Counter
    c = Counter()
    for r in rows:
        st = (r.get("super_type") if isinstance(r, dict) else r["super_type"]) or ""
        sb = (r.get("sub_type") if isinstance(r, dict) else r["sub_type"]) or ""
        st = str(st).strip()
        sb = str(sb).strip()
        if st and sb:
            c[(st, sb)] += 1

    pairs = [
        {"super_type": k[0], "sub_type": k[1], "count": int(v)}
        for k, v in c.most_common()
    ]
    return {"confirmed_count": sum(c.values()), "pairs": pairs}

def _compare_metrics(a: dict, b: dict) -> dict:
    """
    a,b are items returned by stats list, containing recordsAgg & slpAgg.
    return delta summary for UI.
    """
    aR = a.get("recordsAgg") or {}
    bR = b.get("recordsAgg") or {}
    aS = a.get("slpAgg") or {}
    bS = b.get("slpAgg") or {}

    def fnum(x):
        try:
            return float(x)
        except Exception:
            return None

    def d(key, invert=False):
        av = fnum(aR.get(key))
        bv = fnum(bR.get(key))
        if av is None or bv is None:
            return None
        diff = bv - av
        return -diff if invert else diff

    delta = {
        "avg_correct_rate": d("avg_correct_rate", invert=False),   # higher better
        "avg_score": d("avg_score", invert=False),                 # higher better
        "off_target_rate": d("off_target_rate", invert=True),      # lower better => invert
        "confirmed_count": None,
        "sev_high": None,
        "sev_middle": None,
        "sev_slight": None,
    }

    # confirmed_count (lower better => invert)
    try:
        av = float(aS.get("confirmed_count") or 0)
        bv = float(bS.get("confirmed_count") or 0)
        delta["confirmed_count"] = -(bv - av)
    except Exception:
        delta["confirmed_count"] = None

    # severity counts (lower better => invert)
    try:
        aSev = aR.get("sev") or {}
        bSev = bR.get("sev") or {}
        for k in ("high", "middle", "slight"):
            av = float(aSev.get(k) or 0)
            bv = float(bSev.get(k) or 0)
            delta[f"sev_{k}"] = -(bv - av)
    except Exception:
        pass

    return delta

def _normalize_super_type_en(st: str) -> str:
    s = (st or "").strip()
    if s.lower() == "addition":
        return "Addition"
    if s.lower() == "omission":
        return "Omission"
    if s.lower() == "substitution":
        return "Substitution"
    return s

def _detector_key_for_super_en(super_type: str) -> str:
    # must match analyze_record_payload check_results keys
    mapping = {
        "Addition": "addition",
        "Omission": "omission",
        "Substitution": "substitution",
    }
    return mapping.get(super_type, "")

def _final_label_from_payload(super_type: str, payload: dict) -> str:
    """
    payload: output of analyze_record_payload
    expect payload.check_results.<detector_key>.final_label
    """
    det_key = _detector_key_for_super_en(super_type)
    if not det_key:
        return ""
    cr = (payload.get("check_results") or {})
    det = cr.get(det_key) if isinstance(cr, dict) else None
    if not isinstance(det, dict):
        return ""
    return str(det.get("final_label") or "").strip().lower()

def _pick_n_from_items(items: list[dict], n: int) -> list[dict]:
    """
    items: [{"w":"...", "ipa":"..."} ...]
    return random sample size n (or all if <n)
    """
    clean = []
    for it in items or []:
        if not isinstance(it, dict):
            continue
        w = (it.get("w") or "").strip()
        if not w:
            continue
        clean.append({"w": w, "ipa": (it.get("ipa") or "").strip()})
    if not clean:
        return []
    if len(clean) <= n:
        tmp = list(clean)
        random.shuffle(tmp)
        return tmp
    return random.sample(clean, n)

def build_test_flat_queue_en(plan: list[dict]) -> list[dict]:
    """
    plan: [{super_type, sub_type, words:[{w, ipa}]}]
    flatQueue: [{index, super_type, sub_type, word, ipa}]
    """
    flat = []
    idx = 0
    for blk in plan or []:
        st = str(blk.get("super_type") or "").strip()
        sb = str(blk.get("sub_type") or "").strip()
        words = blk.get("words") or []
        for it in words:
            if isinstance(it, dict):
                w = (it.get("w") or "").strip()
                ipa0 = (it.get("ipa") or "").strip()
            else:
                w = str(it).strip()
                ipa0 = ""
            if not w:
                continue
            flat.append({"index": idx, "super_type": st, "sub_type": sb, "word": w, "ipa": ipa0})
            idx += 1
    return flat

class TestStartENResp(BaseModel):
    test_id: str
    language: str
    words_per_subtype: int
    threshold: int
    plan: List[Dict[str, Any]]
    total_questions: int

@app.post("/api/test_en/start", response_model=TestStartENResp)
def api_test_en_start_real(
    words_per_subtype: int = Query(TEST_EN_WORDS_PER_SUBTYPE_DEFAULT, ge=1, le=20),
    threshold: int = Query(TEST_EN_SLP_THRESHOLD_DEFAULT, ge=1, le=10),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Create an EN test session:
    - read EN banks from LLM/*.json (NEW format)
    - for each super_type and each sub_type, pick N words (with IPA if provided)
    - save to tests.plan (NOT NULL) and return plan
    """
    n = int(words_per_subtype)
    th = int(threshold)

    # difficulty bucket for EN bank (primary|secondary|advanced)
    diff = infer_en_difficulty_from_user_id(current_user_id)

    plan: list[dict] = []
    total = 0

    enabled_subtypes: dict[str, list[str]] = {}

    for super_type in TEST_EN_SUPER_ORDER:
        super_type = _normalize_super_type_en(super_type)
        # read subtypes from bank file keys
        # use your existing helper: api_practice_en_subtypes logic
        path = EN_BANK_FILES.get(super_type)
        if not path:
            continue

        obj = safe_load_json(path)
        banks = obj.get("banks") if isinstance(obj, dict) else None
        if not isinstance(banks, dict):
            continue

        subtypes = sorted(list(banks.keys()))
        enabled_subtypes[super_type] = subtypes

        for sub_type in subtypes:
            # items per (super, sub, difficulty)
            items = load_en_bank_items(super_type, sub_type, diff)  # returns [{"w","ipa"}...]
            picked = _pick_n_from_items(items, n)
            if not picked:
                continue

            plan.append({
                "super_type": super_type,
                "sub_type": sub_type,
                "words": picked  # keep dicts so we can show ipa on UI if needed
            })
            total += len(picked)

    if total <= 0:
        raise HTTPException(status_code=500, detail="EN test banks empty / failed to build plan")

    flat_queue = build_test_flat_queue_en(plan)
    plan_obj = {
        "language": TEST_EN_LANG,
        "difficulty": diff,
        "words_per_subtype": n,
        "threshold": th,
        "plan": plan,
        "flatQueue": flat_queue,
        "total_questions": total,
    }

    config_obj = {
        "enabled_super_order": TEST_EN_SUPER_ORDER,
        "enabled_subtypes": enabled_subtypes,
        "bank_files": EN_BANK_FILES,
        "difficulty": diff,
    }

    # create tests row
    test_id = create_test_session_row_v2(
        user_id=current_user_id,
        test_name=f"SLP Screening (EN)",
        language=TEST_EN_LANG,
        words_per_subtype=n,
        threshold=th,
        plan_obj=plan_obj,
        total_questions=total,
        config_obj=config_obj,
    )

    return TestStartENResp(
        test_id=test_id,
        language=TEST_EN_LANG,
        words_per_subtype=n,
        threshold=th,
        plan=plan,
        total_questions=total,
    )

class TestAnalyzeENResp(BaseModel):
    test_record_id: str
    test_id: str
    super_type: str
    sub_type: str
    target_word: str
    target_ipa: str
    asr_word: str
    asr_ipa: str
    correct_rate: int
    status: str
    severity: Optional[str] = None
    check_results: dict

@app.post("/api/test_en/analyze", response_model=TestAnalyzeENResp)
async def api_test_en_analyze_real(
    file: UploadFile = File(...),
    test_id: str = Form(...),
    super_type: str = Form(...),
    sub_type: str = Form(...),
    target_word: str = Form(...),
    question_index: int = Form(...),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Analyze one EN test question:
    - verify test ownership + running
    - run English ASR + analyze_record_payload
    - save to test_records (structure same as CN test_records)
    - update tests.progress_cursor
    """
    if not test_id:
        raise HTTPException(status_code=400, detail="Missing test_id")

    super_type = _normalize_super_type_en(super_type)
    sub_type = (sub_type or "").strip()
    target_word = (target_word or "").strip()
    qidx = int(question_index)

    if super_type not in TEST_EN_SUPER_ORDER:
        raise HTTPException(status_code=400, detail="Invalid super_type (EN only supports Addition/Omission/Substitution)")
    if not sub_type:
        raise HTTPException(status_code=400, detail="Missing sub_type")
    if not target_word:
        raise HTTPException(status_code=400, detail="Missing target_word")

    # verify test row
    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT patient_id, status, language, threshold, words_per_subtype, plan FROM tests WHERE id=?", (test_id,))
    row = cur.fetchone()
    conn.close()

    if not row:
        raise HTTPException(status_code=404, detail="test_id not found")
    if row[0] != current_user_id:
        raise HTTPException(status_code=403, detail="Not allowed")
    if str(row[1] or "").lower() != "running":
        raise HTTPException(status_code=400, detail="Test is not running")
    if str(row[2] or "") != TEST_EN_LANG:
        raise HTTPException(status_code=400, detail="This test is not an EN test")

    # ensure (super_type, sub_type) exists in this test plan (avoid client spoof)
    plan_obj = {}
    try:
        plan_obj = json.loads(row[5]) if row[5] else {}
    except Exception:
        plan_obj = {}
    flatq = plan_obj.get("flatQueue") if isinstance(plan_obj, dict) else None
    if isinstance(flatq, list) and 0 <= qidx < len(flatq):
        expected = flatq[qidx] if isinstance(flatq[qidx], dict) else None
        if expected:
            exp_st = _normalize_super_type_en(expected.get("super_type"))
            exp_sb = str(expected.get("sub_type") or "").strip()
            exp_w = str(expected.get("word") or "").strip()
            if exp_st != super_type or exp_sb != sub_type or exp_w != target_word:
                raise HTTPException(status_code=400, detail="Submitted question does not match server plan")
    else:
        # if flatQueue missing, we skip strict match (but your start saves it, so normally won't happen)
        pass

    content = await file.read()

    # English ASR
    asr = transcribe_bytes_en_full(content, target_word=target_word)
    target_ipa = (asr.get("target_ipa") or "").strip()
    asr_ipa = (asr.get("asr_ipa") or "").strip()
    asr_word = (asr.get("asr_word") or "").strip() or "N/A"

    # keep consistency if needed
    asr_word, asr_ipa = enforce_word_ipa_consistency(target_word, target_ipa, asr_word, asr_ipa)

    # difficulty bucket (primary|secondary|advanced)
    diff = infer_en_difficulty_from_user_id(current_user_id)

    # analyze via your EN LLM pipeline
    req_id = str(uuid.uuid4())
    req_date = datetime.now().strftime("%Y-%m-%d")

    # IMPORTANT: analyze_record_payload expects test_type lower-case in your EN endpoints:
    # - addition/omission/substitution
    test_type_lower = super_type.lower()

    payload = analyze_record_payload(
        id=req_id,
        user_id=current_user_id,
        date=req_date,
        target_word=target_word,
        target_ipa=target_ipa,
        asr_word=asr_word,
        asr_ipa=asr_ipa,
        difficulty=diff,
        language="en",
        test_type=test_type_lower,
        category=sub_type,
        num_cases=None,
        max_new_tokens=None,
        temperature=0.2,
        top_p=1.0,
        repetition_penalty=1.05,
    )

    # Build test check_results: add meta for test
    check_results = payload.get("check_results") if isinstance(payload.get("check_results"), dict) else {}
    if not isinstance(check_results, dict):
        check_results = {}

    meta = check_results.get("meta") if isinstance(check_results.get("meta"), dict) else {}
    meta.update({
        "event": "test_analyze_en",
        "test_id": test_id,
        "language": TEST_EN_LANG,
        "question_index": qidx,
        "super_type": super_type,
        "sub_type": sub_type,
    })
    check_results["meta"] = meta

    # align fields
    correct_rate = int(payload.get("correct_rate") or 0)
    status = str(payload.get("status") or "")
    severity = payload.get("severity", None)
    score_points = payload.get("score", None)

    # âœ… Save into test_records + update tests cursor in ONE transaction
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute(
            "SELECT id FROM test_records WHERE test_id=? AND question_index=? LIMIT 1",
            (test_id, int(qidx)),
        )
        exists = cur.fetchone()
        if exists:
            raise HTTPException(status_code=409, detail="This question was already submitted. Please click Next.")
        
        test_record_id = save_test_record_v2_tx(
            cur,
            test_id=test_id,
            question_index=qidx,
            user_id=current_user_id,
            language="English",
            test_type=super_type,     # âœ… test_type = super_type (as you requested)
            category=sub_type,        # âœ… category = sub_type
            target_word=target_word,
            target_ipa=target_ipa,
            asr_ipa=asr_ipa,
            asr_word=asr_word,
            correct_rate=correct_rate,
            check_results=check_results,
            difficulty_level=diff,    # normalize_difficulty will map, OK
            score=score_points if isinstance(score_points, int) else None,
            severity=severity if isinstance(severity, str) else None,
        )

        # recompute done count
        cur.execute("SELECT COUNT(DISTINCT question_index) FROM test_records WHERE test_id=?", (test_id,))
        done_count = int(cur.fetchone()[0] or 0)

        cur.execute("""
            UPDATE tests
            SET progress_cursor=?,
                current_question_index=?,
                updated_at=CURRENT_TIMESTAMP
            WHERE id=?
        """, (done_count, done_count, test_id))

        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()

    return TestAnalyzeENResp(
        test_record_id=test_record_id,
        test_id=test_id,
        super_type=super_type,
        sub_type=sub_type,
        target_word=target_word,
        target_ipa=target_ipa,
        asr_word=asr_word,
        asr_ipa=asr_ipa,
        correct_rate=correct_rate,
        status=status,
        severity=severity if isinstance(severity, str) else None,
        check_results=check_results,
    )

class TestFinishENResp(BaseModel):
    test_id: str
    language: str
    threshold: int
    words_per_subtype: int
    confirmed: List[Dict[str, Any]]
    has_slp: int

@app.post("/api/test_en/finish", response_model=TestFinishENResp)
def api_test_en_finish_real(
    test_id: str = Query(...),
    current_user_id: str = Depends(get_current_user_id),
):
    """
    Finish EN test:
    - count final_label == 'slp' per (super_type, sub_type)
    - if count >= threshold => insert into slp_patient (language='en')
    - update tests to finished + result json
    """
    if not test_id:
        raise HTTPException(status_code=400, detail="Missing test_id")

    conn = get_db()
    cur = conn.cursor()
    cur.execute("SELECT patient_id, language, threshold, words_per_subtype FROM tests WHERE id=?", (test_id,))
    trow = cur.fetchone()
    if not trow:
        conn.close()
        raise HTTPException(status_code=404, detail="test_id not found")
    if trow[0] != current_user_id:
        conn.close()
        raise HTTPException(status_code=403, detail="Not allowed")
    if str(trow[1] or "") != TEST_EN_LANG:
        conn.close()
        raise HTTPException(status_code=400, detail="This test is not an EN test")

    threshold = int(trow[2] or TEST_EN_SLP_THRESHOLD_DEFAULT)
    wps = int(trow[3] or TEST_EN_WORDS_PER_SUBTYPE_DEFAULT)

    # load all test_records
    cur.execute("""
        SELECT test_type, category, check_results
        FROM test_records
        WHERE test_id=?
        ORDER BY question_index ASC
    """, (test_id,))
    rows = cur.fetchall()
    conn.close()

    counter: dict[tuple[str, str], int] = {}

    for st, sb, cr_json in rows:
        st = _normalize_super_type_en(st)
        sb = str(sb or "").strip()

        try:
            obj = json.loads(cr_json) if cr_json else {}
        except Exception:
            obj = {}

        if not isinstance(obj, dict):
            continue

        meta = obj.get("meta") if isinstance(obj.get("meta"), dict) else {}
        # must match this test_id
        if str(meta.get("test_id") or "") != str(test_id):
            continue

        # get detector result from payload
        det_key = _detector_key_for_super_en(st)
        det = obj.get(det_key) if det_key else None
        if not isinstance(det, dict):
            continue

        final_label = str(det.get("final_label") or "").strip().lower()
        if final_label == "slp":
            counter[(st, sb)] = counter.get((st, sb), 0) + 1

    confirmed = []
    confirmed_pairs: list[tuple[str, str]] = []

    for (st, sb), c in sorted(counter.items(), key=lambda x: (-x[1], x[0][0], x[0][1])):
        if c >= threshold:
            confirmed.append({"super_type": st, "sub_type": sb, "slp_count": c})
            confirmed_pairs.append((st, sb))

    # insert slp_patient rows
    insert_slp_patient_rows(
        user_id=current_user_id,
        test_id=test_id,
        confirmed=confirmed_pairs,
        language=TEST_EN_LANG,
    )

    has_slp = 1 if confirmed_pairs else 0

    summary_obj = {
        "language": TEST_EN_LANG,
        "threshold": threshold,
        "words_per_subtype": wps,
        "confirmed": confirmed,
        "counts": {f"{k[0]}::{k[1]}": v for k, v in counter.items()},
    }

    update_test_session_result(test_id=test_id, has_slp=has_slp, result_obj=summary_obj)

    return TestFinishENResp(
        test_id=test_id,
        language=TEST_EN_LANG,
        threshold=threshold,
        words_per_subtype=wps,
        confirmed=confirmed,
        has_slp=has_slp,
    )

class TestResumeENResp(BaseModel):
    available: bool
    test_id: Optional[str] = None
    status: Optional[str] = None
    progress_cursor: int = 0
    plan: Optional[dict] = None

@app.get("/api/test_en/resume", response_model=TestResumeENResp)
def api_test_en_resume_real(current_user_id: str = Depends(get_current_user_id)):
    """
    Resume latest running EN test for this user.
    """
    ensure_tests_table_v2_columns()

    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT id, status, progress_cursor, plan
            FROM tests
            WHERE patient_id=?
              AND status='running'
              AND language=?
            ORDER BY datetime(updated_at) DESC, datetime(date) DESC
            LIMIT 1
        """, (current_user_id, TEST_EN_LANG))
        row = cur.fetchone()

        if not row:
            return TestResumeENResp(available=False)

        test_id, status, progress_cursor, plan_json = row
        plan_obj = None
        if plan_json:
            try:
                plan_obj = json.loads(plan_json)
            except Exception:
                plan_obj = {"raw": plan_json}

        return TestResumeENResp(
            available=True,
            test_id=test_id,
            status=status,
            progress_cursor=int(progress_cursor or 0),
            plan=plan_obj,
        )
    finally:
        conn.close()

# ---- Staff: patient picker (only patients this SLP has sessions with) ----
class StaffPatientItem(BaseModel):
    id: str
    username: Optional[str] = None
    name: Optional[str] = None
    email: Optional[str] = None
    language: Optional[str] = None
    last_session_at: Optional[str] = None

@app.get("/api/slp/patients", response_model=dict)
def api_slp_patients(
    payload: dict = Depends(get_current_staff_payload),
):
    ensure_customer_service_tables()

    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload["sub"]

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        # patients that have at least one session with this slp
        cur.execute("""
            SELECT
              p.id, p.username, p.name, p.email, p.language,
              MAX(COALESCE(s.last_message_at, s.created_at)) AS last_session_at
            FROM service_sessions s
            JOIN patients p ON p.id = s.patient_id
            WHERE s.slp_id=?
              AND s.status IN ('assigned','open','closed')   -- "talked to" scope
            GROUP BY p.id
            ORDER BY datetime(last_session_at) DESC
        """, (slp_id,))
        items = [dict(r) for r in cur.fetchall()]
        return {"items": items}
    finally:
        conn.close()

@app.get("/api/slp/patient/{patient_id}/records_analysis")
def api_slp_patient_records_analysis(
    patient_id: str,
    language: Optional[str] = Query(None, description="Chinese|English (optional)"),
    limit: int = Query(500, ge=1, le=2000),
    payload: dict = Depends(get_current_staff_payload),
):
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")
    ensure_customer_service_tables()

    slp_id = payload["sub"]

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        # permission: must have a session with this patient
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        where_lang = ""
        params = [patient_id]

        if language and str(language).strip() != "":
            where_lang = " AND language=?"
            params.append(str(language).strip())

        params.append(int(limit))

        cur.execute(f"""
            SELECT *
            FROM records_analysis
            WHERE user_id=?
            {where_lang}
            ORDER BY datetime(created_at) DESC
            LIMIT ?
        """, tuple(params))

        return {"records": [dict(r) for r in cur.fetchall()]}
    finally:
        conn.close()

@app.get("/api/slp/patient/{patient_id}/tests")
def api_slp_patient_tests(
    patient_id: str,
    language: Optional[str] = Query(None, description="cn|en (optional)"),
    limit: int = Query(200, ge=1, le=500),
    payload: dict = Depends(get_current_staff_payload),
):
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")
    ensure_customer_service_tables()

    slp_id = payload["sub"]
    lang = None
    if language is not None and str(language).strip() != "":
        lang = normalize_practice_language(language)

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        where_lang = ""
        params = [patient_id]
        if lang:
            where_lang = " AND language=?"
            params.append(lang)
        params.append(int(limit))

        cur.execute(f"""
            SELECT
              id, test_name, status, language,
              threshold, words_per_subtype,
              progress_cursor, total_questions, current_question_index,
              has_slp, date, updated_at, finished_at
            FROM tests
            WHERE patient_id=?
              AND status <> 'cancelled'
              {where_lang}
            ORDER BY datetime(updated_at) DESC, datetime(date) DESC
            LIMIT ?
        """, tuple(params))

        return {"items": [dict(r) for r in cur.fetchall()]}
    finally:
        conn.close()


@app.get("/api/slp/patient/{patient_id}/tests/{test_id}")
def api_slp_patient_test_detail(
    patient_id: str,
    test_id: str,
    payload: dict = Depends(get_current_staff_payload),
):
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")
    ensure_customer_service_tables()

    slp_id = payload["sub"]

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        cur.execute("""
            SELECT *
            FROM tests
            WHERE id=? AND patient_id=? AND status <> 'cancelled'
            LIMIT 1
        """, (test_id, patient_id))
        row = cur.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="test not found")

        # return as patient endpoint shape
        def try_json(s):
            if not s:
                return None
            try:
                return json.loads(s)
            except Exception:
                return {"raw": s}

        return {
            "test": {
                "id": row["id"],
                "test_name": row["test_name"],
                "status": row["status"],
                "progress_cursor": int(row["progress_cursor"] or 0),
                "total_questions": int(row["total_questions"] or 0),
                "current_question_index": int(row["current_question_index"] or 0),
                "plan": try_json(row["plan"]),
                "config": try_json(row["config_json"]),
                "threshold": int(row["threshold"] or 0),
                "words_per_subtype": int(row["words_per_subtype"] or 0),
                "language": row["language"],
                "has_slp": int(row["has_slp"] or 0),
                "result": try_json(row["result"]),
                "created_at": row["date"],
                "updated_at": row["updated_at"],
                "finished_at": row["finished_at"],
            }
        }
    finally:
        conn.close()


@app.get("/api/slp/patient/{patient_id}/tests/{test_id}/records")
def api_slp_patient_test_records(
    patient_id: str,
    test_id: str,
    payload: dict = Depends(get_current_staff_payload),
):
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")
    ensure_customer_service_tables()

    slp_id = payload["sub"]

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        cur.execute("SELECT patient_id, status FROM tests WHERE id=? LIMIT 1", (test_id,))
        t = cur.fetchone()
        if not t or t["patient_id"] != patient_id or str(t["status"]).lower() == "cancelled":
            raise HTTPException(status_code=404, detail="test not found")

        cur.execute("""
            SELECT *
            FROM test_records
            WHERE test_id=?
            ORDER BY question_index ASC, datetime(created_at) ASC
        """, (test_id,))
        return {"items": [dict(r) for r in cur.fetchall()]}
    finally:
        conn.close()


@app.get("/api/slp/patient/{patient_id}/tests/{test_id}/slp")
def api_slp_patient_test_slp(
    patient_id: str,
    test_id: str,
    language: Optional[str] = Query(None, description="cn|en (optional)"),
    payload: dict = Depends(get_current_staff_payload),
):
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")
    ensure_customer_service_tables()

    slp_id = payload["sub"]
    lang = None
    if language is not None and str(language).strip() != "":
        lang = normalize_practice_language(language)

    conn = get_db()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        where_lang = ""
        params = [test_id]
        if lang:
            where_lang = " AND language=?"
            params.append(lang)

        cur.execute(f"""
            SELECT *
            FROM slp_patient
            WHERE test_id=?
            {where_lang}
            ORDER BY datetime(created_at) DESC, datetime(datetime) DESC
        """, tuple(params))

        return {"items": [dict(r) for r in cur.fetchall()]}
    finally:
        conn.close()

@app.get("/api/slp/patient/{patient_id}/training/tasks")
def api_slp_patient_training_tasks(
    patient_id: str,
    payload: dict = Depends(get_current_staff_payload),
):
    """
    SLP æŸ¥çœ‹æŸä¸ªç—…äººçš„ training tasksï¼ˆCN/EN + day1..7ï¼‰ã€‚
    æƒé™ï¼šè¯¥ SLP å¿…é¡»ä¸è¯¥ç—…äººå­˜åœ¨ service_sessions (assigned/open/closed)ã€‚
    è¿”å›æ ¼å¼å¯¹é½ /api/tasks/training/all-active
    """
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")
    ensure_customer_service_tables()

    slp_id = payload["sub"]

    conn = get_db()
    cur = conn.cursor()
    try:
        # permission check
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        # latest allocated_at for this patient (training tasks only)
        cur.execute("""
            SELECT allocated_at
            FROM tasks
            WHERE user_id=?
              AND is_active=1
              AND allocated_at IS NOT NULL
              AND super_type IS NOT NULL
              AND sub_type IS NOT NULL
            ORDER BY datetime(allocated_at) DESC
            LIMIT 1
        """, (patient_id,))
        r = cur.fetchone()
        latest_alloc = r[0] if r else None
        latest_allowed = _task_allowed_day_index(latest_alloc) if latest_alloc else None

        # all active training tasks
        cur.execute("""
            SELECT
              id, super_type, sub_type, task_kind, language,
              allocated_at, day_index, total_times, progress_times, status, is_active,
              reward_claimed, reward_claimed_at
            FROM tasks
            WHERE user_id=?
              AND is_active=1
              AND super_type IS NOT NULL
              AND sub_type IS NOT NULL
            ORDER BY
              datetime(allocated_at) DESC,
              language ASC,
              super_type ASC,
              sub_type ASC,
              task_kind ASC,
              day_index ASC
        """, (patient_id,))
        rows = cur.fetchall()

        tasks = []
        for row in rows:
            (tid, st, sb, kind, lang, alloc, day_idx, total, prog, status, is_active, reward_claimed, reward_claimed_at) = row
            tasks.append({
                "id": tid,
                "super_type": st,
                "sub_type": sb,
                "task_kind": str(kind or "vocab"),
                "language": str(lang or "cn"),
                "allocated_at": alloc,
                "day_index": int(day_idx or 1),
                "total_times": int(total or 0),
                "progress_times": int(prog or 0),
                "status": str(status or "pending"),
                "is_active": int(is_active or 0),
                "reward_claimed": int(reward_claimed or 0),
                "reward_claimed_at": reward_claimed_at,
            })

        return {
            "available": bool(tasks),
            "latest_allocated_at": latest_alloc,
            "latest_allowed_day_index": latest_allowed,
            "tasks": tasks,
            "reason": None if tasks else "NO_ACTIVE_TRAINING_TASKS",
        }
    finally:
        conn.close()

@app.get("/debug_g2p")
async def debug_g2p(word: str = "RIDBON"):
    # Show exactly which file is running + what espeak returns inside the server process
    info = {
        "module": __name__,
        "file": str(Path(__file__).resolve()),
        "word": word,
    }

    # Check espeak availability
    try:
        ver = subprocess.check_output(
            ["espeak", "--version"],
            text=True,
            encoding="utf-8",
            stderr=subprocess.STDOUT,
        ).strip()
        info["espeak_version"] = ver
    except Exception as e:
        info["espeak_version_error"] = repr(e)

    # IPA output
    try:
        ipa_out = subprocess.check_output(
            ["espeak", "-q", "-v", "en-us", "--ipa=3", word],
            text=True,
            encoding="utf-8",
            stderr=subprocess.STDOUT,
        ).strip().replace("\u200d", "")
        info["espeak_ipa_raw"] = ipa_out
        info["espeak_ipa_normalized"] = normalize_ipa(ipa_out)
    except Exception as e:
        info["espeak_ipa_error"] = repr(e)

    # -x fallback output
    try:
        x_out = subprocess.check_output(
            ["espeak", "-q", "-v", "en-us", "-x", word],
            text=True,
            encoding="utf-8",
            stderr=subprocess.STDOUT,
        ).strip()
        info["espeak_x"] = x_out
    except Exception as e:
        info["espeak_x_error"] = repr(e)

    # What YOUR pipeline would return
    try:
        info["word_to_ipa_or_star"] = word_to_ipa_or_star(word)
    except Exception as e:
        info["word_to_ipa_or_star_error"] = repr(e)

    return JSONResponse(info)

# ==============================
# âœ… SLP Task Editor: Update Patient Training Tasks (CN/EN separate)
# ==============================
from pydantic import BaseModel, Field

class SlpTaskEditItem(BaseModel):
    super_type: str
    sub_type: str
    total_times: int = Field(..., ge=1, le=9999)

class SlpTaskEditDay(BaseModel):
    day_index: int = Field(..., ge=1, le=7)
    items: List[SlpTaskEditItem] = []

class SlpTaskEditReq(BaseModel):
    patient_id: str
    language: str = "cn"        # "cn" | "en"
    task_kind: str = "vocab"    # "vocab" | "sentence"
    days: List[SlpTaskEditDay]
    meta: Optional[dict] = None

def _normalize_task_lang(lang: str | None) -> str:
    s = (lang or "").strip().lower()
    if s in ("cn", "zh", "zh-cn", "chinese"):
        return "cn"
    if s in ("en", "english"):
        return "en"
    return "cn"

def _normalize_task_kind(kind: str | None) -> str:
    k = (kind or "vocab").strip().lower()
    if k not in ("vocab", "sentence"):
        return "vocab"
    return k

@app.post("/api/slp/patient/{patient_id}/training/tasks/update")
def api_slp_update_patient_training_tasks(
    patient_id: str,
    data: SlpTaskEditReq,
    payload: dict = Depends(get_current_staff_payload),
):
    """
    SLP è¦†å¯«ã€ŒæŸç—…äººã€æŸèªè¨€(cn/en) çš„ã€Œæœ€æ–°ä¸€æ‰¹ allocated_atã€ training tasksï¼ˆday1..7ï¼‰ã€‚
    - ä¸æ›´æ–° allocated_atï¼ˆæ²¿ç”¨è©² batch æœ€æ–°å€¼ï¼‰
    - ä¸çœŸçš„åˆª rowï¼šæŠŠä¸åœ¨æ–°é…ç½®å…§çš„èˆŠ task è¨­ is_active=0ï¼ˆsoft deleteï¼‰
    - æ–°å¢ï¼šINSERT æ–° rowï¼ˆallocated_at åŒ batchï¼‰
    - æ›´æ–°ï¼šå­˜åœ¨å‰‡ UPDATE total_timesï¼ˆprogress_times ä¿ç•™ä¸å‹•ï¼‰
    """
    ensure_task_table_v2()
    ensure_customer_service_tables()

    # ---- auth: only slp ----
    if payload.get("role") != "slp":
        raise HTTPException(status_code=403, detail="Only SLP")

    slp_id = payload.get("sub")
    if not slp_id:
        raise HTTPException(status_code=401, detail="Invalid staff token")

    # ---- path/body patient_id must match ----
    if str(patient_id) != str(data.patient_id):
        raise HTTPException(status_code=400, detail="patient_id mismatch")

    # ---- permission: slp must have sessions with patient ----
    conn = get_db()
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT 1
            FROM service_sessions
            WHERE patient_id=? AND slp_id=? AND status IN ('assigned','open','closed')
            LIMIT 1
        """, (patient_id, slp_id))
        if not cur.fetchone():
            raise HTTPException(status_code=403, detail="not allowed")

        lang = _normalize_task_lang(data.language)
        task_kind = _normalize_task_kind(data.task_kind)

        # ---- validate days: must cover 1..7 (can be empty items) ----
        days_map: dict[int, list[SlpTaskEditItem]] = {}
        for d in (data.days or []):
            di = int(d.day_index)
            if di < 1 or di > 7:
                raise HTTPException(status_code=400, detail="Invalid day_index")
            days_map[di] = d.items or []

        for di in range(1, 8):
            if di not in days_map:
                # require explicit day entries (so update is deterministic)
                raise HTTPException(status_code=400, detail=f"Missing day_index={di}")

        # ---- find latest allocated_at batch for this patient+lang+kind ----
        cur.execute("""
            SELECT allocated_at
            FROM tasks
            WHERE user_id=?
              AND is_active=1
              AND allocated_at IS NOT NULL
              AND language=?
              AND task_kind=?
              AND super_type IS NOT NULL
              AND sub_type IS NOT NULL
            ORDER BY datetime(allocated_at) DESC
            LIMIT 1
        """, (patient_id, lang, task_kind))
        r = cur.fetchone()
        if not r or not r[0]:
            raise HTTPException(status_code=400, detail="NO_ACTIVE_BATCH")

        allocated_at = r[0]

        # ---- load existing tasks in this batch (for lang+kind only) ----
        cur.execute("""
            SELECT id, day_index, super_type, sub_type, total_times, progress_times, status, is_active
            FROM tasks
            WHERE user_id=?
              AND language=?
              AND task_kind=?
              AND is_active=1
              AND allocated_at IS NOT NULL
              AND datetime(allocated_at)=datetime(?)
              AND day_index BETWEEN 1 AND 7
              AND super_type IS NOT NULL
              AND sub_type IS NOT NULL
        """, (patient_id, lang, task_kind, allocated_at))
        rows = cur.fetchall()

        # key: (day_index, super_type, sub_type) -> row
        existing = {}
        for row in rows:
            tid, day_index, st, sb, total_times, progress_times, status, is_active = row
            existing[(int(day_index), str(st), str(sb))] = {
                "id": tid,
                "total_times": int(total_times or 0),
                "progress_times": int(progress_times or 0),
                "status": str(status or "pending"),
                "is_active": int(is_active or 0),
            }

        # desired keys set
        desired_keys = set()
        for di in range(1, 8):
            for it in (days_map.get(di) or []):
                st = str(it.super_type or "").strip()
                sb = str(it.sub_type or "").strip()
                if not st or not sb:
                    raise HTTPException(status_code=400, detail="Empty super_type/sub_type")
                desired_keys.add((di, st, sb))

        # ---- soft delete: existing but not desired ----
        for k, ex in existing.items():
            if k not in desired_keys:
                cur.execute("UPDATE tasks SET is_active=0 WHERE id=?", (ex["id"],))

        # ---- upsert desired ----
        upserted = {"inserted": 0, "updated": 0}
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        for di in range(1, 8):
            for it in (days_map.get(di) or []):
                st = str(it.super_type).strip()
                sb = str(it.sub_type).strip()
                total_times = int(it.total_times)

                k = (di, st, sb)
                if k in existing:
                    # UPDATE only total_times (keep progress/status as-is)
                    cur.execute("""
                        UPDATE tasks
                        SET total_times=?,
                            updated_at=CURRENT_TIMESTAMP
                        WHERE id=?
                    """, (total_times, existing[k]["id"]))
                    upserted["updated"] += 1
                else:
                    # INSERT new row into same batch allocated_at
                    # note: title/category are required by schema, provide defaults
                    tid = str(uuid.uuid4())
                    cur.execute("""
                        INSERT INTO tasks
                        (id, title, description, category, due_date,
                         total_times, progress_times, integral, status, created_at,
                         user_id, super_type, sub_type, language, allocated_at,
                         valid_days, day_index, is_active, task_kind, task_key,
                         reward_claimed, reward_claimed_at)
                        VALUES
                        (?, ?, ?, 'daily', NULL,
                         ?, 0, 0, 'pending', CURRENT_TIMESTAMP,
                         ?, ?, ?, ?, ?,
                         7, ?, 1, ?, NULL,
                         0, NULL)
                    """, (
                        tid,
                        f"SLP Edited Task ({lang})",
                        f"Edited by SLP {slp_id} at {now}",
                        total_times,
                        patient_id,
                        st,
                        sb,
                        lang,
                        allocated_at,
                        int(di),
                        task_kind,
                    ))
                    upserted["inserted"] += 1

        # ---- audit log ----
        try:
            audit_log(
                actor_type="slp",
                actor_id=slp_id,
                action="SLP_EDIT_PATIENT_TASKS",
                resource_type="tasks_batch",
                resource_id=str(allocated_at),
                metadata=json.dumps({
                    "patient_id": patient_id,
                    "language": lang,
                    "task_kind": task_kind,
                    "inserted": upserted["inserted"],
                    "updated": upserted["updated"],
                    "meta": data.meta or {},
                }, ensure_ascii=False),
            )
        except Exception:
            pass

        conn.commit()

        # return refreshed batch for frontend to re-render
        cur.execute("""
            SELECT
              id, super_type, sub_type, task_kind, language,
              allocated_at, day_index, total_times, progress_times, status, is_active,
              reward_claimed, reward_claimed_at
            FROM tasks
            WHERE user_id=?
              AND language=?
              AND task_kind=?
              AND allocated_at IS NOT NULL
              AND datetime(allocated_at)=datetime(?)
              AND day_index BETWEEN 1 AND 7
            ORDER BY day_index ASC, super_type ASC, sub_type ASC
        """, (patient_id, lang, task_kind, allocated_at))
        out_rows = cur.fetchall()

        tasks = []
        for row in out_rows:
            (tid, st, sb, kind, lg, alloc, day_idx,
             total, prog, status, is_active, reward_claimed, reward_claimed_at) = row
            tasks.append({
                "id": tid,
                "super_type": st,
                "sub_type": sb,
                "task_kind": str(kind or "vocab"),
                "language": str(lg or lang),
                "allocated_at": alloc,
                "day_index": int(day_idx or 1),
                "total_times": int(total or 0),
                "progress_times": int(prog or 0),
                "status": str(status or "pending"),
                "is_active": int(is_active or 0),
                "reward_claimed": int(reward_claimed or 0),
                "reward_claimed_at": reward_claimed_at,
            })

        allowed = _task_allowed_day_index(allocated_at)

        return {
            "msg": "ok",
            "patient_id": patient_id,
            "language": lang,
            "task_kind": task_kind,
            "allocated_at": allocated_at,
            "allowed_day_index": allowed,
            "upserted": upserted,
            "tasks": tasks,
        }

    except HTTPException:
        conn.rollback()
        raise
    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=500, detail=f"update tasks failed: {str(e)}")
    finally:
        conn.close()

from pathlib import Path
from fastapi import HTTPException
from fastapi.responses import FileResponse

FRONTEND_PUBLIC_DIR = (BASE_DIR / ".." / "frontend" / "public").resolve()
UNITY_GAME1_DIR = (FRONTEND_PUBLIC_DIR / "Game1").resolve()

# Basic MIME map for Unity files
_MIME_MAP = {
    ".js": "application/javascript",
    ".wasm": "application/wasm",
    ".data": "application/octet-stream",
    ".json": "application/json",
    ".txt": "text/plain; charset=utf-8",
    ".png": "image/png",
    ".jpg": "image/jpeg",
    ".jpeg": "image/jpeg",
    ".gif": "image/gif",
    ".svg": "image/svg+xml",
    ".mp3": "audio/mpeg",
    ".wav": "audio/wav",
    ".ogg": "audio/ogg",
    ".mp4": "video/mp4",
}

def _guess_mime_for_unity_file(p: Path) -> str:
    """
    For *.framework.js.br we want JS mime.
    For *.wasm.br we want wasm mime.
    For *.data.br we want octet-stream.
    Strategy:
    - If file endswith .br => look at the suffix BEFORE .br
    - else => look at normal suffix
    """
    suffixes = p.suffixes  # e.g. ['.framework', '.js', '.br']
    if suffixes and suffixes[-1] == ".br":
        # use the suffix before .br if available
        if len(suffixes) >= 2:
            ext = suffixes[-2]  # '.js' or '.wasm' or '.data'
        else:
            ext = ".bin"
    else:
        ext = p.suffix or ".bin"

    return _MIME_MAP.get(ext.lower(), "application/octet-stream")

@app.get("/unity/Game1/{file_path:path}")
def unity_game1_files(file_path: str):
    """
    Serve files under frontend/public/Game1/...
    Example:
      /unity/Game1/Build/Game1.loader.js
      /unity/Game1/Build/Game1.wasm.br
    """
    # Prevent path traversal
    abs_path = (UNITY_GAME1_DIR / file_path).resolve()
    if not str(abs_path).startswith(str(UNITY_GAME1_DIR)):
        raise HTTPException(status_code=403, detail="Forbidden path")

    if not abs_path.exists() or not abs_path.is_file():
        raise HTTPException(status_code=404, detail=f"File not found: {file_path}")

    headers = {
        "Cache-Control": "no-cache",
        "Cross-Origin-Resource-Policy": "cross-origin",
    }

    # Only .br files get Content-Encoding: br
    if abs_path.suffix == ".br":
        headers["Content-Encoding"] = "br"

    return FileResponse(
        path=str(abs_path),
        media_type=_guess_mime_for_unity_file(abs_path),
        headers=headers,
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=True)